# æ¨è–¦ç³»çµ± - å…§å®¹éæ¿¾å¯¦æˆ°

**å°ˆæ¡ˆé¡å‹**: æ¨è–¦æ¼”ç®—æ³• - åŸºæ–¼å…§å®¹çš„éæ¿¾
**é›£åº¦**: â­â­â­ ä¸­ç´š
**é è¨ˆæ™‚é–“**: 2-3 å°æ™‚
**æŠ€è¡“æ£§**: TF-IDF, Cosine Similarity, Scikit-learn

---

## ğŸ“‹ å°ˆæ¡ˆæ¦‚è¿°

æœ¬å°ˆæ¡ˆå¯¦ä½œ**åŸºæ–¼å…§å®¹çš„æ¨è–¦ç³»çµ±** (Content-Based Filtering),ä½¿ç”¨ TF-IDF å‘é‡åŒ–æŠ€è¡“å’Œé¤˜å¼¦ç›¸ä¼¼åº¦è¨ˆç®—,å¯¦ç¾æ–‡ç« /å•†å“çš„æ™ºèƒ½æ¨è–¦ã€‚

**æ ¸å¿ƒæŠ€è¡“**:
- TF-IDF æ–‡æœ¬å‘é‡åŒ–
- é¤˜å¼¦ç›¸ä¼¼åº¦è¨ˆç®—
- ç›¸ä¼¼é …ç›®æ¨è–¦
- æ¨è–¦çµæœæ’åºèˆ‡éæ¿¾

---

## ğŸ¯ å­¸ç¿’ç›®æ¨™

- âœ… ç†è§£åŸºæ–¼å…§å®¹æ¨è–¦çš„æ ¸å¿ƒåŸç†
- âœ… æŒæ¡ TF-IDF å‘é‡åŒ–æŠ€è¡“
- âœ… å¯¦ä½œé¤˜å¼¦ç›¸ä¼¼åº¦è¨ˆç®—
- âœ… æ§‹å»ºå®Œæ•´çš„æ¨è–¦ç³»çµ±
- âœ… è©•ä¼°æ¨è–¦ç³»çµ±æ€§èƒ½

---

## ğŸ“Š Notebook å…§å®¹

**æª”å**: `å°ˆæ¡ˆ_æ¨è–¦ç³»çµ±_å…§å®¹éæ¿¾_TFIDF.ipynb`

### æ ¸å¿ƒæµç¨‹

```
Step 1: æ•¸æ“šæº–å‚™
    â”œâ”€â”€ è¼‰å…¥æ–‡ç« /å•†å“æ•¸æ“š
    â”œâ”€â”€ æ–‡æœ¬é è™•ç†
    â””â”€â”€ ç‰¹å¾µæå–

Step 2: TF-IDF å‘é‡åŒ–
    â”œâ”€â”€ å»ºç«‹è©å½™è¡¨
    â”œâ”€â”€ è¨ˆç®— TF-IDF æ¬Šé‡
    â””â”€â”€ ç”Ÿæˆæ–‡æª”å‘é‡çŸ©é™£

Step 3: ç›¸ä¼¼åº¦è¨ˆç®—
    â”œâ”€â”€ è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦
    â”œâ”€â”€ å»ºç«‹ç›¸ä¼¼åº¦çŸ©é™£
    â””â”€â”€ æ‰¾å‡ºæœ€ç›¸ä¼¼é …ç›®

Step 4: æ¨è–¦ç”Ÿæˆ
    â”œâ”€â”€ æ ¹æ“šç”¨æˆ¶æ­·å²æ¨è–¦
    â”œâ”€â”€ æ’åºèˆ‡éæ¿¾
    â””â”€â”€ Top-N æ¨è–¦çµæœ

Step 5: è©•ä¼°èˆ‡å„ªåŒ–
    â”œâ”€â”€ æ¨è–¦å¤šæ¨£æ€§
    â”œâ”€â”€ è¦†è“‹ç‡åˆ†æ
    â””â”€â”€ æº–ç¢ºç‡è©•ä¼°
```

---

## ğŸ§® æ ¸å¿ƒç®—æ³•

### TF-IDF å…¬å¼

```
TF-IDF(t, d) = TF(t, d) Ã— IDF(t)

å…¶ä¸­:
TF(t, d) = è© t åœ¨æ–‡æª” d ä¸­çš„é »ç‡
IDF(t) = log(ç¸½æ–‡æª”æ•¸ / åŒ…å«è© t çš„æ–‡æª”æ•¸)
```

### é¤˜å¼¦ç›¸ä¼¼åº¦å…¬å¼

```
similarity(A, B) = (A Â· B) / (||A|| Ã— ||B||)

ç¯„åœ: [-1, 1]
- 1: å®Œå…¨ç›¸åŒ
- 0: ç„¡é—œè¯
- -1: å®Œå…¨ç›¸å
```

### å¯¦ä½œç¯„ä¾‹

```python
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# 1. TF-IDF å‘é‡åŒ–
vectorizer = TfidfVectorizer(
    max_features=1000,
    stop_words='english',
    ngram_range=(1, 2)
)
tfidf_matrix = vectorizer.fit_transform(documents)

# 2. è¨ˆç®—ç›¸ä¼¼åº¦çŸ©é™£
similarity_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)

# 3. æ¨è–¦å‡½æ•¸
def get_recommendations(item_id, top_n=5):
    """
    æ ¹æ“šé …ç›® ID æ¨è–¦æœ€ç›¸ä¼¼çš„ N å€‹é …ç›®
    """
    # ç²å–ç›¸ä¼¼åº¦åˆ†æ•¸
    sim_scores = list(enumerate(similarity_matrix[item_id]))

    # æ’åº (é™åº)
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    # æ’é™¤è‡ªå·±,å–å‰ N å€‹
    sim_scores = sim_scores[1:top_n+1]

    # æå–é …ç›®ç´¢å¼•
    item_indices = [i[0] for i in sim_scores]
    scores = [i[1] for i in sim_scores]

    return item_indices, scores

# ä½¿ç”¨
recommendations, scores = get_recommendations(item_id=0, top_n=5)
print(f"æ¨è–¦é …ç›®: {recommendations}")
print(f"ç›¸ä¼¼åº¦: {scores}")
```

---

## ğŸ“ æ•¸æ“šèªªæ˜

### æ•¸æ“šä¾†æº
- **ä½ç½®**: `datasets/lyrics/æƒ…æ­Œæ­Œè©/` æˆ–è‡ªè¨‚æ•¸æ“š
- **æ ¼å¼**: ç´”æ–‡æœ¬ .txt æª”æ¡ˆ
- **æ•¸é‡**: 290+ é¦–æƒ…æ­Œ
- **èªè¨€**: ç¹é«”ä¸­æ–‡

### æ•¸æ“šæ ¼å¼ç¯„ä¾‹
```
æ¯å€‹ .txt æª”æ¡ˆåŒ…å«ä¸€é¦–æ­Œçš„å®Œæ•´æ­Œè©:

æª”å: 100_åŸä¾†é€™æ‰æ˜¯çœŸçš„ä½ .txt
å…§å®¹:
---
åŸä¾†é€™æ‰æ˜¯çœŸçš„ä½ 
åŸä¾†æ„›æœƒè®“äººå¤±å»è‡ªå·±
åŸä¾†é™ªä¼´æ‰æ˜¯æœ€æ·±æƒ…çš„å‘Šç™½
...
---
```

### è¼‰å…¥æ•¸æ“š
```python
from pathlib import Path

lyrics_dir = Path("../../datasets/lyrics/æƒ…æ­Œæ­Œè©")
lyrics_files = sorted(lyrics_dir.glob("*.txt"))

lyrics_data = []
for file in lyrics_files:
    with open(file, 'r', encoding='utf-8') as f:
        lyrics_data.append({
            'title': file.stem,  # æª”åä½œç‚ºæ­Œå
            'lyrics': f.read()
        })

print(f"âœ… è¼‰å…¥ {len(lyrics_data)} é¦–æ­Œè©")
```

---

## ğŸ¨ é æœŸçµæœ

### æ¨è–¦çµæœç¯„ä¾‹

```
è¼¸å…¥æ­Œæ›²: "æ„›ä¹…è¦‹äººå¿ƒ"

æ¨è–¦æ­Œæ›²:
1. å¿ƒå¿ƒç›¸å° (ç›¸ä¼¼åº¦: 0.87)
2. æ„›çš„å¤©éˆéˆ (ç›¸ä¼¼åº¦: 0.82)
3. å–®æˆ€ (ç›¸ä¼¼åº¦: 0.79)
4. æˆ‘å–œæ­¡ (ç›¸ä¼¼åº¦: 0.76)
5. æœ€æƒ³ç’°éŠçš„ä¸–ç•Œ (ç›¸ä¼¼åº¦: 0.74)
```

### è¦–è¦ºåŒ–

1. **è©é »é•·æ¢åœ–**
   - å±•ç¤º TOP 20 é«˜é »è©
   - æ©«è»¸: è©å½™
   - ç¸±è»¸: å‡ºç¾æ¬¡æ•¸

2. **æ–‡å­—é›²**
   - æ„›æƒ…ç›¸é—œè©å½™: "æ„›"ã€"å¿ƒ"ã€"ä½ "ã€"æˆ‘"
   - å­—é«”å¤§å°å°æ‡‰é »ç‡

3. **ç›¸ä¼¼åº¦ç†±åœ–**
   - å±•ç¤ºå‰ 20 é¦–æ­Œçš„ç›¸ä¼¼åº¦çŸ©é™£
   - é¡è‰²æ·±æ·ºä»£è¡¨ç›¸ä¼¼ç¨‹åº¦

---

## ğŸ”§ æŠ€è¡“ç´°ç¯€

### TF-IDF åƒæ•¸èª¿å„ª

```python
# åŸºç¤é…ç½®
vectorizer = TfidfVectorizer()

# é€²éšé…ç½®
vectorizer = TfidfVectorizer(
    max_features=1000,        # æœ€å¤šä¿ç•™ 1000 å€‹è©
    min_df=2,                 # è‡³å°‘å‡ºç¾åœ¨ 2 å€‹æ–‡æª”
    max_df=0.8,               # æœ€å¤šå‡ºç¾åœ¨ 80% æ–‡æª”
    ngram_range=(1, 2),       # 1-gram å’Œ 2-gram
    sublinear_tf=True,        # ä½¿ç”¨ log TF
    use_idf=True,             # ä½¿ç”¨ IDF
    smooth_idf=True           # å¹³æ»‘ IDF
)
```

### æå‡æ¨è–¦è³ªé‡

```python
# 1. å¤šæ¨£æ€§éæ¿¾ (é¿å…æ¨è–¦å¤ªç›¸ä¼¼çš„é …ç›®)
def diverse_recommendations(item_id, top_n=10, diversity_threshold=0.95):
    """æ¨è–¦å¤šæ¨£åŒ–çš„é …ç›®"""
    candidates, scores = get_recommendations(item_id, top_n=50)

    selected = []
    for candidate, score in zip(candidates, scores):
        # æª¢æŸ¥èˆ‡å·²é¸é …ç›®çš„ç›¸ä¼¼åº¦
        is_diverse = True
        for selected_item in selected:
            if similarity_matrix[candidate][selected_item] > diversity_threshold:
                is_diverse = False
                break

        if is_diverse:
            selected.append(candidate)

        if len(selected) == top_n:
            break

    return selected

# 2. æ™‚é–“è¡°æ¸› (newer items get boost)
def time_aware_recommendations(item_id, top_n=5, time_decay=0.1):
    """è€ƒæ…®æ™‚é–“å› ç´ çš„æ¨è–¦"""
    base_scores = similarity_matrix[item_id]

    # æ™‚é–“æ¬Šé‡ (å‡è¨­ items æŒ‰æ™‚é–“æ’åº)
    time_weights = np.exp(-time_decay * np.arange(len(base_scores)))

    # åŠ æ¬Šåˆ†æ•¸
    weighted_scores = base_scores * time_weights

    # æ’åº
    top_indices = np.argsort(weighted_scores)[::-1][1:top_n+1]
    return top_indices
```

---

## ğŸ“ˆ è©•ä¼°æŒ‡æ¨™

### æ¨è–¦ç³»çµ±è©•ä¼°

```python
# 1. è¦†è“‹ç‡ (Coverage)
def calculate_coverage(all_recommendations, total_items):
    """è¨ˆç®—æ¨è–¦ç³»çµ±è¦†è“‹ç‡"""
    unique_recommended = set()
    for recs in all_recommendations:
        unique_recommended.update(recs)

    coverage = len(unique_recommended) / total_items
    return coverage

# 2. å¤šæ¨£æ€§ (Diversity)
def calculate_diversity(recommendations, similarity_matrix):
    """è¨ˆç®—æ¨è–¦åˆ—è¡¨å…§éƒ¨å¤šæ¨£æ€§"""
    diversity_scores = []

    for recs in recommendations:
        # è¨ˆç®—åˆ—è¡¨å…§æ‰€æœ‰é…å°çš„ç›¸ä¼¼åº¦
        n = len(recs)
        if n < 2:
            continue

        avg_similarity = 0
        count = 0
        for i in range(n):
            for j in range(i+1, n):
                avg_similarity += similarity_matrix[recs[i]][recs[j]]
                count += 1

        diversity = 1 - (avg_similarity / count) if count > 0 else 0
        diversity_scores.append(diversity)

    return np.mean(diversity_scores)

# 3. æ–°ç©åº¦ (Novelty)
def calculate_novelty(recommendations, popularity):
    """è¨ˆç®—æ¨è–¦çš„æ–°ç©åº¦ (æ¨è–¦å†·é–€é …ç›®èƒ½åŠ›)"""
    novelty_scores = []

    for recs in recommendations:
        # æ¨è–¦é …ç›®çš„å¹³å‡æµè¡Œåº¦
        avg_popularity = np.mean([popularity[r] for r in recs])
        # æ–°ç©åº¦ = 1 - æµè¡Œåº¦
        novelty = 1 - avg_popularity
        novelty_scores.append(novelty)

    return np.mean(novelty_scores)
```

---

## ğŸš€ é€²éšä¸»é¡Œ

### æ··åˆæ¨è–¦ç³»çµ±

çµåˆå…§å®¹éæ¿¾èˆ‡å”åŒéæ¿¾:

```python
class HybridRecommender:
    def __init__(self, content_weight=0.6, collaborative_weight=0.4):
        self.content_weight = content_weight
        self.collaborative_weight = collaborative_weight

    def recommend(self, user_id, item_id, top_n=5):
        """
        æ··åˆæ¨è–¦
        """
        # å…§å®¹éæ¿¾åˆ†æ•¸
        content_scores = content_based_score(item_id)

        # å”åŒéæ¿¾åˆ†æ•¸
        collaborative_scores = collaborative_filtering_score(user_id)

        # åŠ æ¬Šåˆä½µ
        hybrid_scores = (
            self.content_weight * content_scores +
            self.collaborative_weight * collaborative_scores
        )

        # æ’åº
        top_items = np.argsort(hybrid_scores)[::-1][:top_n]
        return top_items
```

---

## âœ… æª¢æŸ¥æ¸…å–®

å®Œæˆå°ˆæ¡ˆå¾Œ,ç¢ºèª:

- [ ] ç†è§£ TF-IDF åŸç†èˆ‡å¯¦ä½œ
- [ ] æŒæ¡é¤˜å¼¦ç›¸ä¼¼åº¦è¨ˆç®—
- [ ] èƒ½å¤ å»ºç«‹åŸºç¤æ¨è–¦ç³»çµ±
- [ ] ç†è§£æ¨è–¦ç³»çµ±è©•ä¼°æŒ‡æ¨™
- [ ] å˜—è©¦èª¿æ•´åƒæ•¸æå‡æ¨è–¦è³ªé‡
- [ ] (é¸) å¯¦ä½œå¤šæ¨£æ€§å„ªåŒ–
- [ ] (é¸) æ“´å±•åˆ°æ··åˆæ¨è–¦

---

**å°ˆæ¡ˆç‰ˆæœ¬**: v1.0
**æœ€å¾Œæ›´æ–°**: 2025-10-17
**ç¶­è­·è€…**: iSpan NLP Team
**æˆæ¬Š**: MIT License
