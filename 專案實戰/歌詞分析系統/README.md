# æ­Œè©åˆ†æç³»çµ±

**å°ˆæ¡ˆé¡å‹**: ä¸­æ–‡ NLP - è©é »åˆ†æèˆ‡è¦–è¦ºåŒ–
**é›£åº¦**: â­â­ åˆç´š-ä¸­ç´š
**é è¨ˆæ™‚é–“**: 2-3 å°æ™‚
**æŠ€è¡“æ£§**: Jieba, WordCloud, Matplotlib

---

## ğŸ“‹ å°ˆæ¡ˆæ¦‚è¿°

æœ¬å°ˆæ¡ˆä½¿ç”¨ **290+ é¦–æƒ…æ­Œæ­Œè©**é€²è¡Œä¸­æ–‡æ–‡æœ¬åˆ†æ,å±•ç¤º:
- Jieba ä¸­æ–‡æ–·è©æŠ€è¡“
- è©é »çµ±è¨ˆåˆ†æ
- æ–‡å­—é›²è¦–è¦ºåŒ–
- ä¸­æ–‡ NLP å®Œæ•´æµç¨‹

**é©åˆ**: NLP åˆå­¸è€…ã€ä¸­æ–‡æ–‡æœ¬è™•ç†å…¥é–€

---

## ğŸ¯ å­¸ç¿’ç›®æ¨™

- âœ… æŒæ¡ Jieba ä¸­æ–‡æ–·è©æŠ€å·§
- âœ… ç†è§£è©é »çµ±è¨ˆåŸç†
- âœ… å­¸æœƒä½¿ç”¨ WordCloud ç”Ÿæˆæ–‡å­—é›²
- âœ… è™•ç†ç¹é«”ä¸­æ–‡æ–‡æœ¬
- âœ… å¯¦ä½œå®Œæ•´çš„ä¸­æ–‡æ–‡æœ¬åˆ†ææµç¨‹

---

## ğŸ“Š Notebooks èªªæ˜

### 1. æ–·è©åˆ†æ
**æª”å**: `å°ˆæ¡ˆ_æ­Œè©åˆ†æ_æ–·è©åˆ†æ_Jieba.ipynb`

**æ ¸å¿ƒå…§å®¹**:
1. è¼‰å…¥ 290+ é¦–æƒ…æ­Œæ­Œè©
2. ä½¿ç”¨ Jieba é€²è¡Œä¸­æ–‡æ–·è©
3. è©æ€§æ¨™è¨» (POS Tagging)
4. åœç”¨è©éæ¿¾
5. æ–·è©çµæœåˆ†æ

**é—œéµæŠ€è¡“**:
```python
import jieba
import jieba.posseg as pseg

# ç²¾ç¢ºæ¨¡å¼æ–·è©
words = jieba.cut("æˆ‘æ„›è‡ªç„¶èªè¨€è™•ç†", cut_all=False)

# è©æ€§æ¨™è¨»
words_with_pos = pseg.cut("æˆ‘æ„›è‡ªç„¶èªè¨€è™•ç†")
for word, flag in words_with_pos:
    print(f"{word}/{flag}")
```

---

### 2. è©é »çµ±è¨ˆ
**æª”å**: `å°ˆæ¡ˆ_æ­Œè©åˆ†æ_è©é »çµ±è¨ˆ_Jieba.ipynb`

**æ ¸å¿ƒå…§å®¹**:
1. æ‰¹é‡è®€å–æ‰€æœ‰æ­Œè©æª”æ¡ˆ
2. çµ±è¨ˆè©é »åˆ†å¸ƒ
3. æ‰¾å‡ºé«˜é »è©å½™
4. ç”Ÿæˆæ–‡å­—é›²
5. è¦–è¦ºåŒ–çµæœ

**é—œéµæŠ€è¡“**:
```python
from collections import Counter
from wordcloud import WordCloud

# è©é »çµ±è¨ˆ
word_freq = Counter(all_words)
top_words = word_freq.most_common(50)

# æ–‡å­—é›²ç”Ÿæˆ
wordcloud = WordCloud(
    font_path='../../shared_resources/fonts/jf-openhuninn-1.0.ttf',
    width=800,
    height=400,
    background_color='white'
).generate_from_frequencies(dict(top_words))
```

---

## ğŸ“ æ•¸æ“šèªªæ˜

### æ­Œè©æ•¸æ“šé›†
- **ä½ç½®**: `datasets/lyrics/æƒ…æ­Œæ­Œè©/`
- **æ•¸é‡**: 290+ å€‹ .txt æª”æ¡ˆ
- **æ ¼å¼**: ç´”æ–‡æœ¬,UTF-8 ç·¨ç¢¼
- **èªè¨€**: ç¹é«”ä¸­æ–‡

### æ•¸æ“šçµæ§‹
```
datasets/lyrics/æƒ…æ­Œæ­Œè©/
â”œâ”€â”€ 0_æ„›ä¹…è¦‹äººå¿ƒ.txt
â”œâ”€â”€ 0_æˆ€.txt
â”œâ”€â”€ 0_æ²ˆç¡çš„æ£®æ—.txt
â”œâ”€â”€ ...
â””â”€â”€ 139_è¦æˆ‘çš„å‘½.txt

æ¯å€‹æª”æ¡ˆåŒ…å«ä¸€é¦–æ­Œçš„å®Œæ•´æ­Œè©
```

### æ•¸æ“šè¼‰å…¥ç¯„ä¾‹
```python
from pathlib import Path

# è®€å–æ‰€æœ‰æ­Œè©
lyrics_path = Path("../../datasets/lyrics/æƒ…æ­Œæ­Œè©")
lyrics_files = list(lyrics_path.glob("*.txt"))

all_lyrics = []
for file in lyrics_files:
    with open(file, 'r', encoding='utf-8') as f:
        lyrics = f.read()
        all_lyrics.append(lyrics)

print(f"âœ… è¼‰å…¥ {len(all_lyrics)} é¦–æ­Œè©")
```

---

## ğŸ¨ é æœŸçµæœ

### è©é »çµ±è¨ˆ TOP 20
```
æ„›     - 1,234 æ¬¡
å¿ƒ     - 987 æ¬¡
ä½      - 856 æ¬¡
æˆ‘     - 745 æ¬¡
ä¸     - 623 æ¬¡
...
```

### æ–‡å­—é›²ç¯„ä¾‹
ç”Ÿæˆç¹é«”ä¸­æ–‡æ–‡å­—é›²,é«˜é »è©ä»¥å¤§å­—é«”é¡¯ç¤º,å±•ç¾æƒ…æ­Œä¸»é¡Œè©å½™ã€‚

### è©æ€§åˆ†å¸ƒ
```
åè© (n):    35%
å‹•è© (v):    28%
å½¢å®¹è© (a):  18%
å‰¯è© (d):    12%
å…¶ä»–:        7%
```

---

## ğŸ”§ å¸¸è¦‹å•é¡Œ

### Q1: ç¹é«”ä¸­æ–‡å­—å‹å•é¡Œ

```python
# å•é¡Œ: æ–‡å­—é›²é¡¯ç¤ºç‚ºæ–¹æ¡†

# è§£æ±ºæ–¹æ¡ˆ: æŒ‡å®šç¹é«”ä¸­æ–‡å­—å‹
wordcloud = WordCloud(
    font_path='../../shared_resources/fonts/jf-openhuninn-1.0.ttf',  # ç¹ä¸­å­—å‹
    width=800,
    height=400,
    background_color='white'
).generate(text)

# ç¢ºèªå­—å‹æª”æ¡ˆå­˜åœ¨
from pathlib import Path
font_path = Path("../../shared_resources/fonts/jf-openhuninn-1.0.ttf")
print(f"å­—å‹å­˜åœ¨: {font_path.exists()}")
```

### Q2: Jieba æ–·è©ä¸æº–ç¢º

```python
# è§£æ±ºæ–¹æ¡ˆ 1: æ·»åŠ è‡ªè¨‚è©å…¸
jieba.load_userdict("custom_dict.txt")

# è§£æ±ºæ–¹æ¡ˆ 2: å¼·åˆ¶åˆ†è©
jieba.suggest_freq('è‡ªç„¶èªè¨€', True)
jieba.suggest_freq('èªè¨€è™•ç†', True)

# è§£æ±ºæ–¹æ¡ˆ 3: ä½¿ç”¨ç¹é«”è©å…¸
jieba.set_dictionary('../../shared_resources/dictionaries/dict.txt.big')
```

### Q3: åœç”¨è©éæ¿¾

```python
# è¼‰å…¥ç¹ä¸­åœç”¨è©è¡¨
with open('../../shared_resources/stopwords/stopwords_zh_tw.txt', 'r') as f:
    stopwords = set(f.read().splitlines())

# éæ¿¾
filtered_words = [w for w in words if w not in stopwords]
```

---

## ğŸ“ˆ æ“´å±•å»ºè­°

### åˆç´šæ“´å±•
- [ ] åˆ†æä¸åŒæ­Œæ‰‹çš„ç”¨è©é¢¨æ ¼
- [ ] æ¯”è¼ƒä¸åŒå¹´ä»£çš„æ­Œè©ç‰¹è‰²
- [ ] çµ±è¨ˆæƒ…æ­Œé«˜é »ä¸»é¡Œè©

### ä¸­ç´šæ“´å±•
- [ ] æ•´åˆæƒ…æ„Ÿåˆ†æ (åˆ¤æ–·æ­Œè©æƒ…ç·’)
- [ ] ä½¿ç”¨ LDA ä¸»é¡Œå»ºæ¨¡
- [ ] å»ºç«‹æ­Œè©æœå°‹å¼•æ“ (TF-IDF)

### é€²éšæ“´å±•
- [ ] è¨“ç·´æ­Œè©ç”Ÿæˆæ¨¡å‹ (LSTM)
- [ ] å»ºç«‹æ­Œè©æ¨è–¦ç³»çµ±
- [ ] å¤šç¶­åº¦åˆ†æå„€è¡¨æ¿

---

## ğŸ† å°ˆæ¡ˆä½œå“é›†å»ºè­°

### å¦‚ä½•å±•ç¤ºæ­¤å°ˆæ¡ˆ

1. **GitHub README** æ‡‰åŒ…å«:
   - å°ˆæ¡ˆèƒŒæ™¯èˆ‡å‹•æ©Ÿ
   - æŠ€è¡“æ¶æ§‹åœ–
   - æ ¸å¿ƒä»£ç¢¼ç‰‡æ®µ
   - è¦–è¦ºåŒ–çµæœæˆªåœ–
   - ä¸»è¦ç™¼ç¾ (Insights)

2. **å±•ç¤ºé‡é»**:
   - "åˆ†æ 290+ é¦–æƒ…æ­Œ,ç™¼ç¾'æ„›'å­—å‡ºç¾ 1,234 æ¬¡"
   - "ä½¿ç”¨ Jieba è™•ç†ç¹é«”ä¸­æ–‡,æº–ç¢ºç‡ XX%"
   - "ç”Ÿæˆäº’å‹•å¼æ–‡å­—é›²,å±•ç¾æƒ…æ­Œä¸»é¡Œè©å½™"

3. **æŠ€è¡“äº®é»**:
   - ä¸­æ–‡ NLP è™•ç†ç¶“é©—
   - å¤§è¦æ¨¡æ–‡æœ¬è™•ç†èƒ½åŠ›
   - æ•¸æ“šè¦–è¦ºåŒ–æŠ€å·§

---

## ğŸ“ æ”¯æ´

- **Jieba æ–‡æª”**: https://github.com/fxsjy/jieba
- **WordCloud æ–‡æª”**: https://amueller.github.io/word_cloud/
- **èª²ç¨‹ç›¸é—œ**: åƒè€ƒ `èª²ç¨‹è³‡æ–™/03_æ–‡æœ¬é è™•ç†/`

---

**å°ˆæ¡ˆç‰ˆæœ¬**: v1.0
**æœ€å¾Œæ›´æ–°**: 2025-10-17
**ç¶­è­·è€…**: iSpan NLP Team
