{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 專案實戰: 聊天機器人系統 (Chatbot with Hugging Face)\n",
    "\n",
    "**專案類型**: 對話系統 - 基於 Transformer 的聊天機器人\n",
    "**難度**: ⭐⭐⭐⭐ 進階\n",
    "**預計時間**: 4-5 小時\n",
    "**技術棧**: Hugging Face Transformers, DialoGPT, Streamlit\n",
    "\n",
    "---\n",
    "\n",
    "## 📚 學習目標\n",
    "\n",
    "完成本專案後,您將能夠:\n",
    "\n",
    "1. ✅ 理解對話系統的核心架構\n",
    "2. ✅ 使用 Hugging Face 對話模型 (DialoGPT, Blenderbot)\n",
    "3. ✅ 實作多輪對話管理\n",
    "4. ✅ 構建互動式聊天介面\n",
    "5. ✅ 部署生產級聊天機器人\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: 對話系統基礎\n",
    "\n",
    "### 1.1 對話系統類型\n",
    "\n",
    "| 類型 | 說明 | 應用場景 | 範例 |\n",
    "|------|------|---------|------|\n",
    "| **檢索式** | 從預定義回覆中選擇 | 客服 FAQ | 選擇最相關答案 |\n",
    "| **生成式** | 動態生成回覆 | 開放對話 | GPT, DialoGPT |\n",
    "| **任務導向** | 完成特定任務 | 訂票、查詢 | 槽填充對話 |\n",
    "| **閒聊型** | 自由對話 | 陪伴機器人 | Blenderbot |\n",
    "\n",
    "### 1.2 本專案架構\n",
    "\n",
    "```\n",
    "用戶輸入\n",
    "    ↓\n",
    "文本預處理\n",
    "    ├── Tokenization\n",
    "    ├── 添加歷史對話\n",
    "    └── 構建 Context\n",
    "    ↓\n",
    "對話模型 (DialoGPT)\n",
    "    ├── Encoder: 理解輸入\n",
    "    ├── Decoder: 生成回覆\n",
    "    └── Attention: 關注重點\n",
    "    ↓\n",
    "後處理\n",
    "    ├── Beam Search 選擇最佳回覆\n",
    "    ├── 過濾不當內容\n",
    "    └── 格式化輸出\n",
    "    ↓\n",
    "機器人回覆\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: 環境準備與套件安裝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安裝必要套件\n",
    "# !pip install transformers torch accelerate streamlit -q\n",
    "\n",
    "# 驗證安裝\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "print(f\"✅ Transformers 版本: {transformers.__version__}\")\n",
    "print(f\"✅ PyTorch 版本: {torch.__version__}\")\n",
    "print(f\"✅ CUDA 可用: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: 基礎聊天機器人實作\n",
    "\n",
    "### 3.1 使用 DialoGPT (Microsoft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# 載入 DialoGPT 模型 (3 種規模可選)\n",
    "model_name = \"microsoft/DialoGPT-medium\"  # small, medium, large\n",
    "\n",
    "print(f\"載入模型: {model_name}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "print(f\"✅ 模型載入完成\")\n",
    "print(f\"   參數量: {model.num_parameters():,}\")\n",
    "print(f\"   詞彙表大小: {tokenizer.vocab_size:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 單輪對話實作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(user_input, chat_history_ids=None, max_length=1000):\n",
    "    \"\"\"\n",
    "    生成聊天機器人回覆\n",
    "\n",
    "    Args:\n",
    "        user_input: 用戶輸入文本\n",
    "        chat_history_ids: 對話歷史 (用於多輪對話)\n",
    "        max_length: 最大生成長度\n",
    "\n",
    "    Returns:\n",
    "        response: 機器人回覆\n",
    "        new_chat_history_ids: 更新的對話歷史\n",
    "    \"\"\"\n",
    "    # 編碼用戶輸入\n",
    "    new_input_ids = tokenizer.encode(\n",
    "        user_input + tokenizer.eos_token,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    # 合併對話歷史\n",
    "    if chat_history_ids is not None:\n",
    "        bot_input_ids = torch.cat([chat_history_ids, new_input_ids], dim=-1)\n",
    "    else:\n",
    "        bot_input_ids = new_input_ids\n",
    "\n",
    "    # 生成回覆\n",
    "    chat_history_ids = model.generate(\n",
    "        bot_input_ids,\n",
    "        max_length=max_length,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        do_sample=True,           # 啟用採樣\n",
    "        top_k=50,                 # Top-K 採樣\n",
    "        top_p=0.95,               # Nucleus 採樣\n",
    "        temperature=0.7           # 控制創造性\n",
    "    )\n",
    "\n",
    "    # 解碼回覆\n",
    "    response = tokenizer.decode(\n",
    "        chat_history_ids[:, bot_input_ids.shape[-1]:][0],\n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "\n",
    "    return response, chat_history_ids\n",
    "\n",
    "\n",
    "# 測試單輪對話\n",
    "user_input = \"Hello! How are you?\"\n",
    "response, history = generate_response(user_input)\n",
    "\n",
    "print(f\"User: {user_input}\")\n",
    "print(f\"Bot: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 多輪對話實作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多輪對話測試\n",
    "chat_history_ids = None\n",
    "conversation = [\n",
    "    \"Hi there!\",\n",
    "    \"What's your favorite programming language?\",\n",
    "    \"Why do you like it?\",\n",
    "    \"Do you know about NLP?\",\n",
    "    \"Goodbye!\"\n",
    "]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"多輪對話示範\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, user_input in enumerate(conversation, 1):\n",
    "    response, chat_history_ids = generate_response(\n",
    "        user_input,\n",
    "        chat_history_ids=chat_history_ids\n",
    "    )\n",
    "\n",
    "    print(f\"\\n第 {i} 輪對話:\")\n",
    "    print(f\"User: {user_input}\")\n",
    "    print(f\"Bot: {response}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: 進階功能實作\n",
    "\n",
    "### 4.1 對話歷史管理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatHistoryManager:\n",
    "    \"\"\"\n",
    "    管理對話歷史，防止記憶體溢出\n",
    "    \"\"\"\n",
    "    def __init__(self, max_history_length=1000):\n",
    "        self.max_history_length = max_history_length\n",
    "        self.chat_history_ids = None\n",
    "\n",
    "    def add_to_history(self, new_input_ids, response_ids):\n",
    "        \"\"\"添加對話到歷史\"\"\"\n",
    "        if self.chat_history_ids is None:\n",
    "            self.chat_history_ids = torch.cat([new_input_ids, response_ids], dim=-1)\n",
    "        else:\n",
    "            self.chat_history_ids = torch.cat(\n",
    "                [self.chat_history_ids, new_input_ids, response_ids],\n",
    "                dim=-1\n",
    "            )\n",
    "\n",
    "        # 限制歷史長度\n",
    "        if self.chat_history_ids.shape[-1] > self.max_history_length:\n",
    "            self.chat_history_ids = self.chat_history_ids[:, -self.max_history_length:]\n",
    "\n",
    "    def get_history(self):\n",
    "        \"\"\"獲取當前歷史\"\"\"\n",
    "        return self.chat_history_ids\n",
    "\n",
    "    def clear_history(self):\n",
    "        \"\"\"清空歷史\"\"\"\n",
    "        self.chat_history_ids = None\n",
    "\n",
    "    def get_conversation_text(self, tokenizer):\n",
    "        \"\"\"獲取對話歷史文本\"\"\"\n",
    "        if self.chat_history_ids is None:\n",
    "            return \"\"\n",
    "        return tokenizer.decode(self.chat_history_ids[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "# 使用範例\n",
    "history_manager = ChatHistoryManager(max_history_length=500)\n",
    "\n",
    "user_input = \"Tell me about Python\"\n",
    "response, history_ids = generate_response(user_input)\n",
    "\n",
    "print(f\"User: {user_input}\")\n",
    "print(f\"Bot: {response}\")\n",
    "print(f\"\\n歷史長度: {history_ids.shape[-1]} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 回覆品質控制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class ResponseFilter:\n",
    "    \"\"\"\n",
    "    過濾不當回覆,提升對話品質\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # 不當詞彙列表 (示範,實際應更完整)\n",
    "        self.blocked_words = set(['badword1', 'badword2'])\n",
    "\n",
    "    def is_valid_response(self, response):\n",
    "        \"\"\"\n",
    "        檢查回覆是否合格\n",
    "        \"\"\"\n",
    "        # 檢查 1: 非空\n",
    "        if not response or len(response.strip()) == 0:\n",
    "            return False, \"空回覆\"\n",
    "\n",
    "        # 檢查 2: 長度合理\n",
    "        if len(response) < 3:\n",
    "            return False, \"回覆過短\"\n",
    "\n",
    "        if len(response) > 500:\n",
    "            return False, \"回覆過長\"\n",
    "\n",
    "        # 檢查 3: 無重複 (避免 \"I I I I...\")\n",
    "        words = response.split()\n",
    "        if len(words) > 3 and len(set(words)) < len(words) * 0.3:\n",
    "            return False, \"過度重複\"\n",
    "\n",
    "        # 檢查 4: 無不當詞彙\n",
    "        if any(word in response.lower() for word in self.blocked_words):\n",
    "            return False, \"包含不當詞彙\"\n",
    "\n",
    "        return True, \"合格\"\n",
    "\n",
    "    def clean_response(self, response):\n",
    "        \"\"\"\n",
    "        清理回覆\n",
    "        \"\"\"\n",
    "        # 移除多餘空白\n",
    "        response = re.sub(r'\\s+', ' ', response).strip()\n",
    "\n",
    "        # 確保句號結尾\n",
    "        if response and response[-1] not in '.!?':\n",
    "            response += '.'\n",
    "\n",
    "        return response\n",
    "\n",
    "\n",
    "# 測試回覆過濾\n",
    "filter = ResponseFilter()\n",
    "\n",
    "test_responses = [\n",
    "    \"I love Python programming!\",\n",
    "    \"I I I I I\",  # 重複\n",
    "    \"\",  # 空回覆\n",
    "    \"Ok\"  # 過短\n",
    "]\n",
    "\n",
    "for resp in test_responses:\n",
    "    is_valid, reason = filter.is_valid_response(resp)\n",
    "    print(f\"回覆: '{resp}'\")\n",
    "    print(f\"  有效: {is_valid} ({reason})\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 完整聊天機器人類別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chatbot:\n",
    "    \"\"\"\n",
    "    完整的聊天機器人系統\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name=\"microsoft/DialoGPT-medium\"):\n",
    "        print(f\"初始化聊天機器人: {model_name}\")\n",
    "\n",
    "        # 載入模型\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "        # 對話歷史\n",
    "        self.chat_history_ids = None\n",
    "\n",
    "        # 回覆過濾器\n",
    "        self.response_filter = ResponseFilter()\n",
    "\n",
    "        print(\"✅ 聊天機器人準備完成!\")\n",
    "\n",
    "    def chat(self, user_input, max_retries=3):\n",
    "        \"\"\"\n",
    "        處理用戶輸入並生成回覆\n",
    "        \"\"\"\n",
    "        # 編碼輸入\n",
    "        new_input_ids = self.tokenizer.encode(\n",
    "            user_input + self.tokenizer.eos_token,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        # 合併歷史\n",
    "        if self.chat_history_ids is not None:\n",
    "            bot_input_ids = torch.cat([self.chat_history_ids, new_input_ids], dim=-1)\n",
    "        else:\n",
    "            bot_input_ids = new_input_ids\n",
    "\n",
    "        # 嘗試生成合格回覆 (最多重試 3 次)\n",
    "        for attempt in range(max_retries):\n",
    "            # 生成回覆\n",
    "            chat_history_ids = self.model.generate(\n",
    "                bot_input_ids,\n",
    "                max_length=1000,\n",
    "                pad_token_id=self.tokenizer.eos_token_id,\n",
    "                do_sample=True,\n",
    "                top_k=50,\n",
    "                top_p=0.95,\n",
    "                temperature=0.7 + (attempt * 0.1)  # 重試時增加溫度\n",
    "            )\n",
    "\n",
    "            # 解碼\n",
    "            response = self.tokenizer.decode(\n",
    "                chat_history_ids[:, bot_input_ids.shape[-1]:][0],\n",
    "                skip_special_tokens=True\n",
    "            )\n",
    "\n",
    "            # 檢查品質\n",
    "            is_valid, reason = self.response_filter.is_valid_response(response)\n",
    "\n",
    "            if is_valid:\n",
    "                # 更新歷史\n",
    "                self.chat_history_ids = chat_history_ids\n",
    "\n",
    "                # 清理回覆\n",
    "                response = self.response_filter.clean_response(response)\n",
    "\n",
    "                return response\n",
    "            else:\n",
    "                print(f\"  嘗試 {attempt+1}: 回覆無效 ({reason})\")\n",
    "\n",
    "        # 所有重試失敗,返回備用回覆\n",
    "        return \"I'm sorry, I didn't quite understand that. Could you rephrase?\"\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"重置對話歷史\"\"\"\n",
    "        self.chat_history_ids = None\n",
    "        print(\"✅ 對話歷史已清空\")\n",
    "\n",
    "    def get_conversation_length(self):\n",
    "        \"\"\"獲取對話長度\"\"\"\n",
    "        if self.chat_history_ids is None:\n",
    "            return 0\n",
    "        return self.chat_history_ids.shape[-1]\n",
    "\n",
    "\n",
    "# 創建聊天機器人實例\n",
    "bot = Chatbot(model_name=\"microsoft/DialoGPT-medium\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 互動式對話介面 (Jupyter Widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "class ChatInterface:\n",
    "    \"\"\"\n",
    "    Jupyter Notebook 聊天介面\n",
    "    \"\"\"\n",
    "    def __init__(self, chatbot):\n",
    "        self.chatbot = chatbot\n",
    "        self.conversation_history = []\n",
    "\n",
    "        # UI 元件\n",
    "        self.output = widgets.Output()\n",
    "        self.user_input = widgets.Text(\n",
    "            placeholder='輸入訊息...',\n",
    "            description='您:',\n",
    "            layout=widgets.Layout(width='80%')\n",
    "        )\n",
    "        self.send_button = widgets.Button(\n",
    "            description='發送',\n",
    "            button_style='primary'\n",
    "        )\n",
    "        self.reset_button = widgets.Button(\n",
    "            description='重置對話',\n",
    "            button_style='warning'\n",
    "        )\n",
    "\n",
    "        # 綁定事件\n",
    "        self.send_button.on_click(self.on_send)\n",
    "        self.reset_button.on_click(self.on_reset)\n",
    "        self.user_input.on_submit(self.on_send)\n",
    "\n",
    "    def on_send(self, b):\n",
    "        \"\"\"處理發送事件\"\"\"\n",
    "        user_message = self.user_input.value.strip()\n",
    "\n",
    "        if not user_message:\n",
    "            return\n",
    "\n",
    "        # 清空輸入框\n",
    "        self.user_input.value = ''\n",
    "\n",
    "        # 生成回覆\n",
    "        with self.output:\n",
    "            print(f\"\\n👤 You: {user_message}\")\n",
    "\n",
    "        bot_response = self.chatbot.chat(user_message)\n",
    "\n",
    "        with self.output:\n",
    "            print(f\"🤖 Bot: {bot_response}\")\n",
    "            print(\"-\" * 60)\n",
    "\n",
    "        # 記錄對話\n",
    "        self.conversation_history.append({\n",
    "            'user': user_message,\n",
    "            'bot': bot_response\n",
    "        })\n",
    "\n",
    "    def on_reset(self, b):\n",
    "        \"\"\"重置對話\"\"\"\n",
    "        self.chatbot.reset()\n",
    "        self.conversation_history = []\n",
    "\n",
    "        with self.output:\n",
    "            clear_output()\n",
    "            print(\"✅ 對話已重置\")\n",
    "\n",
    "    def display(self):\n",
    "        \"\"\"顯示聊天介面\"\"\"\n",
    "        input_box = widgets.HBox([self.user_input, self.send_button, self.reset_button])\n",
    "        chat_box = widgets.VBox([self.output, input_box])\n",
    "\n",
    "        display(HTML(\"<h3>💬 聊天機器人介面</h3>\"))\n",
    "        display(chat_box)\n",
    "\n",
    "\n",
    "# 啟動聊天介面\n",
    "chat_interface = ChatInterface(bot)\n",
    "chat_interface.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: 使用 Blenderbot (Meta)\n",
    "\n",
    "### 5.1 Blenderbot vs DialoGPT 對比\n",
    "\n",
    "| 模型 | 開發者 | 規模 | 特色 | 適用場景 |\n",
    "|------|--------|------|------|----------|\n",
    "| **DialoGPT** | Microsoft | 117M-762M | 基於 Reddit 訓練 | 開放閒聊 |\n",
    "| **Blenderbot** | Meta (Facebook) | 90M-9.4B | 多技能整合 | 知識問答+閒聊 |\n",
    "| **DialoGPT** | 生成速度快 | 較輕量 | 英文對話 |\n",
    "| **Blenderbot** | 知識豐富 | 較重量 | 多語言支持 |\n",
    "\n",
    "### 5.2 使用 Blenderbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BlenderbotTokenizer, BlenderbotForConditionalGeneration\n",
    "\n",
    "# 載入 Blenderbot\n",
    "blenderbot_model_name = \"facebook/blenderbot-400M-distill\"\n",
    "\n",
    "print(f\"載入 Blenderbot: {blenderbot_model_name}\")\n",
    "blenderbot_tokenizer = BlenderbotTokenizer.from_pretrained(blenderbot_model_name)\n",
    "blenderbot_model = BlenderbotForConditionalGeneration.from_pretrained(blenderbot_model_name)\n",
    "\n",
    "print(\"✅ Blenderbot 載入完成\")\n",
    "\n",
    "\n",
    "def chat_with_blenderbot(user_input):\n",
    "    \"\"\"\n",
    "    使用 Blenderbot 對話\n",
    "    \"\"\"\n",
    "    inputs = blenderbot_tokenizer([user_input], return_tensors=\"pt\")\n",
    "\n",
    "    reply_ids = blenderbot_model.generate(\n",
    "        **inputs,\n",
    "        max_length=128,\n",
    "        num_beams=5,              # Beam Search\n",
    "        early_stopping=True,\n",
    "        no_repeat_ngram_size=3   # 避免重複\n",
    "    )\n",
    "\n",
    "    response = blenderbot_tokenizer.decode(\n",
    "        reply_ids[0],\n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "# 測試 Blenderbot\n",
    "test_inputs = [\n",
    "    \"What is natural language processing?\",\n",
    "    \"Tell me about Python programming.\",\n",
    "    \"What's your favorite book?\"\n",
    "]\n",
    "\n",
    "print(\"🤖 Blenderbot 對話測試\\n\")\n",
    "for inp in test_inputs:\n",
    "    response = chat_with_blenderbot(inp)\n",
    "    print(f\"User: {inp}\")\n",
    "    print(f\"Bot: {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: 特殊功能擴展\n",
    "\n",
    "### 6.1 情緒識別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 載入情感分析器\n",
    "emotion_classifier = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"j-hartmann/emotion-english-distilroberta-base\"\n",
    ")\n",
    "\n",
    "def detect_emotion(text):\n",
    "    \"\"\"\n",
    "    檢測用戶情緒\n",
    "    \"\"\"\n",
    "    result = emotion_classifier(text)[0]\n",
    "    return result['label'], result['score']\n",
    "\n",
    "def generate_empathetic_response(user_input, emotion):\n",
    "    \"\"\"\n",
    "    根據用戶情緒調整回覆風格\n",
    "    \"\"\"\n",
    "    # 情緒前綴模板\n",
    "    emotion_templates = {\n",
    "        'joy': \"That's wonderful! \",\n",
    "        'sadness': \"I'm sorry to hear that. \",\n",
    "        'anger': \"I understand your frustration. \",\n",
    "        'fear': \"Don't worry, \",\n",
    "        'surprise': \"Oh! \"\n",
    "    }\n",
    "\n",
    "    # 獲取基本回覆\n",
    "    base_response = bot.chat(user_input)\n",
    "\n",
    "    # 添加情緒前綴\n",
    "    prefix = emotion_templates.get(emotion.lower(), \"\")\n",
    "    empathetic_response = prefix + base_response\n",
    "\n",
    "    return empathetic_response\n",
    "\n",
    "\n",
    "# 測試情緒感知對話\n",
    "test_messages = [\n",
    "    \"I just got a promotion at work!\",\n",
    "    \"I'm feeling really sad today.\",\n",
    "    \"This is so frustrating!\"\n",
    "]\n",
    "\n",
    "print(\"😊 情緒感知對話測試\\n\")\n",
    "for msg in test_messages:\n",
    "    emotion, confidence = detect_emotion(msg)\n",
    "    response = generate_empathetic_response(msg, emotion)\n",
    "\n",
    "    print(f\"User: {msg}\")\n",
    "    print(f\"  檢測情緒: {emotion} ({confidence:.2%})\")\n",
    "    print(f\"Bot: {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 意圖識別與槽填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 簡單的意圖識別\n",
    "intent_classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"facebook/bart-large-mnli\"\n",
    ")\n",
    "\n",
    "INTENTS = [\n",
    "    \"greeting\",\n",
    "    \"weather_query\",\n",
    "    \"restaurant_search\",\n",
    "    \"general_chat\",\n",
    "    \"goodbye\"\n",
    "]\n",
    "\n",
    "def detect_intent(user_input):\n",
    "    \"\"\"\n",
    "    識別用戶意圖\n",
    "    \"\"\"\n",
    "    result = intent_classifier(user_input, INTENTS)\n",
    "    return result['labels'][0], result['scores'][0]\n",
    "\n",
    "def handle_intent(user_input, intent):\n",
    "    \"\"\"\n",
    "    根據意圖處理請求\n",
    "    \"\"\"\n",
    "    if intent == \"greeting\":\n",
    "        return \"Hello! How can I help you today?\"\n",
    "\n",
    "    elif intent == \"weather_query\":\n",
    "        # 實際應串接天氣 API\n",
    "        return \"I'm sorry, I can't check the weather right now. Try asking me about something else!\"\n",
    "\n",
    "    elif intent == \"goodbye\":\n",
    "        return \"Goodbye! Have a great day!\"\n",
    "\n",
    "    else:\n",
    "        # 一般閒聊,使用對話模型\n",
    "        return bot.chat(user_input)\n",
    "\n",
    "\n",
    "# 測試意圖識別\n",
    "test_inputs = [\n",
    "    \"Hi there!\",\n",
    "    \"What's the weather like today?\",\n",
    "    \"Can you recommend a good restaurant?\",\n",
    "    \"Tell me a joke.\",\n",
    "    \"Goodbye!\"\n",
    "]\n",
    "\n",
    "print(\"🎯 意圖識別測試\\n\")\n",
    "for inp in test_inputs:\n",
    "    intent, confidence = detect_intent(inp)\n",
    "    response = handle_intent(inp, intent)\n",
    "\n",
    "    print(f\"User: {inp}\")\n",
    "    print(f\"  意圖: {intent} ({confidence:.2%})\")\n",
    "    print(f\"Bot: {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: 生產部署 (Streamlit App)\n",
    "\n",
    "### 7.1 Streamlit 聊天應用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile chatbot_app.py\n",
    "# chatbot_app.py - Streamlit 聊天機器人應用\n",
    "\n",
    "import streamlit as st\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "@st.cache_resource\n",
    "def load_chatbot_model():\n",
    "    \"\"\"載入模型 (僅載入一次)\"\"\"\n",
    "    model_name = \"microsoft/DialoGPT-medium\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    return tokenizer, model\n",
    "\n",
    "def generate_response(user_input, chat_history_ids, tokenizer, model):\n",
    "    \"\"\"生成回覆\"\"\"\n",
    "    new_input_ids = tokenizer.encode(\n",
    "        user_input + tokenizer.eos_token,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    if chat_history_ids is not None:\n",
    "        bot_input_ids = torch.cat([chat_history_ids, new_input_ids], dim=-1)\n",
    "    else:\n",
    "        bot_input_ids = new_input_ids\n",
    "\n",
    "    chat_history_ids = model.generate(\n",
    "        bot_input_ids,\n",
    "        max_length=1000,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        do_sample=True,\n",
    "        top_p=0.95,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    response = tokenizer.decode(\n",
    "        chat_history_ids[:, bot_input_ids.shape[-1]:][0],\n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "\n",
    "    return response, chat_history_ids\n",
    "\n",
    "# Streamlit UI\n",
    "st.title(\"💬 AI 聊天機器人\")\n",
    "st.caption(\"Powered by DialoGPT (Microsoft)\")\n",
    "\n",
    "# 載入模型\n",
    "tokenizer, model = load_chatbot_model()\n",
    "\n",
    "# 初始化對話歷史 (使用 session state)\n",
    "if \"chat_history_ids\" not in st.session_state:\n",
    "    st.session_state.chat_history_ids = None\n",
    "\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "# 顯示對話歷史\n",
    "for message in st.session_state.messages:\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.write(message[\"content\"])\n",
    "\n",
    "# 用戶輸入\n",
    "if user_input := st.chat_input(\"輸入訊息...\"):\n",
    "    # 顯示用戶訊息\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.write(user_input)\n",
    "\n",
    "    # 生成回覆\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        with st.spinner(\"思考中...\"):\n",
    "            response, st.session_state.chat_history_ids = generate_response(\n",
    "                user_input,\n",
    "                st.session_state.chat_history_ids,\n",
    "                tokenizer,\n",
    "                model\n",
    "            )\n",
    "            st.write(response)\n",
    "\n",
    "    # 記錄機器人回覆\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "# 側邊欄: 重置對話\n",
    "if st.sidebar.button(\"🔄 重置對話\"):\n",
    "    st.session_state.chat_history_ids = None\n",
    "    st.session_state.messages = []\n",
    "    st.rerun()\n",
    "\n",
    "# 側邊欄: 對話統計\n",
    "st.sidebar.markdown(\"### 📊 對話統計\")\n",
    "st.sidebar.metric(\"對話輪數\", len(st.session_state.messages) // 2)\n",
    "\n",
    "if st.session_state.chat_history_ids is not None:\n",
    "    st.sidebar.metric(\"Token 數\", st.session_state.chat_history_ids.shape[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 運行 Streamlit App\n",
    "\n",
    "```bash\n",
    "# 安裝 Streamlit\n",
    "poetry add streamlit\n",
    "\n",
    "# 運行應用\n",
    "poetry run streamlit run chatbot_app.py\n",
    "\n",
    "# 瀏覽器自動開啟: http://localhost:8501\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: 進階優化\n",
    "\n",
    "### 8.1 加入記憶功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryEnhancedChatbot:\n",
    "    \"\"\"\n",
    "    帶記憶功能的聊天機器人\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name=\"microsoft/DialoGPT-medium\"):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "        self.chat_history_ids = None\n",
    "\n",
    "        # 用戶資訊記憶\n",
    "        self.user_info = {}\n",
    "\n",
    "    def extract_user_info(self, user_input):\n",
    "        \"\"\"\n",
    "        從對話中提取用戶資訊\n",
    "        \"\"\"\n",
    "        # 簡單範例: 提取名字\n",
    "        if \"my name is\" in user_input.lower():\n",
    "            name = user_input.lower().split(\"my name is\")[-1].strip().split()[0]\n",
    "            self.user_info['name'] = name.capitalize()\n",
    "            print(f\"  📝 記住: 用戶名字是 {self.user_info['name']}\")\n",
    "\n",
    "        # 提取其他資訊 (興趣、位置等)\n",
    "        # 實際應用可使用 NER\n",
    "\n",
    "    def personalize_response(self, response):\n",
    "        \"\"\"\n",
    "        個性化回覆\n",
    "        \"\"\"\n",
    "        if 'name' in self.user_info:\n",
    "            # 在回覆中使用用戶名字\n",
    "            response = response.replace(\"you\", self.user_info['name'], 1)\n",
    "\n",
    "        return response\n",
    "\n",
    "    def chat(self, user_input):\n",
    "        \"\"\"處理對話並記憶資訊\"\"\"\n",
    "        # 提取用戶資訊\n",
    "        self.extract_user_info(user_input)\n",
    "\n",
    "        # 生成回覆 (使用前面定義的函數)\n",
    "        response, self.chat_history_ids = generate_response(\n",
    "            user_input,\n",
    "            self.chat_history_ids\n",
    "        )\n",
    "\n",
    "        # 個性化回覆\n",
    "        response = self.personalize_response(response)\n",
    "\n",
    "        return response\n",
    "\n",
    "\n",
    "# 測試記憶功能\n",
    "memory_bot = MemoryEnhancedChatbot()\n",
    "\n",
    "dialogue = [\n",
    "    \"Hi! My name is Alice.\",\n",
    "    \"What's your favorite color?\",\n",
    "    \"Do you remember my name?\"\n",
    "]\n",
    "\n",
    "print(\"🧠 記憶功能測試\\n\")\n",
    "for inp in dialogue:\n",
    "    response = memory_bot.chat(inp)\n",
    "    print(f\"User: {inp}\")\n",
    "    print(f\"Bot: {response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: 評估與測試\n",
    "\n",
    "### 9.1 對話品質評估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_response_quality(response, user_input):\n",
    "    \"\"\"\n",
    "    評估回覆品質\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "\n",
    "    # 1. 長度合理性\n",
    "    metrics['length'] = len(response.split())\n",
    "    metrics['length_score'] = 1.0 if 5 <= metrics['length'] <= 50 else 0.5\n",
    "\n",
    "    # 2. 多樣性 (不重複)\n",
    "    words = response.split()\n",
    "    unique_ratio = len(set(words)) / len(words) if words else 0\n",
    "    metrics['diversity_score'] = unique_ratio\n",
    "\n",
    "    # 3. 相關性 (簡單檢查是否包含用戶輸入關鍵詞)\n",
    "    user_keywords = set(user_input.lower().split())\n",
    "    response_keywords = set(response.lower().split())\n",
    "    overlap = len(user_keywords & response_keywords)\n",
    "    metrics['relevance_score'] = min(overlap / len(user_keywords), 1.0) if user_keywords else 0\n",
    "\n",
    "    # 4. 整體分數\n",
    "    metrics['overall_score'] = (\n",
    "        metrics['length_score'] * 0.3 +\n",
    "        metrics['diversity_score'] * 0.4 +\n",
    "        metrics['relevance_score'] * 0.3\n",
    "    )\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "# 評估範例\n",
    "user_inp = \"What do you think about artificial intelligence?\"\n",
    "bot_resp = bot.chat(user_inp)\n",
    "\n",
    "metrics = evaluate_response_quality(bot_resp, user_inp)\n",
    "\n",
    "print(f\"User: {user_inp}\")\n",
    "print(f\"Bot: {bot_resp}\\n\")\n",
    "print(\"品質評估:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"  {metric}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 10: 總結與擴展\n",
    "\n",
    "### ✅ 本專案完成內容\n",
    "\n",
    "1. **基礎對話系統**\n",
    "   - DialoGPT 單輪/多輪對話\n",
    "   - Blenderbot 整合\n",
    "   - 對話歷史管理\n",
    "\n",
    "2. **進階功能**\n",
    "   - 回覆品質過濾\n",
    "   - 情緒識別\n",
    "   - 意圖分類\n",
    "   - 用戶資訊記憶\n",
    "\n",
    "3. **生產部署**\n",
    "   - Streamlit 互動介面\n",
    "   - 模型快取優化\n",
    "   - 評估指標\n",
    "\n",
    "### 🚀 進階擴展方向\n",
    "\n",
    "#### 功能擴展\n",
    "- [ ] 整合知識庫 (RAG)\n",
    "- [ ] 多語言支持\n",
    "- [ ] 語音輸入/輸出\n",
    "- [ ] 個性化對話風格\n",
    "\n",
    "#### 技術優化\n",
    "- [ ] 使用更大模型 (GPT-3.5, LLaMA)\n",
    "- [ ] 模型量化加速\n",
    "- [ ] 多模態對話 (圖片+文字)\n",
    "- [ ] 強化學習微調 (RLHF)\n",
    "\n",
    "#### 應用場景\n",
    "- [ ] 客服機器人\n",
    "- [ ] 教學助手\n",
    "- [ ] 心理諮詢機器人\n",
    "- [ ] 程式碼助手\n",
    "\n",
    "### 📚 延伸閱讀\n",
    "\n",
    "- [DialoGPT 論文](https://arxiv.org/abs/1911.00536)\n",
    "- [Blenderbot 論文](https://arxiv.org/abs/2004.13637)\n",
    "- [對話系統綜述](https://arxiv.org/abs/2203.08745)\n",
    "- [Streamlit 文檔](https://docs.streamlit.io/)\n",
    "\n",
    "---\n",
    "\n",
    "**專案版本**: v1.0\n",
    "**建立日期**: 2025-10-17\n",
    "**作者**: iSpan NLP Team\n",
    "**授權**: MIT License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
