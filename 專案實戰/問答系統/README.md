# æ™ºèƒ½å•ç­”ç³»çµ± (RAG)

**å°ˆæ¡ˆé¡å‹**: æª¢ç´¢å¢å¼·ç”Ÿæˆ (Retrieval-Augmented Generation)
**é›£åº¦**: â­â­â­â­â­ å°ˆå®¶ç´š
**é è¨ˆæ™‚é–“**: 5-6 å°æ™‚
**æŠ€è¡“æ£§**: RAG, FAISS, LangChain, Sentence Transformers

---

## ğŸ“‹ å°ˆæ¡ˆæ¦‚è¿°

æœ¬å°ˆæ¡ˆå¯¦ä½œ**ç”Ÿç”¢ç´šæ™ºèƒ½å•ç­”ç³»çµ±**,åŸºæ–¼ RAG (æª¢ç´¢å¢å¼·ç”Ÿæˆ) æ¶æ§‹,å±•ç¤º:

1. å‘é‡æ•¸æ“šåº«æ§‹å»º (FAISS)
2. èªç¾©æª¢ç´¢æŠ€è¡“
3. æª¢ç´¢èˆ‡ç”Ÿæˆæ•´åˆ
4. æ··åˆæª¢ç´¢å„ªåŒ–
5. FastAPI æœå‹™éƒ¨ç½²

**å•†æ¥­æ‡‰ç”¨**:
- ä¼æ¥­çŸ¥è­˜ç®¡ç†ç³»çµ±
- æ™ºèƒ½å®¢æœåŠ©æ‰‹
- æ–‡æª”æœå°‹å¼•æ“
- æ³•å¾‹/é†«ç™‚å•ç­”ç³»çµ±

---

## ğŸ¯ æ ¸å¿ƒæŠ€è¡“

### RAG æ¶æ§‹å„ªå‹¢

| å„ªå‹¢ | èªªæ˜ | å•†æ¥­åƒ¹å€¼ |
|------|------|----------|
| **å‹•æ…‹çŸ¥è­˜** | ç„¡éœ€é‡æ–°è¨“ç·´æ¨¡å‹ | é™ä½ç¶­è­·æˆæœ¬ |
| **å¯è¿½æº¯æ€§** | å¼•ç”¨å…·é«”ä¾†æº | æå‡å¯ä¿¡åº¦ |
| **å¯æ“´å±•æ€§** | è¼•é¬†æ·»åŠ æ–°çŸ¥è­˜ | å¿«é€Ÿé©æ‡‰æ¥­å‹™è®ŠåŒ– |
| **æº–ç¢ºæ€§** | åŸºæ–¼å¯¦éš›æ–‡æª”å›ç­” | æ¸›å°‘å¹»è¦º (Hallucination) |

### æŠ€è¡“æ£§èªªæ˜

| çµ„ä»¶ | æŠ€è¡“ | ä½œç”¨ |
|------|------|------|
| **Embedding** | Sentence-BERT | æ–‡æœ¬å‘é‡åŒ– |
| **Vector DB** | FAISS | é«˜æ•ˆç›¸ä¼¼åº¦æª¢ç´¢ |
| **QA Model** | DistilBERT-SQuAD | ç­”æ¡ˆæŠ½å– |
| **Orchestration** | LangChain | æµç¨‹ç·¨æ’ |
| **Deployment** | FastAPI | API æœå‹™ |

---

## ğŸš€ å¿«é€Ÿé–‹å§‹

### å®‰è£ä¾è³´

```bash
# æ ¸å¿ƒå¥—ä»¶
poetry add transformers sentence-transformers faiss-cpu

# LangChain ç”Ÿæ…‹
poetry add langchain langchain-community

# API æœå‹™ (é¸ç”¨)
poetry add fastapi uvicorn

# ç¶²é çˆ¬èŸ² (é¸ç”¨)
poetry add beautifulsoup4 requests
```

### é‹è¡Œ Notebook

```bash
poetry run jupyter notebook
# é–‹å•Ÿ: å°ˆæ¡ˆ_å•ç­”ç³»çµ±_RAGæª¢ç´¢å¢å¼·ç”Ÿæˆ.ipynb
```

### é‹è¡Œ API æœå‹™

```bash
# å•Ÿå‹• FastAPI
poetry run uvicorn qa_api:app --reload

# è¨ªå• API æ–‡æª”: http://localhost:8000/docs
```

---

## ğŸ§® æ ¸å¿ƒæµç¨‹

### éšæ®µ 1: çŸ¥è­˜åº«æ§‹å»º

```python
# 1. æº–å‚™æ–‡æª”
documents = [
    "Document 1 content...",
    "Document 2 content...",
    # ...
]

# 2. å‘é‡åŒ–
from sentence_transformers import SentenceTransformer

model = SentenceTransformer("all-MiniLM-L6-v2")
embeddings = model.encode(documents)

# 3. å»ºç«‹ç´¢å¼•
import faiss

index = faiss.IndexFlatL2(embeddings.shape[1])
index.add(embeddings)
```

### éšæ®µ 2: æª¢ç´¢

```python
# æŸ¥è©¢å‘é‡åŒ–
query = "What is BERT?"
query_embedding = model.encode([query])

# æª¢ç´¢ Top-K
distances, indices = index.search(query_embedding, k=3)

# ç²å–ç›¸é—œæ–‡æª”
relevant_docs = [documents[i] for i in indices[0]]
```

### éšæ®µ 3: ç­”æ¡ˆç”Ÿæˆ

```python
from transformers import pipeline

qa = pipeline("question-answering")

# åˆä½µæª¢ç´¢æ–‡æª”ä½œç‚º context
context = " ".join(relevant_docs)

# æŠ½å–ç­”æ¡ˆ
answer = qa(question=query, context=context)
```

---

## ğŸ“ çŸ¥è­˜åº«ä¾†æº

### æ”¯æ´çš„æ–‡æª”æ ¼å¼

- **ç´”æ–‡æœ¬**: .txt
- **Markdown**: .md
- **PDF**: ä½¿ç”¨ PyPDF2 è§£æ
- **ç¶²é **: BeautifulSoup çˆ¬å–
- **JSON/CSV**: çµæ§‹åŒ–æ•¸æ“š

### è¼‰å…¥ç¯„ä¾‹

```python
# å¾ç›®éŒ„è¼‰å…¥æ‰€æœ‰ .md æ–‡æª”
from pathlib import Path

docs_dir = Path("../../docs")
md_files = docs_dir.glob("*.md")

documents = []
for file in md_files:
    with open(file, 'r', encoding='utf-8') as f:
        documents.append(f.read())
```

---

## ğŸ¨ é æœŸæ•ˆæœ

### å•ç­”ç¯„ä¾‹

```
Q: What is Natural Language Processing?
A: Natural Language Processing (NLP) is a field of AI that focuses on
   the interaction between computers and human language.
   Confidence: 95.7%
   Source: [Document 1]

Q: Who developed BERT?
A: Google
   Confidence: 92.3%
   Source: [Document 3]

Q: Explain the attention mechanism.
A: The attention mechanism allows models to focus on relevant parts of
   the input when generating output.
   Confidence: 88.9%
   Source: [Document 9]
```

### æ€§èƒ½æŒ‡æ¨™

- **æª¢ç´¢é€Ÿåº¦**: < 50ms (FAISS)
- **å•ç­”å»¶é²**: < 200ms (DistilBERT)
- **æº–ç¢ºç‡**: 85-95% (å–æ±ºæ–¼çŸ¥è­˜åº«å“è³ª)
- **è¦†è“‹ç‡**: å–æ±ºæ–¼çŸ¥è­˜åº«å®Œæ•´æ€§

---

## ğŸ”§ å¸¸è¦‹å•é¡Œ

### Q1: FAISS å®‰è£å¤±æ•—

```bash
# CPU ç‰ˆæœ¬
pip install faiss-cpu

# GPU ç‰ˆæœ¬ (éœ€è¦ CUDA)
pip install faiss-gpu
```

### Q2: æª¢ç´¢çµæœä¸ç›¸é—œ

```python
# èª¿æ•´æª¢ç´¢åƒæ•¸
results = qa_system.retrieve(question, top_k=5)  # å¢åŠ  top_k

# ä½¿ç”¨æ··åˆæª¢ç´¢
hybrid_retriever = HybridRetriever(
    documents,
    semantic_weight=0.7  # èª¿æ•´æ¬Šé‡
)
```

### Q3: ç­”æ¡ˆä¿¡å¿ƒåº¦ä½

```python
# å¢åŠ æª¢ç´¢æ–‡æª”æ•¸
top_k = 5  # å¾ 3 å¢åŠ åˆ° 5

# ä½¿ç”¨é‡æ’åº
reranked = rerank_documents(query, retrieved_docs, top_k=3)

# èª¿æ•´ä¿¡å¿ƒåº¦é–¾å€¼
min_confidence = 0.2  # é™ä½é–¾å€¼
```

---

## ğŸ“ˆ é€²éšå„ªåŒ–

### 1. ä½¿ç”¨ Chroma å‘é‡æ•¸æ“šåº«

```python
from langchain.vectorstores import Chroma

# å»ºç«‹æŒä¹…åŒ–å‘é‡æ•¸æ“šåº«
vectorstore = Chroma.from_texts(
    texts=documents,
    embedding=embeddings,
    persist_directory=\"./chroma_db\"
)

# æŒä¹…åŒ–
vectorstore.persist()

# è¼‰å…¥
vectorstore = Chroma(
    persist_directory=\"./chroma_db\",
    embedding_function=embeddings
)
```

### 2. æ•´åˆ LLaMA/GPT ç”Ÿæˆ

```python
# ä½¿ç”¨ OpenAI GPT (éœ€è¦ API key)
from langchain.llms import OpenAI

llm = OpenAI(temperature=0, openai_api_key=\"your-key\")

qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=vectorstore.as_retriever()
)
```

### 3. å°è©±å¼å•ç­”

```python
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory

# å¸¶è¨˜æ†¶çš„å°è©±å¼å•ç­”
memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "conversational_qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "# å¤šè¼ªå°è©±\n",
    "conversational_qa({\"question\": \"What is BERT?\"})\n",
    "conversational_qa({\"question\": \"Who developed it?\"})  # ç†è§£ \"it\" æŒ‡ BERT\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ† ä½œå“é›†å±•ç¤º\n",
    "\n",
    "### æŠ€è¡“äº®é»\n",
    "\n",
    "1. **å‰æ²¿æŠ€è¡“**: \"å¯¦ä½œ RAG æ¶æ§‹,çµåˆæª¢ç´¢èˆ‡ç”Ÿæˆ\"\n",
    "2. **é«˜æ•ˆæª¢ç´¢**: \"ä½¿ç”¨ FAISS å¯¦ç¾æ¯«ç§’ç´šèªç¾©æª¢ç´¢\"\n",
    "3. **å¯æ“´å±•**: \"æ”¯æ´å‹•æ…‹çŸ¥è­˜åº«æ›´æ–°,ç„¡éœ€é‡æ–°è¨“ç·´\"\n",
    "4. **ç”Ÿç”¢å°±ç·’**: \"FastAPI æœå‹™,å®Œæ•´ API æ–‡æª”\"\n",
    "\n",
    "### Demo å»ºè­°\n",
    "\n",
    "- å±•ç¤ºä¸åŒé ˜åŸŸçš„å•ç­” (æŠ€è¡“ã€å¸¸è­˜ã€ç‰¹å®šé ˜åŸŸ)\n",
    "- å°æ¯”æœ‰/ç„¡ RAG çš„å›ç­”å“è³ª\n",
    "- å±•ç¤ºå³æ™‚æ·»åŠ æ–°çŸ¥è­˜çš„èƒ½åŠ›\n",
    "- æ€§èƒ½åŸºæº–æ¸¬è©¦å ±å‘Š\n",
    "\n",
    "---\n",
    "\n",
    "**å°ˆæ¡ˆç‰ˆæœ¬**: v1.0\n",
    "**Notebooks**: 1\n",
    "**æœ€å¾Œæ›´æ–°**: 2025-10-17\n",
    "**ç¶­è­·è€…**: iSpan NLP Team\n",
    "**æˆæ¬Š**: MIT License\n",
    "