# Natural Language Processing (NDAK18000U)
## Course at the University of Copenhagen

Materials from this interactive book are used throughout the Natural Language Processing course at the Department of Computer Science, University of Copenhagen. The official course description can be found [here](https://kurser.ku.dk/course/ndak18000u). Materials covered each week are listed below. The course schedule and materials are tentative and subject to minor changes. Most reading material is from [Speech and Language Processing by Jurafsky & Martin](https://web.stanford.edu/~jurafsky/slp3).

Note: Github has issues displaying the python notebook downloaded from colab(2025.9.18). If you have trouble with this, you can download the python notebook and view them in your colab or other editor.

<table>
   <tr>
      <th>Week</th>
      <th>Reading (before lecture)</th>
      <th>Lecture (Tuesday)</th>
      <th>Lab (Friday &amp; Monday)</th>
      <th>Lab notebook</th>
   </tr>
   <tr>
      <td>36</td>
      <td> <a href='https://web.stanford.edu/~jurafsky/slp3/2.pdf'>Chapter 2 up to end of 2.5</a><br> <a href='https://web.stanford.edu/~jurafsky/slp3/4.pdf'>Chapter 4 up to end of 4.5</a><br> <a href='https://web.stanford.edu/~jurafsky/slp3/5.pdf'>Chapter 5 up to end of 5.6</a><br> </td>
      <td>2. Sep. 2025:<br> Course Logistics (<a href='chapters/course_logistics.ipynb'>slides</a>)<br> Introduction to NLP (<a href='chapters/intro_short.ipynb'>slides</a>)<br> Tokenisation &amp; Sentence Splitting (<a href='chapters/tokenization.ipynb'>notes</a>, <a href='chapters/tokenization_slides.ipynb'>slides</a>, <a href='exercises/tokenization.ipynb'>exercises</a>)<br> Text Classification (<a href='chapters/doc_classify_slides_short.ipynb'>slides</a>)<br> </td>
      <td>5. &amp; 8. Sep. 2025:<br> Jupyter notebook setup, introduction to <a href='https://colab.research.google.com/'>Colab</a><br> Introduction to <a href='https://pytorch.org/tutorials/'>PyTorch</a><br> Project group arrangements<br> Questions about the course project<br> </td>
      <td><a href='labs/notebooks_2025/lab_1.ipynb'>lab 1</a></td>
   </tr>
   <tr>
      <td>37</td>
      <td> <a href='https://web.stanford.edu/~jurafsky/slp3/3.pdf'>Chapter 3 up to end of 3.5</a><br> <a href='https://web.stanford.edu/~jurafsky/slp3/6.pdf'>Chapter 6 up to end of 6.4</a><br> <a href='https://web.stanford.edu/~jurafsky/slp3/7.pdf'>Chapter 7 up to end of 7.5</a><br> </td>
      <td>9. Sep. 2025:<br> Language Modelling (<a href='chapters/language_models_slides.ipynb'>slides</a>)<br> Word Embeddings (<a href='chapters/dl-representations_simple.ipynb'>slides</a>)<br> </td>
      <td>12. &amp; 15. Sep. 2025:<br> Word representations and sentiment classification<br> Project help<br> </td>
      <td><a href='labs/notebooks_2025/lab_2.ipynb'>lab 2</a></td>
   </tr>
   <tr>
      <td>38</td>
      <td> <a href='https://web.stanford.edu/~jurafsky/slp3/7.pdf'>Chapter 7 up to end of 7.6</a><br> <a href='https://web.stanford.edu/~jurafsky/slp3/8.pdf'>Chapter 8 up to end of 8.7</a> </td>
      <td>16. Sep. 2025:<br> Recurrent Neural Networks (<a href='chapters/rnn_slides_ucph.ipynb'>slides</a>)<br> Neural Language Models (<a href='chapters/dl-representations_contextual.ipynb'>slides</a>)<br> </td>
      <td>19. &amp; 22. Sep. 2025:<br> Error analysis and explainability<br> Project help<br> </td>
      <td><a href='labs/notebooks_2025/lab_3.ipynb'>lab 3</a></td>
   </tr>
   <tr>
      <td>39</td>
      <td> <a href='https://web.stanford.edu/~jurafsky/slp3/8.pdf'>Chapter 8 up to end of 8.8</a><br> <a href='https://web.stanford.edu/~jurafsky/slp3/10.pdf'>Chapter 10 up to end of 10.2</a><br> <a href='https://web.stanford.edu/~jurafsky/slp3/11.pdf'>Chapter 11</a> </td>
      <td>23. Sep. 2025:<br> Attention (<a href='chapters/attention_slides2.ipynb'>slides</a>)<br> Transformers (<a href='chapters/dl-representations_contextual_transformers.ipynb'>slides</a>)<br> </td>
      <td>26. &amp; 29. Sep. 2025:<br> Language Models with <a href='https://huggingface.co/course/chapter1'>Transformers</a> and RNNs<br> Project help<br> </td>
      <td><a href='labs/notebooks_2025/lab_4.ipynb'>lab 4</a></td>
   </tr>
   <tr>
      <td>40</td>
      <td> <a href='https://web.stanford.edu/~jurafsky/slp3/17.pdf'>Chapter 17 up to end of 17.3</a><br> <a href='https://web.stanford.edu/~jurafsky/slp3/19.pdf'>Chapter 19 up to end of 19.2</a> </td>
      <td>30. Sep. 2025:<br> Sequence Labelling (<a href='chapters/sequence_labeling_slides.ipynb'>slides</a>)<br> Parsing (<a href='chapters/dependency_parsing_slides_active.ipynb'>slides</a>)<br> </td>
      <td>3. &amp; 6. Oct. 2025:<br> Sequence labelling and beam search<br> Project help<br> </td>
      <td><a href='labs/notebooks_2025/lab_5.ipynb'>lab 5</a></td>
   </tr>
   <tr>
      <td>41</td>
      <td> <a href='https://web.stanford.edu/~jurafsky/slp3/14.pdf'>Chapter 14</a><br> <a href='https://web.stanford.edu/~jurafsky/slp3/20.pdf'>Chapter 20</a> </td>
      <td>7. Oct. 2025:<br> Information Extraction (<a href='chapters/information_extraction_slides.ipynb'>slides</a>)<br> Question Answering (<a href='chapters/question_answering_slides.ipynb'>slides</a>)<br> </td>
      <td>10. &amp; 20. Oct. 2025:<br> In-depth look at Transformers and Multilingual QA<br> Project help<br> </td>
      <td><a href='labs/notebooks_2025/lab_6.ipynb'>lab 6</a></td>
   </tr>
   <tr>
      <td>43</td>
      <td> <a href='https://web.stanford.edu/~jurafsky/slp3/12.pdf'>Chapter 12</a><br> <a href='https://web.stanford.edu/~jurafsky/slp3/13.pdf'>Chapter 13</a><br> </td>
      <td>21. Oct. 2025:<br> Machine Translation (<a href='chapters/nmt_slides_active.ipynb'>slides</a>)<br> Transfer Learning (<a href='chapters/xling_transfer_learning_slides.ipynb'>slides</a>)<br> </td>
      <td>24. &amp; 27. Oct. 2025: Project help.</td>
      <td></td>
   </tr>
   <tr>
      <td>44</td>
      <td> <a href='https://web.stanford.edu/~jurafsky/slp3/9.pdf'>Chapter 9 up to end of 9.3</a><br> <a href='https://arxiv.org/abs/2508.16982'> Chalkidis, 2025</a></td>
      <td>28. Oct. 2025:<br> Post-training: Instruction Tuning & Alignment (<a href='chapters/post_training_llms_slides.pdf'>slides</a>)<br> Sociotechnical Challenges of Alignment (TBA) </td>
      <td>31. Oct. 2025: Project help.</td>
      <td></td>
   </tr>
</table>
The easiest way to view the course content is via the static [nbviewer](https://nbviewer.jupyter.org/github/coastalcph/nlp-course/blob/master/overview.ipynb). 
To be able to make changes to the book and render it dynamically, see the [installation instructions](INSTALL.md).
