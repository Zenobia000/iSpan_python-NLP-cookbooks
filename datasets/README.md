# iSpan Python NLP Cookbooks v2 - æ•¸æ“šé›†è³‡æºç›®éŒ„

æœ¬ç›®éŒ„çµ±ä¸€ç®¡ç† NLP èª²ç¨‹æ‰€éœ€çš„æ‰€æœ‰æ•¸æ“šé›†è³‡æºã€‚

---

## ğŸ“‚ ç›®éŒ„çµæ§‹

```
datasets/
â”œâ”€â”€ README.md                    # æœ¬èªªæ˜æ–‡æª”
â”œâ”€â”€ honglou.txt                  # ç´…æ¨“å¤¢å…¨æ–‡ (ä¸­æ–‡èªæ–™)
â”œâ”€â”€ glove/                       # GloVe è©å‘é‡
â”‚   â”œâ”€â”€ glove.6B.50d.txt
â”‚   â”œâ”€â”€ glove.6B.100d.txt
â”‚   â”œâ”€â”€ glove.6B.200d.txt
â”‚   â””â”€â”€ glove.6B.300d.txt
â”œâ”€â”€ sms_spam/                    # SMS åƒåœ¾ç°¡è¨Šæ•¸æ“šé›†
â”œâ”€â”€ twitter_sentiment/           # Twitter æƒ…æ„Ÿåˆ†ææ•¸æ“šé›†
â”œâ”€â”€ food_delivery/               # å¤–é€å¹³å°æ•¸æ“šé›†
â”œâ”€â”€ movielens/                   # MovieLens æ¨è–¦ç³»çµ±æ•¸æ“šé›†
â”œâ”€â”€ google_reviews/              # Google å•†å®¶è©•è«– (å°ˆæ¡ˆè‡ªå»º)
â””â”€â”€ lyrics/                      # æ­Œè©æ•¸æ“šé›†
    â””â”€â”€ æƒ…æ­Œæ­Œè©/                # 290+ é¦–æƒ…æ­Œæ­Œè© (å°ˆæ¡ˆè‡ªå»º)
```

---

## ğŸ“¥ æ•¸æ“šé›†ä¸‹è¼‰æ–¹å¼

### æ–¹æ³• 1: ä½¿ç”¨çµ±ä¸€ä¸‹è¼‰è…³æœ¬ (æ¨è–¦)

```bash
# ä¸‹è¼‰æ‰€æœ‰æ•¸æ“šé›†
python scripts/download_datasets.py --all

# åªä¸‹è¼‰ Keras å…§å»ºæ•¸æ“šé›†
python scripts/download_datasets.py --keras

# åªä¸‹è¼‰ Hugging Face æ•¸æ“šé›†
python scripts/download_datasets.py --huggingface

# åªä¸‹è¼‰ä¸­æ–‡èªæ–™
python scripts/download_datasets.py --chinese

# æŸ¥çœ‹å®Œæ•´é¸é …
python scripts/download_datasets.py --help
```

### æ–¹æ³• 2: æ‰‹å‹•ä¸‹è¼‰

è©³è¦‹å„ç« ç¯€ notebook å…§çš„æ•¸æ“šè¼‰å…¥æŒ‡ä»¤ã€‚

---

## ğŸ“Š æ•¸æ“šé›†æ¸…å–®

### å…§å»ºæ•¸æ“šé›† (è‡ªå‹•ä¸‹è¼‰)

é€™äº›æ•¸æ“šé›†æœƒåœ¨é¦–æ¬¡ä½¿ç”¨æ™‚è‡ªå‹•ä¸‹è¼‰åˆ°ç³»çµ±å¿«å–ç›®éŒ„:

| æ•¸æ“šé›† | ä¾†æº | å¤§å° | å¿«å–ä½ç½® | ç”¨é€”ç« ç¯€ |
|--------|------|------|----------|----------|
| IMDB | Keras | 80MB | `~/.keras/datasets/` | CH05, CH06, CH07 |
| Reuters | Keras | 2MB | `~/.keras/datasets/` | CH06 |
| 20 Newsgroups | sklearn | 18MB | `~/scikit_learn_data/` | CH04 |
| AG News | Hugging Face | 30MB | `~/.cache/huggingface/` | CH08 |
| CoNLL-2003 | Hugging Face | 3MB | `~/.cache/huggingface/` | CH08 |
| SQuAD 2.0 | Hugging Face | 50MB | `~/.cache/huggingface/` | å°ˆæ¡ˆå¯¦æˆ° |

### éœ€æ‰‹å‹•ä¸‹è¼‰æ•¸æ“šé›†

| æ•¸æ“šé›† | ä¾†æº | å¤§å° | ä¸‹è¼‰æ–¹å¼ | ç”¨é€”ç« ç¯€ |
|--------|------|------|----------|----------|
| **GloVe 6B** | Stanford NLP | 822MB | `python scripts/download_datasets.py --glove` | CH07 |
| **ç´…æ¨“å¤¢å…¨æ–‡** | GitHub | 1MB | `python scripts/download_datasets.py --chinese` | CH03 |
| **Twitter Sentiment** | Kaggle | 238MB | `python scripts/download_datasets.py --kaggle` | CH08 |
| **Food Delivery** | Kaggle | 50MB | `python scripts/download_datasets.py --kaggle` | å°ˆæ¡ˆå¯¦æˆ° |
| **MovieLens** | GroupLens | 1MB | `python scripts/download_datasets.py --movielens` | å°ˆæ¡ˆå¯¦æˆ° |
| **CNN/DailyMail** | Hugging Face | 1.4GB | ä½¿ç”¨æ™‚æ‰‹å‹•è¼‰å…¥ `load_dataset('cnn_dailymail')` | CH08 |

### å°ˆæ¡ˆè‡ªå»ºæ•¸æ“šé›† (å·²å­˜åœ¨)

| æ•¸æ“šé›† | ä½ç½® | å¤§å° | èªªæ˜ |
|--------|------|------|------|
| **æƒ…æ­Œæ­Œè©** | `datasets/lyrics/æƒ…æ­Œæ­Œè©/` | 5MB | 290+ é¦–ç¹é«”ä¸­æ–‡æƒ…æ­Œ (ç”¨æ–¼ CH06 åºåˆ—ç”Ÿæˆ) |
| **Google å•†å®¶è©•è«–** | `datasets/google_reviews/` | 20MB | çœŸå¯¦å•†å®¶è©•è«–æ•¸æ“š (ç”¨æ–¼ CH08 å°ˆæ¡ˆå¯¦æˆ°) |

---

## ğŸ”§ Kaggle æ•¸æ“šé›†è¨­å®š

ä½¿ç”¨ Kaggle æ•¸æ“šé›†éœ€è¦å…ˆè¨­å®š API Token:

### æ­¥é©Ÿ 1: ç²å– API Token

1. å‰å¾€ [https://www.kaggle.com/account](https://www.kaggle.com/account)
2. é»æ“Š "Create New API Token"
3. ä¸‹è¼‰ `kaggle.json` æª”æ¡ˆ

### æ­¥é©Ÿ 2: è¨­å®š Token

**Windows**:
```bash
# å‰µå»º .kaggle ç›®éŒ„
mkdir %USERPROFILE%\.kaggle

# è¤‡è£½ kaggle.json åˆ°è©²ç›®éŒ„
copy kaggle.json %USERPROFILE%\.kaggle\

# ç¢ºèªæ¬Šé™
```

**macOS/Linux**:
```bash
# å‰µå»º .kaggle ç›®éŒ„
mkdir -p ~/.kaggle

# è¤‡è£½ kaggle.json
cp kaggle.json ~/.kaggle/

# è¨­å®šæ¬Šé™
chmod 600 ~/.kaggle/kaggle.json
```

### æ­¥é©Ÿ 3: å®‰è£ Kaggle API

```bash
pip install kaggle
```

### æ­¥é©Ÿ 4: ä¸‹è¼‰æ•¸æ“šé›†

```bash
python scripts/download_datasets.py --kaggle
```

---

## ğŸ“ ä½¿ç”¨ç¯„ä¾‹

### è¼‰å…¥ IMDB æ•¸æ“šé›† (Keras)

```python
from tensorflow import keras

(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=10000)
print(f"è¨“ç·´æ¨£æœ¬: {len(x_train)}, æ¸¬è©¦æ¨£æœ¬: {len(x_test)}")
```

### è¼‰å…¥ AG News æ•¸æ“šé›† (Hugging Face)

```python
from datasets import load_dataset

ag_news = load_dataset("ag_news")
print(f"è¨“ç·´é›†: {len(ag_news['train'])} æ–°è")
print(f"é¡åˆ¥: {ag_news['train'].features['label'].names}")
```

### è¼‰å…¥ç´…æ¨“å¤¢èªæ–™ (æœ¬åœ°æª”æ¡ˆ)

```python
from pathlib import Path

corpus_path = Path("datasets/honglou.txt")
text = corpus_path.read_text(encoding="utf-8")
print(f"ç´…æ¨“å¤¢å…¨æ–‡å­—æ•¸: {len(text)}")
```

### è¼‰å…¥æƒ…æ­Œæ­Œè© (æœ¬åœ°ç›®éŒ„)

```python
from pathlib import Path

lyrics_dir = Path("datasets/lyrics/æƒ…æ­Œæ­Œè©/")
lyrics_files = list(lyrics_dir.glob("*.txt"))

all_lyrics = []
for file in lyrics_files:
    with open(file, 'r', encoding='utf-8') as f:
        all_lyrics.append(f.read())

print(f"è¼‰å…¥ {len(all_lyrics)} é¦–æƒ…æ­Œæ­Œè©")
```

### è¼‰å…¥ GloVe è©å‘é‡

```python
import numpy as np
from pathlib import Path

glove_path = Path("datasets/glove/glove.6B.100d.txt")
embeddings_index = {}

with open(glove_path, encoding='utf-8') as f:
    for line in f:
        values = line.split()
        word = values[0]
        coefs = np.asarray(values[1:], dtype='float32')
        embeddings_index[word] = coefs

print(f"è¼‰å…¥ {len(embeddings_index)} å€‹è©å‘é‡")
```

---

## âš–ï¸ æ•¸æ“šé›†æˆæ¬Šè²æ˜

**é‡è¦æé†’**: è«‹éµå®ˆå„æ•¸æ“šé›†çš„æˆæ¬Šæ¢æ¬¾

| æ•¸æ“šé›† | æˆæ¬Šé¡å‹ | å•†æ¥­ä½¿ç”¨ | æ•™å­¸ä½¿ç”¨ | é€£çµ |
|--------|---------|---------|---------|------|
| IMDB | Academic Use | âŒ | âœ… | [Stanford](http://ai.stanford.edu/~amaas/data/sentiment/) |
| AG News | CC BY-SA 3.0 | âœ… | âœ… | [Hugging Face](https://huggingface.co/datasets/ag_news) |
| CoNLL-2003 | Research Use | âŒ | âœ… | [ACL](https://www.clips.uantwerpen.be/conll2003/ner/) |
| SQuAD 2.0 | CC BY-SA 4.0 | âœ… | âœ… | [Stanford](https://rajpurkar.github.io/SQuAD-explorer/) |
| GloVe | Public Domain | âœ… | âœ… | [Stanford NLP](https://nlp.stanford.edu/projects/glove/) |
| 20 Newsgroups | Public Domain | âœ… | âœ… | [UCI ML](https://archive.ics.uci.edu/ml/datasets/Twenty+Newsgroups) |
| CNN/DailyMail | Research Use | âŒ | âœ… | [Papers with Code](https://paperswithcode.com/dataset/cnn-daily-mail-1) |
| MovieLens | Research Use | âŒ | âœ… | [GroupLens](https://grouplens.org/datasets/movielens/) |
| Twitter Sentiment140 | Research Use | âŒ | âœ… | [Kaggle](https://www.kaggle.com/datasets/kazanova/sentiment140) |

**æœ¬å°ˆæ¡ˆè²æ˜**: æ‰€æœ‰æ•¸æ“šé›†åƒ…ç”¨æ–¼æ•™å­¸èˆ‡å­¸è¡“ç ”ç©¶ç›®çš„ï¼Œä¸å¾—ç”¨æ–¼å•†æ¥­ç”¨é€”ã€‚

---

## ğŸš¨ å•é¡Œæ’è§£

### å•é¡Œ 1: Keras æ•¸æ“šé›†ä¸‹è¼‰å¤±æ•—

**è§£æ±ºæ–¹æ¡ˆ**:
```python
# æ‰‹å‹•æŒ‡å®šé¡åƒç«™
import os
os.environ['KERAS_BACKEND'] = 'tensorflow'

# æˆ–ä½¿ç”¨ä»£ç†
os.environ['HTTP_PROXY'] = 'http://proxy.example.com:8080'
os.environ['HTTPS_PROXY'] = 'http://proxy.example.com:8080'
```

### å•é¡Œ 2: Hugging Face æ•¸æ“šé›†ä¸‹è¼‰ç·©æ…¢

**è§£æ±ºæ–¹æ¡ˆ**:
```python
# ä½¿ç”¨åœ‹å…§é¡åƒ (æ¸…è¯å¤§å­¸)
export HF_ENDPOINT=https://hf-mirror.com

# æˆ–åœ¨ä»£ç¢¼ä¸­è¨­å®š
import os
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
```

### å•é¡Œ 3: Kaggle API ç„¡æ³•ä½¿ç”¨

**æª¢æŸ¥æ¸…å–®**:
1. ç¢ºèª `kaggle.json` ä½æ–¼ `~/.kaggle/` (Linux/Mac) æˆ– `%USERPROFILE%\.kaggle\` (Windows)
2. ç¢ºèªæª”æ¡ˆæ¬Šé™ (Linux/Mac éœ€è¦ `chmod 600 ~/.kaggle/kaggle.json`)
3. ç¢ºèªå·²å®‰è£ `kaggle` å¥—ä»¶: `pip install kaggle`

### å•é¡Œ 4: ç£ç¢Ÿç©ºé–“ä¸è¶³

**ç¸½æ•¸æ“šé‡ä¼°ç®—**:
- **å¿…å‚™æ•¸æ“š** (P0): ~500MB (IMDB, Reuters, AG News, CoNLL-2003, ç´…æ¨“å¤¢, æƒ…æ­Œæ­Œè©)
- **æ¨è–¦æ•¸æ“š** (P1): ~1.2GB (+ GloVe)
- **å®Œæ•´æ•¸æ“š** (P2): ~3GB (+ CNN/DailyMail, Twitter Sentiment, MovieLens)

**å»ºè­°**:
- æ ¹æ“šéœ€æ±‚é¸æ“‡æ€§ä¸‹è¼‰
- ä½¿ç”¨é›²ç«¯ç’°å¢ƒ (Google Colab, Kaggle Notebooks)
- å®šæœŸæ¸…ç†ä¸å†ä½¿ç”¨çš„æ•¸æ“šé›†

---

## ğŸ“š ç›¸é—œæ–‡æª”

- **å®Œæ•´æ•¸æ“šè¦åŠƒ**: [docs/16_wbs_development_plan_template.md](../docs/16_wbs_development_plan_template.md) - Section 6
- **ä¸‹è¼‰è…³æœ¬**: [scripts/download_datasets.py](../scripts/download_datasets.py)
- **èª²ç¨‹è¦åŠƒ**: [COURSE_PLAN.md](../COURSE_PLAN.md)
- **å°ˆæ¡ˆçµæ§‹**: [PROJECT_STRUCTURE.md](../PROJECT_STRUCTURE.md)

---

## ğŸ¤ è²¢ç»

å¦‚æœæ‚¨æœ‰æ¨è–¦çš„å„ªè³ª NLP æ•¸æ“šé›†ï¼Œæ­¡è¿æå‡ºå»ºè­°:

1. Fork æœ¬å°ˆæ¡ˆ
2. æ–°å¢æ•¸æ“šé›†è³‡è¨Šåˆ°æœ¬æ–‡æª”
3. æ›´æ–°ä¸‹è¼‰è…³æœ¬ (å¦‚é©ç”¨)
4. æäº¤ Pull Request

---

**æœ€å¾Œæ›´æ–°**: 2025-10-17
**ç¶­è­·è€…**: iSpan NLP Team
**ç‰ˆæœ¬**: v1.0
