{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CH09-03: é€²éšå­¸ç¿’è·¯å¾‘\n",
    "\n",
    "**èª²ç¨‹ç›®æ¨™:**\n",
    "- å»ºç«‹å®Œæ•´çš„ NLP å·¥ç¨‹å¸«æŠ€èƒ½æ¨¹\n",
    "- æŒæ¡ç³»çµ±åŒ–çš„å­¸ç¿’è·¯å¾‘èˆ‡æ–¹æ³•\n",
    "- ç²å–å„ªè³ªå­¸ç¿’è³‡æºæ¨è–¦ (æ›¸ç±/èª²ç¨‹/è«–æ–‡)\n",
    "- äº†è§£é–‹æºå°ˆæ¡ˆåƒèˆ‡èˆ‡å¯¦æˆ°ç·´ç¿’æ–¹å‘\n",
    "\n",
    "**å­¸ç¿’æ™‚é–“:** ç´„ 90 åˆ†é˜\n",
    "\n",
    "**å‰ç½®çŸ¥è­˜:**\n",
    "- å·²å®Œæˆ CH01-08 èª²ç¨‹\n",
    "- å…·å‚™ NLP åŸºç¤å¯¦ä½œç¶“é©—\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š ç›®éŒ„\n",
    "\n",
    "1. [NLP å·¥ç¨‹å¸«æŠ€èƒ½æ¨¹](#1)\n",
    "2. [å¾åˆå­¸è€…åˆ°å°ˆå®¶çš„å­¸ç¿’è·¯ç·šåœ–](#2)\n",
    "3. [æ¨è–¦æ›¸ç±æ¸…å–®](#3)\n",
    "4. [å„ªè³ªèª²ç¨‹èˆ‡æ•™å­¸è³‡æº](#4)\n",
    "5. [å¿…è®€è«–æ–‡åˆ—è¡¨](#5)\n",
    "6. [é–‹æºå°ˆæ¡ˆæ¨è–¦èˆ‡åƒèˆ‡æŒ‡å—](#6)\n",
    "7. [å¯¦æˆ°ç·´ç¿’å¹³å°èˆ‡ç«¶è³½](#7)\n",
    "8. [æŒçºŒå­¸ç¿’èˆ‡çŸ¥è­˜ç®¡ç†](#8)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç’°å¢ƒè¨­å®šèˆ‡å¥—ä»¶å°å…¥\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import HTML, display, Markdown\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# è¨­å®šä¸­æ–‡é¡¯ç¤º\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'SimHei', 'Arial Unicode MS']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# è¨­å®šé¡¯ç¤ºé¢¨æ ¼\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_palette('Set2')\n",
    "\n",
    "print(\"âœ… ç’°å¢ƒè¨­å®šå®Œæˆ\")\n",
    "print(f\"NumPy ç‰ˆæœ¬: {np.__version__}\")\n",
    "print(f\"Pandas ç‰ˆæœ¬: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1. NLP å·¥ç¨‹å¸«æŠ€èƒ½æ¨¹\n",
    "\n",
    "### 1.1 æŠ€èƒ½é«”ç³»å…¨æ™¯åœ–\n",
    "\n",
    "NLP å·¥ç¨‹å¸«éœ€è¦æŒæ¡çš„æŠ€èƒ½å¯åˆ†ç‚ºäº”å¤§é ˜åŸŸ:\n",
    "\n",
    "#### 1. åŸºç¤æŠ€èƒ½ (Foundation)\n",
    "- **æ•¸å­¸åŸºç¤:** ç·šæ€§ä»£æ•¸ã€æ¦‚ç‡çµ±è¨ˆã€å¾®ç©åˆ†\n",
    "- **ç·¨ç¨‹èƒ½åŠ›:** Pythonã€Linuxã€Git\n",
    "- **ç®—æ³•èˆ‡æ•¸æ“šçµæ§‹:** æ’åºã€æœç´¢ã€å‹•æ…‹è¦åŠƒ\n",
    "\n",
    "#### 2. æ©Ÿå™¨å­¸ç¿’ (Machine Learning)\n",
    "- **å‚³çµ± ML:** ç·šæ€§å›æ­¸ã€æ¨¸ç´ è²è‘‰æ–¯ã€SVM\n",
    "- **æ·±åº¦å­¸ç¿’:** MLPã€CNNã€RNNã€Transformer\n",
    "- **å„ªåŒ–ç®—æ³•:** SGDã€Adamã€å­¸ç¿’ç‡èª¿åº¦\n",
    "\n",
    "#### 3. NLP æ ¸å¿ƒ (NLP Core)\n",
    "- **æ–‡æœ¬é è™•ç†:** åˆ†è©ã€è©å¹¹æå–ã€æ­£å‰‡è¡¨é”å¼\n",
    "- **æ–‡æœ¬è¡¨ç¤º:** BoWã€TF-IDFã€Word2Vecã€BERT\n",
    "- **NLP ä»»å‹™:** åˆ†é¡ã€NERã€ç”Ÿæˆã€å•ç­”\n",
    "\n",
    "#### 4. å·¥ç¨‹èƒ½åŠ› (Engineering)\n",
    "- **æ·±åº¦å­¸ç¿’æ¡†æ¶:** PyTorchã€TensorFlow\n",
    "- **NLP å·¥å…·åº«:** Hugging Faceã€spaCyã€NLTK\n",
    "- **æ¨¡å‹éƒ¨ç½²:** Dockerã€FastAPIã€TorchServe\n",
    "- **æ€§èƒ½å„ªåŒ–:** æ¨¡å‹å£“ç¸®ã€é‡åŒ–ã€åˆ†å¸ƒå¼è¨“ç·´\n",
    "\n",
    "#### 5. é ˜åŸŸçŸ¥è­˜ (Domain Knowledge)\n",
    "- **è¡Œæ¥­æ‡‰ç”¨:** é‡‘èã€é†«ç™‚ã€æ³•å¾‹ã€æ•™è‚²\n",
    "- **å¤šæ¨¡æ…‹:** è¦–è¦º+èªè¨€ã€èªéŸ³+èªè¨€\n",
    "- **å‰æ²¿æŠ€è¡“:** LLMã€Prompt Engineeringã€RLHF\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP å·¥ç¨‹å¸«æŠ€èƒ½æ¨¹è¦–è¦ºåŒ–\n",
    "skill_tree_data = {\n",
    "    'æŠ€èƒ½é ˜åŸŸ': [\n",
    "        'æ•¸å­¸åŸºç¤', 'ç·¨ç¨‹èƒ½åŠ›', 'ç®—æ³•èˆ‡æ•¸æ“šçµæ§‹',\n",
    "        'å‚³çµ±æ©Ÿå™¨å­¸ç¿’', 'æ·±åº¦å­¸ç¿’', 'å„ªåŒ–ç®—æ³•',\n",
    "        'æ–‡æœ¬é è™•ç†', 'æ–‡æœ¬è¡¨ç¤º', 'NLP ä»»å‹™',\n",
    "        'æ·±åº¦å­¸ç¿’æ¡†æ¶', 'NLP å·¥å…·åº«', 'æ¨¡å‹éƒ¨ç½²',\n",
    "        'è¡Œæ¥­æ‡‰ç”¨', 'å¤šæ¨¡æ…‹', 'å‰æ²¿æŠ€è¡“'\n",
    "    ],\n",
    "    'é¡åˆ¥': [\n",
    "        'åŸºç¤æŠ€èƒ½', 'åŸºç¤æŠ€èƒ½', 'åŸºç¤æŠ€èƒ½',\n",
    "        'æ©Ÿå™¨å­¸ç¿’', 'æ©Ÿå™¨å­¸ç¿’', 'æ©Ÿå™¨å­¸ç¿’',\n",
    "        'NLP æ ¸å¿ƒ', 'NLP æ ¸å¿ƒ', 'NLP æ ¸å¿ƒ',\n",
    "        'å·¥ç¨‹èƒ½åŠ›', 'å·¥ç¨‹èƒ½åŠ›', 'å·¥ç¨‹èƒ½åŠ›',\n",
    "        'é ˜åŸŸçŸ¥è­˜', 'é ˜åŸŸçŸ¥è­˜', 'é ˜åŸŸçŸ¥è­˜'\n",
    "    ],\n",
    "    'é‡è¦æ€§': [9, 10, 7, 7, 10, 8, 10, 10, 10, 9, 10, 8, 7, 8, 9],\n",
    "    'é›£åº¦': [8, 6, 7, 6, 8, 7, 5, 7, 8, 6, 5, 7, 6, 8, 9]\n",
    "}\n",
    "\n",
    "df_skills = pd.DataFrame(skill_tree_data)\n",
    "\n",
    "# ç¹ªè£½æŠ€èƒ½æ¨¹ç†±åŠ›åœ–\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "# å‰µå»ºçŸ©é™£ (é‡è¦æ€§ vs é›£åº¦)\n",
    "pivot_data = df_skills.pivot_table(index='æŠ€èƒ½é ˜åŸŸ', columns='é¡åˆ¥', values='é‡è¦æ€§', aggfunc='mean')\n",
    "\n",
    "# ç¹ªè£½æ•£é»åœ–\n",
    "categories = df_skills['é¡åˆ¥'].unique()\n",
    "colors_cat = {'åŸºç¤æŠ€èƒ½': 'coral', 'æ©Ÿå™¨å­¸ç¿’': 'skyblue', 'NLP æ ¸å¿ƒ': 'lightgreen', \n",
    "              'å·¥ç¨‹èƒ½åŠ›': 'gold', 'é ˜åŸŸçŸ¥è­˜': 'plum'}\n",
    "\n",
    "for category in categories:\n",
    "    subset = df_skills[df_skills['é¡åˆ¥'] == category]\n",
    "    ax.scatter(subset['é›£åº¦'], subset['é‡è¦æ€§'], \n",
    "               s=300, alpha=0.7, label=category, \n",
    "               color=colors_cat[category], edgecolors='black', linewidth=2)\n",
    "\n",
    "# æ·»åŠ æŠ€èƒ½æ¨™ç±¤\n",
    "for i, row in df_skills.iterrows():\n",
    "    ax.annotate(row['æŠ€èƒ½é ˜åŸŸ'], (row['é›£åº¦'], row['é‡è¦æ€§']), \n",
    "                textcoords=\"offset points\", xytext=(0,-15), \n",
    "                ha='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('é›£åº¦ (1-10)', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('é‡è¦æ€§ (1-10)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('NLP å·¥ç¨‹å¸«æŠ€èƒ½æ¨¹: é‡è¦æ€§ vs é›£åº¦', fontsize=16, fontweight='bold')\n",
    "ax.set_xlim(4, 10)\n",
    "ax.set_ylim(6, 11)\n",
    "ax.legend(loc='lower right', fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# æ¨™è¨˜é«˜å„ªå…ˆç´šå€åŸŸ\n",
    "ax.axhline(y=9, color='red', linestyle='--', linewidth=1.5, alpha=0.5, label='é«˜é‡è¦æ€§ç·š')\n",
    "ax.axvline(x=7, color='blue', linestyle='--', linewidth=1.5, alpha=0.5, label='ä¸­ç­‰é›£åº¦ç·š')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ æŠ€èƒ½å­¸ç¿’å„ªå…ˆç´š:\")\n",
    "print(\"  ğŸ”´ é«˜å„ªå…ˆç´š (é‡è¦æ€§â‰¥9, å¿…é ˆæŒæ¡):\")\n",
    "high_priority = df_skills[df_skills['é‡è¦æ€§'] >= 9]['æŠ€èƒ½é ˜åŸŸ'].tolist()\n",
    "for skill in high_priority:\n",
    "    print(f\"    - {skill}\")\n",
    "print(\"\\n  ğŸŸ¡ ä¸­å„ªå…ˆç´š (é‡è¦æ€§ 7-8, å»ºè­°æŒæ¡):\")\n",
    "mid_priority = df_skills[(df_skills['é‡è¦æ€§'] >= 7) & (df_skills['é‡è¦æ€§'] < 9)]['æŠ€èƒ½é ˜åŸŸ'].tolist()\n",
    "for skill in mid_priority:\n",
    "    print(f\"    - {skill}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 æŠ€èƒ½è©³ç´°åˆ†è§£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŠ€èƒ½è©³ç´°åˆ†è§£è¡¨\n",
    "skill_details = {\n",
    "    'é¡åˆ¥': ['åŸºç¤æŠ€èƒ½', 'åŸºç¤æŠ€èƒ½', 'åŸºç¤æŠ€èƒ½',\n",
    "            'æ©Ÿå™¨å­¸ç¿’', 'æ©Ÿå™¨å­¸ç¿’', 'æ©Ÿå™¨å­¸ç¿’',\n",
    "            'NLP æ ¸å¿ƒ', 'NLP æ ¸å¿ƒ', 'NLP æ ¸å¿ƒ',\n",
    "            'å·¥ç¨‹èƒ½åŠ›', 'å·¥ç¨‹èƒ½åŠ›', 'å·¥ç¨‹èƒ½åŠ›'],\n",
    "    'æŠ€èƒ½': ['æ•¸å­¸åŸºç¤', 'ç·¨ç¨‹èƒ½åŠ›', 'ç®—æ³•æ•¸æ“šçµæ§‹',\n",
    "            'å‚³çµ± ML', 'æ·±åº¦å­¸ç¿’', 'å„ªåŒ–ç®—æ³•',\n",
    "            'æ–‡æœ¬é è™•ç†', 'æ–‡æœ¬è¡¨ç¤º', 'NLP ä»»å‹™',\n",
    "            'æ·±åº¦å­¸ç¿’æ¡†æ¶', 'NLP å·¥å…·åº«', 'æ¨¡å‹éƒ¨ç½²'],\n",
    "    'å…·é«”å…§å®¹': [\n",
    "        'ç·šæ€§ä»£æ•¸, æ¦‚ç‡çµ±è¨ˆ, å¾®ç©åˆ†',\n",
    "        'Python, NumPy, Pandas, Linux, Git',\n",
    "        'æ’åº/æœç´¢, å‹•æ…‹è¦åŠƒ, åœ–è«–',\n",
    "        'ç·šæ€§å›æ­¸, æ¨¸ç´ è²è‘‰æ–¯, SVM, æ±ºç­–æ¨¹',\n",
    "        'MLP, CNN, RNN, LSTM, Transformer',\n",
    "        'SGD, Adam, å­¸ç¿’ç‡èª¿åº¦, æ­£å‰‡åŒ–',\n",
    "        'åˆ†è©, è©å¹¹æå–, æ­£å‰‡è¡¨é”å¼, æ¸…æ´—',\n",
    "        'BoW, TF-IDF, Word2Vec, BERT Embeddings',\n",
    "        'åˆ†é¡, NER, ç”Ÿæˆ, ç¿»è­¯, å•ç­”',\n",
    "        'PyTorch, TensorFlow, JAX',\n",
    "        'Hugging Face, spaCy, NLTK, Stanza',\n",
    "        'Docker, FastAPI, TorchServe, ONNX'\n",
    "    ],\n",
    "    'å­¸ç¿’æ™‚é–“': ['3-6 å€‹æœˆ', '2-4 å€‹æœˆ', '1-3 å€‹æœˆ',\n",
    "                '2-3 å€‹æœˆ', '3-6 å€‹æœˆ', '1-2 å€‹æœˆ',\n",
    "                '1-2 å€‹æœˆ', '2-3 å€‹æœˆ', '3-6 å€‹æœˆ',\n",
    "                '2-4 å€‹æœˆ', '1-2 å€‹æœˆ', '2-3 å€‹æœˆ'],\n",
    "    'æ¨è–¦è³‡æº': [\n",
    "        'ã€Šç·šæ€§ä»£æ•¸åŠå…¶æ‡‰ç”¨ã€‹, 3Blue1Brown',\n",
    "        'Pythonå®˜æ–¹æ•™ç¨‹, LeetCode',\n",
    "        'ã€Šç®—æ³•å°è«–ã€‹, LeetCode',\n",
    "        'ã€Šæ©Ÿå™¨å­¸ç¿’ã€‹å‘¨å¿—è¯, Coursera ML',\n",
    "        'CS231n, ã€Šæ·±åº¦å­¸ç¿’ã€‹èŠ±æ›¸',\n",
    "        'CS231n, Adamè«–æ–‡',\n",
    "        'NLTKæ•™ç¨‹, spaCyæ•™ç¨‹',\n",
    "        'Word2Vecè«–æ–‡, BERTè«–æ–‡',\n",
    "        'CS224N, Hugging Face Course',\n",
    "        'PyTorchå®˜æ–¹æ•™ç¨‹',\n",
    "        'Hugging Faceå®˜æ–¹æ–‡æª”',\n",
    "        'Dockeræ•™ç¨‹, FastAPIæ–‡æª”'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_details = pd.DataFrame(skill_details)\n",
    "\n",
    "display(HTML(\"<h3>ğŸ“‹ NLP å·¥ç¨‹å¸«æŠ€èƒ½è©³ç´°åˆ†è§£è¡¨</h3>\"))\n",
    "display(df_details.style.hide(axis='index').set_properties(**{'text-align': 'left', 'font-size': '10pt'}))\n",
    "\n",
    "print(\"\\nğŸ¯ å­¸ç¿’å»ºè­°:\")\n",
    "print(\"  1. å¾ªåºæ¼¸é€²: åŸºç¤æŠ€èƒ½ â†’ æ©Ÿå™¨å­¸ç¿’ â†’ NLP æ ¸å¿ƒ â†’ å·¥ç¨‹èƒ½åŠ›\")\n",
    "print(\"  2. ç†è«–èˆ‡å¯¦è¸ä¸¦é‡: æ¯å€‹æŠ€èƒ½éƒ½è¦å‹•æ‰‹å¯¦ä½œ\")\n",
    "print(\"  3. é …ç›®é©…å‹•å­¸ç¿’: é€šéå¯¦éš›é …ç›®éå›ºæŠ€èƒ½\")\n",
    "print(\"  4. æŒçºŒæ›´æ–°: NLP é ˜åŸŸç™¼å±•å¿«,éœ€æŒçºŒå­¸ç¿’\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "## 2. å¾åˆå­¸è€…åˆ°å°ˆå®¶çš„å­¸ç¿’è·¯ç·šåœ–\n",
    "\n",
    "### 2.1 äº”éšæ®µæˆé•·è·¯å¾‘\n",
    "\n",
    "#### éšæ®µ 1: å…¥é–€è€… (Beginner, 0-3 å€‹æœˆ)\n",
    "\n",
    "**å­¸ç¿’ç›®æ¨™:**\n",
    "- æŒæ¡ Python åŸºç¤ç·¨ç¨‹\n",
    "- ç†è§£ NLP åŸºæœ¬æ¦‚å¿µ\n",
    "- èƒ½å®Œæˆç°¡å–®çš„æ–‡æœ¬åˆ†é¡ä»»å‹™\n",
    "\n",
    "**æ ¸å¿ƒæŠ€èƒ½:**\n",
    "- Python èªæ³•ã€NumPyã€Pandas\n",
    "- æ–‡æœ¬é è™•ç† (åˆ†è©ã€æ¸…æ´—)\n",
    "- BoWã€TF-IDF\n",
    "- æ¨¸ç´ è²è‘‰æ–¯ã€Logistic Regression\n",
    "\n",
    "**å­¸ç¿’è³‡æº:**\n",
    "- æ›¸ç±: ã€ŠPython ç·¨ç¨‹: å¾å…¥é–€åˆ°å¯¦è¸ã€‹\n",
    "- èª²ç¨‹: Coursera - Python for Everybody\n",
    "- å¯¦æˆ°: Kaggle - Titanic, Digit Recognizer\n",
    "\n",
    "**é‡Œç¨‹ç¢‘é …ç›®:**\n",
    "- åƒåœ¾éƒµä»¶åˆ†é¡å™¨\n",
    "- å½±è©•æƒ…æ„Ÿåˆ†æ\n",
    "\n",
    "---\n",
    "\n",
    "#### éšæ®µ 2: åˆç´šå·¥ç¨‹å¸« (Junior, 3-6 å€‹æœˆ)\n",
    "\n",
    "**å­¸ç¿’ç›®æ¨™:**\n",
    "- æŒæ¡æ·±åº¦å­¸ç¿’åŸºç¤\n",
    "- ç†Ÿç·´ä½¿ç”¨ PyTorch/TensorFlow\n",
    "- èƒ½è¨“ç·´ RNN/LSTM æ¨¡å‹\n",
    "\n",
    "**æ ¸å¿ƒæŠ€èƒ½:**\n",
    "- ç¥ç¶“ç¶²è·¯åŸºç¤ (MLP, CNN)\n",
    "- Word2Vec, GloVe\n",
    "- RNN, LSTM, GRU\n",
    "- PyTorch åŸºç¤\n",
    "\n",
    "**å­¸ç¿’è³‡æº:**\n",
    "- æ›¸ç±: ã€Šæ·±åº¦å­¸ç¿’ã€‹(Goodfellow et al.)\n",
    "- èª²ç¨‹: CS231n, Fast.ai\n",
    "- è«–æ–‡: Word2Vec, LSTM\n",
    "\n",
    "**é‡Œç¨‹ç¢‘é …ç›®:**\n",
    "- ä½¿ç”¨ LSTM çš„æ–‡æœ¬ç”Ÿæˆ\n",
    "- Seq2Seq æ©Ÿå™¨ç¿»è­¯\n",
    "\n",
    "---\n",
    "\n",
    "#### éšæ®µ 3: ä¸­ç´šå·¥ç¨‹å¸« (Intermediate, 6-12 å€‹æœˆ)\n",
    "\n",
    "**å­¸ç¿’ç›®æ¨™:**\n",
    "- ç²¾é€š Transformer æ¶æ§‹\n",
    "- ç†Ÿç·´ä½¿ç”¨ Hugging Face\n",
    "- èƒ½å¾®èª¿ BERT/GPT æ¨¡å‹\n",
    "\n",
    "**æ ¸å¿ƒæŠ€èƒ½:**\n",
    "- Transformer, Self-Attention\n",
    "- BERT, GPT, T5\n",
    "- Hugging Face Transformers\n",
    "- æ¨¡å‹å¾®èª¿æŠ€å·§\n",
    "\n",
    "**å­¸ç¿’è³‡æº:**\n",
    "- æ›¸ç±: ã€ŠNatural Language Processing with Transformersã€‹\n",
    "- èª²ç¨‹: CS224N, Hugging Face Course\n",
    "- è«–æ–‡: Attention is All You Need, BERT, GPT-2\n",
    "\n",
    "**é‡Œç¨‹ç¢‘é …ç›®:**\n",
    "- BERT æ–‡æœ¬åˆ†é¡\n",
    "- GPT-2 æ–‡æœ¬ç”Ÿæˆ\n",
    "- å¤šä»»å‹™ NLP ç³»çµ±\n",
    "\n",
    "---\n",
    "\n",
    "#### éšæ®µ 4: é«˜ç´šå·¥ç¨‹å¸« (Senior, 1-2 å¹´)\n",
    "\n",
    "**å­¸ç¿’ç›®æ¨™:**\n",
    "- æŒæ¡å¤§å‹èªè¨€æ¨¡å‹\n",
    "- ç†Ÿæ‚‰æ¨¡å‹éƒ¨ç½²èˆ‡å„ªåŒ–\n",
    "- èƒ½è¨­è¨ˆè¤‡é›œ NLP ç³»çµ±\n",
    "\n",
    "**æ ¸å¿ƒæŠ€èƒ½:**\n",
    "- LLM (GPT-3/4, LLaMA)\n",
    "- Prompt Engineering, RLHF\n",
    "- æ¨¡å‹å£“ç¸®ã€é‡åŒ–ã€è’¸é¤¾\n",
    "- åˆ†å¸ƒå¼è¨“ç·´\n",
    "- ç³»çµ±è¨­è¨ˆ\n",
    "\n",
    "**å­¸ç¿’è³‡æº:**\n",
    "- è«–æ–‡: GPT-3, InstructGPT, LLaMA\n",
    "- èª²ç¨‹: Stanford CS324 - Large Language Models\n",
    "- é–‹æºé …ç›®: LangChain, LlamaIndex\n",
    "\n",
    "**é‡Œç¨‹ç¢‘é …ç›®:**\n",
    "- RAG (æª¢ç´¢å¢å¼·ç”Ÿæˆ) ç³»çµ±\n",
    "- LLM æ‡‰ç”¨é–‹ç™¼\n",
    "- å¤§è¦æ¨¡æ¨¡å‹éƒ¨ç½²\n",
    "\n",
    "---\n",
    "\n",
    "#### éšæ®µ 5: å°ˆå®¶/ç ”ç©¶å“¡ (Expert, 2+ å¹´)\n",
    "\n",
    "**å­¸ç¿’ç›®æ¨™:**\n",
    "- è¿½è¹¤å‰æ²¿ç ”ç©¶\n",
    "- ç™¼è¡¨é«˜è³ªé‡è«–æ–‡\n",
    "- è²¢ç»é–‹æºç¤¾ç¾¤\n",
    "\n",
    "**æ ¸å¿ƒæŠ€èƒ½:**\n",
    "- æœ€æ–° LLM æŠ€è¡“\n",
    "- å¤šæ¨¡æ…‹æ¨¡å‹\n",
    "- ç ”ç©¶æ–¹æ³•è«–\n",
    "- è«–æ–‡é–±è®€èˆ‡å¯«ä½œ\n",
    "\n",
    "**å­¸ç¿’è³‡æº:**\n",
    "- é ‚æœƒè«–æ–‡: ACL, EMNLP, NeurIPS, ICML\n",
    "- arXiv æœ€æ–°è«–æ–‡\n",
    "- ç ”ç©¶ç¤¾ç¾¤: Twitter, Reddit\n",
    "\n",
    "**é‡Œç¨‹ç¢‘:**\n",
    "- é ‚æœƒè«–æ–‡ç™¼è¡¨\n",
    "- é–‹æºé …ç›®ç¶­è­·\n",
    "- æŠ€è¡“æ¼”è¬›/æ•™å­¸\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¦–è¦ºåŒ–å­¸ç¿’è·¯ç·šåœ–\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "\n",
    "stages = [\n",
    "    {'name': 'å…¥é–€è€…\\nBeginner', 'duration': '0-3æœˆ', 'x': 1, 'skills': 5, 'projects': 2, 'color': '#FFB6C1'},\n",
    "    {'name': 'åˆç´šå·¥ç¨‹å¸«\\nJunior', 'duration': '3-6æœˆ', 'x': 2, 'skills': 8, 'projects': 3, 'color': '#87CEEB'},\n",
    "    {'name': 'ä¸­ç´šå·¥ç¨‹å¸«\\nIntermediate', 'duration': '6-12æœˆ', 'x': 3, 'skills': 12, 'projects': 5, 'color': '#98FB98'},\n",
    "    {'name': 'é«˜ç´šå·¥ç¨‹å¸«\\nSenior', 'duration': '1-2å¹´', 'x': 4, 'skills': 15, 'projects': 8, 'color': '#FFD700'},\n",
    "    {'name': 'å°ˆå®¶/ç ”ç©¶å“¡\\nExpert', 'duration': '2+å¹´', 'x': 5, 'skills': 20, 'projects': 12, 'color': '#DDA0DD'},\n",
    "]\n",
    "\n",
    "# ç¹ªè£½éšæ®µ\n",
    "for stage in stages:\n",
    "    circle = plt.Circle((stage['x'], 5), 0.4, color=stage['color'], alpha=0.7, edgecolor='black', linewidth=3)\n",
    "    ax.add_patch(circle)\n",
    "    ax.text(stage['x'], 5, stage['name'], ha='center', va='center', fontsize=11, fontweight='bold')\n",
    "    ax.text(stage['x'], 4.2, f\"({stage['duration']})\", ha='center', fontsize=9, style='italic')\n",
    "    ax.text(stage['x'], 3.8, f\"æŠ€èƒ½: {stage['skills']}+\", ha='center', fontsize=9)\n",
    "    ax.text(stage['x'], 3.5, f\"é …ç›®: {stage['projects']}+\", ha='center', fontsize=9)\n",
    "\n",
    "# ç¹ªè£½è·¯å¾‘ç®­é ­\n",
    "for i in range(len(stages)-1):\n",
    "    ax.annotate('', xy=(stages[i+1]['x']-0.5, 5), xytext=(stages[i]['x']+0.5, 5),\n",
    "                arrowprops=dict(arrowstyle='->', lw=3, color='gray', alpha=0.6))\n",
    "\n",
    "ax.set_xlim(0.5, 5.5)\n",
    "ax.set_ylim(3, 7)\n",
    "ax.set_title('NLP å·¥ç¨‹å¸«äº”éšæ®µæˆé•·è·¯ç·šåœ–', fontsize=18, fontweight='bold', pad=20)\n",
    "ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ“ˆ æˆé•·æ›²ç·šç‰¹é»:\")\n",
    "print(\"  1. å…¥é–€éšæ®µ (0-3æœˆ): å¿«é€ŸæŒæ¡åŸºç¤,çœ‹åˆ°æˆæ•ˆ\")\n",
    "print(\"  2. åˆç´šéšæ®µ (3-6æœˆ): æ·±å…¥å­¸ç¿’æ·±åº¦å­¸ç¿’,æ›²ç·šè¼ƒé™¡\")\n",
    "print(\"  3. ä¸­ç´šéšæ®µ (6-12æœˆ): Transformer æ™‚ä»£,èƒ½åŠ›é£›èº\")\n",
    "print(\"  4. é«˜ç´šéšæ®µ (1-2å¹´): ç³»çµ±åŒ–èƒ½åŠ›,é€²å…¥é«˜åŸæœŸ\")\n",
    "print(\"  5. å°ˆå®¶éšæ®µ (2+å¹´): å‰æ²¿æ¢ç´¢,æŒçºŒç²¾é€²\")\n",
    "print(\"\\nğŸ’¡ é—œéµå»ºè­°: æ¯å€‹éšæ®µéƒ½è¦å®Œæˆé‡Œç¨‹ç¢‘é …ç›®,å¯¦è¸å‡ºçœŸçŸ¥!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 å­¸ç¿’æ™‚é–“åˆ†é…å»ºè­°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¸åŒéšæ®µçš„å­¸ç¿’æ™‚é–“åˆ†é…\n",
    "time_allocation = {\n",
    "    'éšæ®µ': ['å…¥é–€è€…', 'åˆç´šå·¥ç¨‹å¸«', 'ä¸­ç´šå·¥ç¨‹å¸«', 'é«˜ç´šå·¥ç¨‹å¸«', 'å°ˆå®¶'],\n",
    "    'ç†è«–å­¸ç¿’ (%)': [40, 35, 30, 20, 15],\n",
    "    'ç·¨ç¨‹å¯¦ä½œ (%)': [30, 35, 30, 25, 20],\n",
    "    'é …ç›®é–‹ç™¼ (%)': [20, 20, 25, 30, 25],\n",
    "    'è«–æ–‡é–±è®€ (%)': [5, 5, 10, 15, 25],\n",
    "    'é–‹æºè²¢ç» (%)': [5, 5, 5, 10, 15]\n",
    "}\n",
    "\n",
    "df_time = pd.DataFrame(time_allocation)\n",
    "\n",
    "# ç¹ªè£½å †ç–Šæ¢å½¢åœ–\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "categories = ['ç†è«–å­¸ç¿’ (%)', 'ç·¨ç¨‹å¯¦ä½œ (%)', 'é …ç›®é–‹ç™¼ (%)', 'è«–æ–‡é–±è®€ (%)', 'é–‹æºè²¢ç» (%)']\n",
    "colors_time = ['#FFB6C1', '#87CEEB', '#98FB98', '#FFD700', '#DDA0DD']\n",
    "\n",
    "bottom = np.zeros(len(df_time))\n",
    "\n",
    "for i, category in enumerate(categories):\n",
    "    ax.barh(df_time['éšæ®µ'], df_time[category], left=bottom, \n",
    "            color=colors_time[i], alpha=0.8, label=category, edgecolor='black', linewidth=1)\n",
    "    bottom += df_time[category].values\n",
    "\n",
    "ax.set_xlabel('æ™‚é–“åˆ†é… (%)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('ä¸åŒéšæ®µå­¸ç¿’æ™‚é–“åˆ†é…å»ºè­°', fontsize=15, fontweight='bold')\n",
    "ax.legend(loc='upper right', fontsize=10)\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "display(HTML(\"<h3>â° å­¸ç¿’æ™‚é–“åˆ†é…è©³ç´°è¡¨</h3>\"))\n",
    "display(df_time.style.hide(axis='index').set_properties(**{'text-align': 'center', 'font-size': '10pt'}))\n",
    "\n",
    "print(\"\\nğŸ“Š æ™‚é–“åˆ†é…æ´å¯Ÿ:\")\n",
    "print(\"  1. å…¥é–€éšæ®µ: ç†è«–å­¸ç¿’å æ¯”æœ€é«˜ (40%),æ‰“å¥½åŸºç¤\")\n",
    "print(\"  2. åˆä¸­ç´š: ç·¨ç¨‹å¯¦ä½œèˆ‡é …ç›®é–‹ç™¼æ¯”é‡å¢åŠ \")\n",
    "print(\"  3. é«˜ç´šéšæ®µ: é …ç›®é–‹ç™¼å æ¯”æœ€é«˜ (30%),å¯¦æˆ°ç‚ºä¸»\")\n",
    "print(\"  4. å°ˆå®¶éšæ®µ: è«–æ–‡é–±è®€å æ¯”æœ€é«˜ (25%),è¿½è¹¤å‰æ²¿\")\n",
    "print(\"  5. é–‹æºè²¢ç»: éš¨éšæ®µæå‡é€æ­¥å¢åŠ \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "## 3. æ¨è–¦æ›¸ç±æ¸…å–®\n",
    "\n",
    "### 3.1 åŸºç¤å¿…è®€æ›¸ç±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¨è–¦æ›¸ç±æ¸…å–®\n",
    "books = {\n",
    "    'é¡åˆ¥': [\n",
    "        'ç·¨ç¨‹åŸºç¤', 'ç·¨ç¨‹åŸºç¤', 'æ•¸å­¸åŸºç¤', 'æ•¸å­¸åŸºç¤',\n",
    "        'æ©Ÿå™¨å­¸ç¿’', 'æ©Ÿå™¨å­¸ç¿’', 'æ·±åº¦å­¸ç¿’', 'æ·±åº¦å­¸ç¿’',\n",
    "        'NLP å…¥é–€', 'NLP é€²éš', 'NLP é€²éš', 'Transformer',\n",
    "        'å·¥ç¨‹å¯¦è¸', 'å·¥ç¨‹å¯¦è¸'\n",
    "    ],\n",
    "    'æ›¸å': [\n",
    "        'Python ç·¨ç¨‹:å¾å…¥é–€åˆ°å¯¦è¸',\n",
    "        'Fluent Python',\n",
    "        'ç·šæ€§ä»£æ•¸åŠå…¶æ‡‰ç”¨ (Strang)',\n",
    "        'æ©Ÿç‡çµ±è¨ˆ (DeGroot)',\n",
    "        'æ©Ÿå™¨å­¸ç¿’ (å‘¨å¿—è¯)',\n",
    "        'Pattern Recognition and ML (Bishop)',\n",
    "        'æ·±åº¦å­¸ç¿’ (Goodfellow et al.)',\n",
    "        'Dive into Deep Learning (ææ²)',\n",
    "        'Speech and Language Processing (Jurafsky)',\n",
    "        'Natural Language Processing with PyTorch',\n",
    "        'NLP with Transformers (Hugging Face)',\n",
    "        'Attention is All You Need (è«–æ–‡)',\n",
    "        'Designing Data-Intensive Applications',\n",
    "        'Machine Learning Systems Design'\n",
    "    ],\n",
    "    'é›£åº¦': ['å…¥é–€', 'ä¸­ç´š', 'ä¸­ç´š', 'ä¸­ç´š', \n",
    "            'ä¸­ç´š', 'é«˜ç´š', 'é«˜ç´š', 'ä¸­ç´š',\n",
    "            'ä¸­ç´š', 'ä¸­ç´š', 'ä¸­ç´š', 'é«˜ç´š',\n",
    "            'é«˜ç´š', 'é«˜ç´š'],\n",
    "    'æ¨è–¦æŒ‡æ•¸': [5, 4, 5, 4, 5, 4, 5, 5, 5, 4, 5, 5, 4, 4],\n",
    "    'é©åˆéšæ®µ': [\n",
    "        'å…¥é–€è€…', 'åˆç´š', 'å…¥é–€-åˆç´š', 'åˆç´š',\n",
    "        'å…¥é–€-åˆç´š', 'ä¸­ç´š', 'åˆç´š-ä¸­ç´š', 'åˆç´š-ä¸­ç´š',\n",
    "        'å…¥é–€-ä¸­ç´š', 'ä¸­ç´š', 'ä¸­ç´š-é«˜ç´š', 'ä¸­ç´š-é«˜ç´š',\n",
    "        'é«˜ç´š', 'é«˜ç´š'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_books = pd.DataFrame(books)\n",
    "\n",
    "# è¦–è¦ºåŒ–æ›¸ç±æ¨è–¦\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "categories_books = df_books['é¡åˆ¥'].unique()\n",
    "x_pos = np.arange(len(df_books))\n",
    "\n",
    "colors_books = {\n",
    "    'ç·¨ç¨‹åŸºç¤': '#FFB6C1', 'æ•¸å­¸åŸºç¤': '#87CEEB', \n",
    "    'æ©Ÿå™¨å­¸ç¿’': '#98FB98', 'æ·±åº¦å­¸ç¿’': '#FFD700',\n",
    "    'NLP å…¥é–€': '#DDA0DD', 'NLP é€²éš': '#FF6347',\n",
    "    'Transformer': '#4CAF50', 'å·¥ç¨‹å¯¦è¸': '#FF9800'\n",
    "}\n",
    "\n",
    "bar_colors = [colors_books[cat] for cat in df_books['é¡åˆ¥']]\n",
    "\n",
    "bars = ax.barh(x_pos, df_books['æ¨è–¦æŒ‡æ•¸'], color=bar_colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "ax.set_yticks(x_pos)\n",
    "ax.set_yticklabels(df_books['æ›¸å'], fontsize=9)\n",
    "ax.set_xlabel('æ¨è–¦æŒ‡æ•¸ (1-5)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('NLP å­¸ç¿’æ¨è–¦æ›¸ç±æ¸…å–®', fontsize=16, fontweight='bold')\n",
    "ax.set_xlim(0, 6)\n",
    "ax.invert_yaxis()\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# æ·»åŠ åœ–ä¾‹\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor=color, label=cat, alpha=0.8) \n",
    "                   for cat, color in colors_books.items()]\n",
    "ax.legend(handles=legend_elements, loc='lower right', fontsize=9, ncol=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "display(HTML(\"<h3>ğŸ“š æ¨è–¦æ›¸ç±è©³ç´°åˆ—è¡¨</h3>\"))\n",
    "display(df_books.style.hide(axis='index').set_properties(**{'text-align': 'left', 'font-size': '10pt'}))\n",
    "\n",
    "print(\"\\nğŸ’¡ é–±è®€å»ºè­°:\")\n",
    "print(\"  1. ä¸è¦è²ªå¤š,é¸æ“‡é©åˆç•¶å‰éšæ®µçš„ 2-3 æœ¬æ›¸ç²¾è®€\")\n",
    "print(\"  2. ç†è«–æ›¸ç±è¦é…åˆå¯¦ä½œ,é‚Šå­¸é‚Šç·´\")\n",
    "print(\"  3. ç¶“å…¸æ›¸ç± (å¦‚æ·±åº¦å­¸ç¿’èŠ±æ›¸) å¯åè¦†é–±è®€\")\n",
    "print(\"  4. è«–æ–‡é–±è®€å¾ç¶“å…¸è«–æ–‡é–‹å§‹ (Word2Vec, BERT, GPT)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "## 4. å„ªè³ªèª²ç¨‹èˆ‡æ•™å­¸è³‡æº\n",
    "\n",
    "### 4.1 é ‚ç´šå¤§å­¸å…¬é–‹èª²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å„ªè³ªèª²ç¨‹æ¨è–¦\n",
    "courses = {\n",
    "    'å¹³å°': [\n",
    "        'Stanford', 'Stanford', 'Stanford', 'MIT',\n",
    "        'Coursera', 'Coursera', 'Fast.ai', 'Hugging Face',\n",
    "        'DeepLearning.AI', 'YouTube', 'YouTube', 'Kaggle'\n",
    "    ],\n",
    "    'èª²ç¨‹åç¨±': [\n",
    "        'CS224N: NLP with Deep Learning',\n",
    "        'CS231n: CNN for Visual Recognition',\n",
    "        'CS324: Large Language Models',\n",
    "        '6.S191: Introduction to Deep Learning',\n",
    "        'Machine Learning (Andrew Ng)',\n",
    "        'Deep Learning Specialization',\n",
    "        'Practical Deep Learning',\n",
    "        'NLP Course (å…è²»)',\n",
    "        'ChatGPT Prompt Engineering',\n",
    "        '3Blue1Brown (ç·šæ€§ä»£æ•¸/å¾®ç©åˆ†)',\n",
    "        'Andrej Karpathy (GPT å¾é›¶å¯¦ç¾)',\n",
    "        'Learn NLP'\n",
    "    ],\n",
    "    'é›£åº¦': ['ä¸­ç´š', 'ä¸­ç´š', 'é«˜ç´š', 'å…¥é–€',\n",
    "            'å…¥é–€', 'ä¸­ç´š', 'ä¸­ç´š', 'ä¸­ç´š',\n",
    "            'å…¥é–€', 'å…¥é–€', 'é«˜ç´š', 'å…¥é–€'],\n",
    "    'æ™‚é•·': ['10é€±', '10é€±', '10é€±', '6é€±',\n",
    "            '11é€±', '5å€‹æœˆ', '7é€±', '9ç« ç¯€',\n",
    "            '1å°æ™‚', 'ç³»åˆ—', '4å°æ™‚', 'ç³»åˆ—'],\n",
    "    'è²»ç”¨': ['å…è²»', 'å…è²»', 'å…è²»', 'å…è²»',\n",
    "            'å…è²»æ—è½', '$49/æœˆ', 'å…è²»', 'å…è²»',\n",
    "            'å…è²»', 'å…è²»', 'å…è²»', 'å…è²»'],\n",
    "    'æ¨è–¦æŒ‡æ•¸': [5, 5, 5, 4, 5, 5, 5, 5, 4, 5, 5, 4]\n",
    "}\n",
    "\n",
    "df_courses = pd.DataFrame(courses)\n",
    "\n",
    "display(HTML(\"\"\"\n",
    "<div style=\"border:3px solid #4CAF50; padding:20px; border-radius:15px; background-color:#F1F8E9;\">\n",
    "    <h3 style=\"color:#2E7D32;\">ğŸ“ é ‚ç´šèª²ç¨‹æ¨è–¦æ¸…å–®</h3>\n",
    "    <p><strong>èª²ç¨‹é¸æ“‡å»ºè­°:</strong></p>\n",
    "    <ul style=\"line-height:1.8;\">\n",
    "        <li>ğŸŸ¢ <strong>å…¥é–€å¿…ä¿®:</strong> CS224N (NLP è–ç¶“), Andrew Ng ML (æ©Ÿå™¨å­¸ç¿’åŸºç¤)</li>\n",
    "        <li>ğŸ”µ <strong>æ·±åº¦å­¸ç¿’:</strong> CS231n (CNN), Fast.ai (å¯¦æˆ°å°å‘)</li>\n",
    "        <li>ğŸ”´ <strong>å‰æ²¿æŠ€è¡“:</strong> CS324 (LLM), Hugging Face NLP Course</li>\n",
    "        <li>ğŸŸ£ <strong>æ•¸å­¸è£œå¼·:</strong> 3Blue1Brown (è¦–è¦ºåŒ–è¬›è§£,æ¥µä½³)</li>\n",
    "        <li>ğŸŸ¡ <strong>å¯¦ä½œé€²éš:</strong> Andrej Karpathy (GPT å¾é›¶å¯¦ç¾)</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "display(df_courses.style.hide(axis='index').set_properties(**{'text-align': 'center', 'font-size': '10pt'}))\n",
    "\n",
    "print(\"\\nğŸ¯ å­¸ç¿’è·¯å¾‘å»ºè­°:\")\n",
    "print(\"  ã€éšæ®µ 1: å…¥é–€ã€‘\")\n",
    "print(\"    1. 3Blue1Brown (ç·šæ€§ä»£æ•¸/å¾®ç©åˆ†) - å»ºç«‹æ•¸å­¸ç›´è¦º\")\n",
    "print(\"    2. Coursera ML (Andrew Ng) - æ©Ÿå™¨å­¸ç¿’åŸºç¤\")\n",
    "print(\"    3. MIT 6.S191 - æ·±åº¦å­¸ç¿’å…¥é–€\")\n",
    "print(\"  ã€éšæ®µ 2: é€²éšã€‘\")\n",
    "print(\"    4. CS231n - CNN èˆ‡è¦–è¦º (é·ç§»åˆ° NLP)\")\n",
    "print(\"    5. CS224N - NLP å°ˆæ¥­èª²ç¨‹ (å¿…ä¿®!)\")\n",
    "print(\"    6. Fast.ai - å¯¦æˆ°æŠ€å·§\")\n",
    "print(\"  ã€éšæ®µ 3: å‰æ²¿ã€‘\")\n",
    "print(\"    7. Hugging Face NLP Course - Transformers å¯¦æˆ°\")\n",
    "print(\"    8. CS324 - å¤§å‹èªè¨€æ¨¡å‹\")\n",
    "print(\"    9. Andrej Karpathy - GPT å¾é›¶å¯¦ç¾\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 åœ¨ç·šå­¸ç¿’å¹³å°å°æ¯”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åœ¨ç·šå­¸ç¿’å¹³å°å°æ¯”\n",
    "platforms = {\n",
    "    'å¹³å°': ['Coursera', 'edX', 'Udacity', 'Fast.ai', 'Hugging Face', 'YouTube', 'Kaggle'],\n",
    "    'å„ªå‹¢': [\n",
    "        'é ‚ç´šå¤§å­¸èª²ç¨‹\\nè­‰æ›¸èªå¯',\n",
    "        'MIT/Harvardèª²ç¨‹\\nå­¸è¡“åš´è¬¹',\n",
    "        'ç´ç±³å­¸ä½\\nå°±æ¥­å°å‘',\n",
    "        'å¯¦æˆ°ç‚ºä¸»\\nå®Œå…¨å…è²»',\n",
    "        'Transformerå°ˆç²¾\\nå…è²»é«˜è³ªé‡',\n",
    "        'å…è²»å¤šæ¨£\\néš¨æ™‚å­¸ç¿’',\n",
    "        'å¯¦æˆ°ç«¶è³½\\næ•¸æ“šé›†è±å¯Œ'\n",
    "    ],\n",
    "    'åŠ£å‹¢': [\n",
    "        'è­‰æ›¸éœ€ä»˜è²»\\nç¯€å¥è¼ƒæ…¢',\n",
    "        'éƒ¨åˆ†èª²ç¨‹éæ™‚\\näº’å‹•æ€§å·®',\n",
    "        'åƒ¹æ ¼æ˜‚è²´\\n($399-$999)',\n",
    "        'éœ€è¦åŸºç¤\\né›£åº¦è·³èºå¤§',\n",
    "        'èšç„¦Transformers\\nç¯„åœæœ‰é™',\n",
    "        'è³ªé‡åƒå·®\\nç³»çµ±æ€§å·®',\n",
    "        'ç«¶è³½å£“åŠ›å¤§\\næ–°æ‰‹é–€æª»é«˜'\n",
    "    ],\n",
    "    'é©åˆéšæ®µ': ['å…¥é–€-ä¸­ç´š', 'å…¥é–€-ä¸­ç´š', 'ä¸­ç´š-é«˜ç´š', 'ä¸­ç´š-é«˜ç´š', \n",
    "                'ä¸­ç´š-é«˜ç´š', 'æ‰€æœ‰éšæ®µ', 'ä¸­ç´š-é«˜ç´š'],\n",
    "    'æ¨è–¦åº¦': [5, 4, 3, 5, 5, 4, 5]\n",
    "}\n",
    "\n",
    "df_platforms = pd.DataFrame(platforms)\n",
    "\n",
    "# è¦–è¦ºåŒ–å¹³å°æ¨è–¦åº¦\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "colors_platform = ['#4CAF50', '#2196F3', '#FF9800', '#9C27B0', '#F44336', '#607D8B', '#FF5722']\n",
    "bars = ax.bar(df_platforms['å¹³å°'], df_platforms['æ¨è–¦åº¦'], \n",
    "              color=colors_platform, alpha=0.8, edgecolor='black', linewidth=2)\n",
    "\n",
    "for bar, score in zip(bars, df_platforms['æ¨è–¦åº¦']):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "            f'{score}/5', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "ax.set_ylabel('æ¨è–¦åº¦ (1-5)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('åœ¨ç·šå­¸ç¿’å¹³å°æ¨è–¦åº¦å°æ¯”', fontsize=15, fontweight='bold')\n",
    "ax.set_ylim(0, 6)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "display(HTML(\"<h3>ğŸŒ åœ¨ç·šå­¸ç¿’å¹³å°è©³ç´°å°æ¯”</h3>\"))\n",
    "display(df_platforms.style.hide(axis='index').set_properties(**{'text-align': 'center', 'font-size': '10pt'}))\n",
    "\n",
    "print(\"\\nğŸ’¡ å¹³å°é¸æ“‡å»ºè­°:\")\n",
    "print(\"  - ç³»çµ±å­¸ç¿’: Coursera (CS224N, Andrew Ng)\")\n",
    "print(\"  - å¯¦æˆ°å¿«é€Ÿ: Fast.ai (å¾å¯¦æˆ°ä¸­å­¸ç¿’)\")\n",
    "print(\"  - Transformerå°ˆç²¾: Hugging Face Course (å…è²»é«˜è³ªé‡)\")\n",
    "print(\"  - ç«¶è³½å¯¦æˆ°: Kaggle (çœŸå¯¦æ•¸æ“šé›†,æ’åç³»çµ±)\")\n",
    "print(\"  - è£œå……å­¸ç¿’: YouTube (3Blue1Brown, Andrej Karpathy)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "## 5. å¿…è®€è«–æ–‡åˆ—è¡¨\n",
    "\n",
    "### 5.1 ç¶“å…¸è«–æ–‡ (å¿…è®€)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¿…è®€è«–æ–‡æ¸…å–®\n",
    "papers = {\n",
    "    'å¹´ä»½': [2013, 2014, 2014, 2015, 2017, 2018, 2018, 2019, 2020, 2020, 2022, 2023],\n",
    "    'è«–æ–‡æ¨™é¡Œ': [\n",
    "        'Word2Vec: Efficient Estimation of Word Representations',\n",
    "        'GloVe: Global Vectors for Word Representation',\n",
    "        'Seq2Seq: Sequence to Sequence Learning with NNs',\n",
    "        'Attention Mechanism (Bahdanau Attention)',\n",
    "        'Attention is All You Need (Transformer)',\n",
    "        'BERT: Pre-training of Deep Bidirectional Transformers',\n",
    "        'GPT: Improving Language Understanding',\n",
    "        'GPT-2: Language Models are Unsupervised Multitask Learners',\n",
    "        'GPT-3: Language Models are Few-Shot Learners',\n",
    "        'T5: Exploring Limits of Transfer Learning',\n",
    "        'InstructGPT: Training LMs to Follow Instructions',\n",
    "        'LLaMA: Open and Efficient Foundation LMs'\n",
    "    ],\n",
    "    'å½±éŸ¿åŠ›': [10, 8, 9, 9, 10, 10, 9, 9, 10, 8, 9, 8],\n",
    "    'é›£åº¦': [6, 6, 7, 7, 8, 8, 7, 7, 8, 8, 8, 8],\n",
    "    'å¼•ç”¨æ•¸': [35000, 25000, 28000, 22000, 45000, 55000, 15000, 12000, 18000, 8000, 3000, 2000]\n",
    "}\n",
    "\n",
    "df_papers = pd.DataFrame(papers)\n",
    "\n",
    "# è¦–è¦ºåŒ–è«–æ–‡å½±éŸ¿åŠ›èˆ‡å¼•ç”¨æ•¸\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# å·¦åœ–: å½±éŸ¿åŠ›æ’å\n",
    "top_papers = df_papers.nlargest(10, 'å½±éŸ¿åŠ›')\n",
    "colors_impact = ['red' if x == 10 else 'orange' if x == 9 else 'skyblue' for x in top_papers['å½±éŸ¿åŠ›']]\n",
    "\n",
    "ax1.barh(range(len(top_papers)), top_papers['å½±éŸ¿åŠ›'], color=colors_impact, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "ax1.set_yticks(range(len(top_papers)))\n",
    "ax1.set_yticklabels([f\"{year}: {title[:30]}...\" for year, title in zip(top_papers['å¹´ä»½'], top_papers['è«–æ–‡æ¨™é¡Œ'])], fontsize=9)\n",
    "ax1.set_xlabel('å½±éŸ¿åŠ› (1-10)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('NLP å¿…è®€è«–æ–‡å½±éŸ¿åŠ›æ’å (Top 10)', fontsize=14, fontweight='bold')\n",
    "ax1.invert_yaxis()\n",
    "ax1.set_xlim(0, 11)\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# å³åœ–: å¼•ç”¨æ•¸è¶¨å‹¢\n",
    "ax2.plot(df_papers['å¹´ä»½'], df_papers['å¼•ç”¨æ•¸']/1000, 'o-', linewidth=2, markersize=8, color='royalblue')\n",
    "for i, (year, citations, title) in enumerate(zip(df_papers['å¹´ä»½'], df_papers['å¼•ç”¨æ•¸'], df_papers['è«–æ–‡æ¨™é¡Œ'])):\n",
    "    if citations > 20000:\n",
    "        ax2.annotate(title[:15], (year, citations/1000), textcoords=\"offset points\", \n",
    "                    xytext=(0,10), ha='center', fontsize=8, fontweight='bold')\n",
    "\n",
    "ax2.set_xlabel('å¹´ä»½', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('å¼•ç”¨æ•¸ (åƒæ¬¡)', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('NLP é‡Œç¨‹ç¢‘è«–æ–‡å¼•ç”¨æ•¸', fontsize=14, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "display(HTML(\"<h3>ğŸ“„ å¿…è®€è«–æ–‡è©³ç´°åˆ—è¡¨</h3>\"))\n",
    "display(df_papers.style.hide(axis='index').set_properties(**{'text-align': 'left', 'font-size': '10pt'}))\n",
    "\n",
    "print(\"\\nğŸ“– è«–æ–‡é–±è®€å»ºè­°:\")\n",
    "print(\"  ã€ç¬¬ä¸€å„ªå…ˆç´š (å½±éŸ¿åŠ› 10):ã€‘\")\n",
    "print(\"    - Word2Vec (2013): è©å‘é‡é–‹å±±ä¹‹ä½œ\")\n",
    "print(\"    - Transformer (2017): æ”¹è®Š NLP çš„æ¶æ§‹\")\n",
    "print(\"    - BERT (2018): é è¨“ç·´æ¨¡å‹é‡Œç¨‹ç¢‘\")\n",
    "print(\"    - GPT-3 (2020): å¤§æ¨¡å‹æ™‚ä»£é–‹å•Ÿ\")\n",
    "print(\"  ã€ç¬¬äºŒå„ªå…ˆç´š (å½±éŸ¿åŠ› 9):ã€‘\")\n",
    "print(\"    - Seq2Seq, Attention, GPT, GPT-2, InstructGPT\")\n",
    "print(\"  ã€é–±è®€é †åºå»ºè­°:ã€‘\")\n",
    "print(\"    Word2Vec â†’ Seq2Seq â†’ Attention â†’ Transformer â†’ BERT â†’ GPT ç³»åˆ—\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 è«–æ–‡é–±è®€æ–¹æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(\"\"\"\n",
    "<div style=\"border:3px solid #2196F3; padding:20px; border-radius:15px; background-color:#E3F2FD;\">\n",
    "    <h3 style=\"color:#1976D2;\">ğŸ“š é«˜æ•ˆè«–æ–‡é–±è®€ä¸‰éæ³•</h3>\n",
    "    \n",
    "    <h4 style=\"color:#1565C0;\">ç¬¬ä¸€é: å¿«é€Ÿæƒæ (5-10 åˆ†é˜)</h4>\n",
    "    <ul style=\"line-height:1.8;\">\n",
    "        <li><strong>ç›®æ¨™:</strong> åˆ¤æ–·è«–æ–‡æ˜¯å¦å€¼å¾—æ·±è®€</li>\n",
    "        <li><strong>æ­¥é©Ÿ:</strong>\n",
    "            <ol>\n",
    "                <li>é–±è®€æ¨™é¡Œã€æ‘˜è¦ã€çµè«–</li>\n",
    "                <li>ç€è¦½ç« ç¯€æ¨™é¡Œèˆ‡åœ–è¡¨</li>\n",
    "                <li>çœ‹ä¸€çœ¼åƒè€ƒæ–‡ç» (äº†è§£èƒŒæ™¯)</li>\n",
    "            </ol>\n",
    "        </li>\n",
    "        <li><strong>è¼¸å‡º:</strong> è«–æ–‡çš„æ ¸å¿ƒè²¢ç»æ˜¯ä»€éº¼?</li>\n",
    "    </ul>\n",
    "    \n",
    "    <h4 style=\"color:#1565C0;\">ç¬¬äºŒé: æ·±å…¥é–±è®€ (1 å°æ™‚)</h4>\n",
    "    <ul style=\"line-height:1.8;\">\n",
    "        <li><strong>ç›®æ¨™:</strong> ç†è§£è«–æ–‡ä¸»è¦å…§å®¹</li>\n",
    "        <li><strong>æ­¥é©Ÿ:</strong>\n",
    "            <ol>\n",
    "                <li>ä»”ç´°é–±è®€å…¨æ–‡ (é™¤æ•¸å­¸è­‰æ˜å¤–)</li>\n",
    "                <li>æ¨™è¨˜é—œéµé»èˆ‡ä¸ç†è§£çš„éƒ¨åˆ†</li>\n",
    "                <li>è¨˜éŒ„æ ¸å¿ƒæ€æƒ³èˆ‡æ–¹æ³•</li>\n",
    "                <li>æŸ¥çœ‹åœ–è¡¨,ç†è§£å¯¦é©—è¨­ç½®</li>\n",
    "            </ol>\n",
    "        </li>\n",
    "        <li><strong>è¼¸å‡º:</strong> èƒ½å‘ä»–äººè§£é‡‹è«–æ–‡çš„ä¸»è¦å…§å®¹</li>\n",
    "    </ul>\n",
    "    \n",
    "    <h4 style=\"color:#1565C0;\">ç¬¬ä¸‰é: å¾©ç¾é©—è­‰ (4-5 å°æ™‚)</h4>\n",
    "    <ul style=\"line-height:1.8;\">\n",
    "        <li><strong>ç›®æ¨™:</strong> å®Œå…¨æŒæ¡è«–æ–‡ç´°ç¯€</li>\n",
    "        <li><strong>æ­¥é©Ÿ:</strong>\n",
    "            <ol>\n",
    "                <li>é€è¡Œç†è§£æ•¸å­¸å…¬å¼èˆ‡è­‰æ˜</li>\n",
    "                <li>å˜—è©¦å¾©ç¾æ ¸å¿ƒç®—æ³• (ä»£ç¢¼å¯¦ç¾)</li>\n",
    "                <li>æ€è€ƒè«–æ–‡çš„å±€é™æ€§èˆ‡æ”¹é€²æ–¹å‘</li>\n",
    "                <li>é–±è®€ç›¸é—œè«–æ–‡,å»ºç«‹çŸ¥è­˜é«”ç³»</li>\n",
    "            </ol>\n",
    "        </li>\n",
    "        <li><strong>è¼¸å‡º:</strong> èƒ½å¤ æ”¹é€²æˆ–æ“´å±•è«–æ–‡æ–¹æ³•</li>\n",
    "    </ul>\n",
    "    \n",
    "    <h4 style=\"color:#D32F2F;\">âš ï¸ æ³¨æ„äº‹é …:</h4>\n",
    "    <ul style=\"line-height:1.8;\">\n",
    "        <li>ä¸æ˜¯æ¯ç¯‡è«–æ–‡éƒ½éœ€è¦ä¸‰é (æ ¹æ“šç›®æ¨™é¸æ“‡)</li>\n",
    "        <li>ç¶“å…¸è«–æ–‡å»ºè­°å®Œæ•´ä¸‰é</li>\n",
    "        <li>å‰æ²¿è«–æ–‡å¯èƒ½åªéœ€ä¸€å…©é</li>\n",
    "        <li>åšç­†è¨˜!è¨˜éŒ„é—œéµæ€æƒ³èˆ‡ç–‘å•</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "print(\"\\nğŸ’¡ è«–æ–‡ç®¡ç†å·¥å…·æ¨è–¦:\")\n",
    "print(\"  - Zotero: é–‹æºå…è²»,å¼·å¤§çš„æ–‡ç»ç®¡ç†\")\n",
    "print(\"  - Mendeley: Elsevier å‡ºå“,PDF æ¨™è¨»åŠŸèƒ½å¥½\")\n",
    "print(\"  - Notion: ç­†è¨˜æ•´ç†,å»ºç«‹çŸ¥è­˜åº«\")\n",
    "print(\"  - Obsidian: Markdown ç­†è¨˜,çŸ¥è­˜åœ–è­œ\")\n",
    "print(\"  - arXiv Sanity: Andrej Karpathy é–‹ç™¼,arXiv è«–æ–‡æ¨è–¦\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a>\n",
    "## 6. é–‹æºå°ˆæ¡ˆæ¨è–¦èˆ‡åƒèˆ‡æŒ‡å—\n",
    "\n",
    "### 6.1 å„ªè³ªé–‹æºå°ˆæ¡ˆæ¨è–¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é–‹æºå°ˆæ¡ˆæ¨è–¦\n",
    "open_source = {\n",
    "    'å°ˆæ¡ˆåç¨±': [\n",
    "        'Hugging Face Transformers',\n",
    "        'spaCy',\n",
    "        'LangChain',\n",
    "        'LlamaIndex',\n",
    "        'FastChat (Vicuna)',\n",
    "        'ChatGLM',\n",
    "        'Sentence Transformers',\n",
    "        'Rasa',\n",
    "        'Gensim',\n",
    "        'NLTK'\n",
    "    ],\n",
    "    'é¡å‹': [\n",
    "        'Transformer æ¨¡å‹åº«',\n",
    "        'NLP å·¥å…·åº«',\n",
    "        'LLM æ‡‰ç”¨æ¡†æ¶',\n",
    "        'LLM æ•¸æ“šæ¡†æ¶',\n",
    "        'é–‹æºèŠå¤©æ¨¡å‹',\n",
    "        'ä¸­æ–‡å°è©±æ¨¡å‹',\n",
    "        'å¥å‘é‡',\n",
    "        'å°è©±ç³»çµ±æ¡†æ¶',\n",
    "        'ä¸»é¡Œå»ºæ¨¡',\n",
    "        'NLP åŸºç¤å·¥å…·'\n",
    "    ],\n",
    "    'GitHub Stars': ['120K+', '27K+', '70K+', '25K+', '30K+', '35K+', '12K+', '17K+', '14K+', '12K+'],\n",
    "    'é›£åº¦': ['ä¸­ç´š', 'å…¥é–€', 'ä¸­ç´š', 'ä¸­ç´š', 'é«˜ç´š', 'é«˜ç´š', 'ä¸­ç´š', 'ä¸­ç´š', 'ä¸­ç´š', 'å…¥é–€'],\n",
    "    'æ´»èºåº¦': ['æ¥µé«˜', 'é«˜', 'æ¥µé«˜', 'æ¥µé«˜', 'é«˜', 'é«˜', 'é«˜', 'ä¸­', 'ä¸­', 'ä¸­'],\n",
    "    'æ¨è–¦åº¦': [5, 5, 5, 5, 4, 4, 4, 4, 3, 4]\n",
    "}\n",
    "\n",
    "df_opensource = pd.DataFrame(open_source)\n",
    "\n",
    "display(HTML(\"\"\"\n",
    "<div style=\"border:3px solid #FF9800; padding:20px; border-radius:15px; background-color:#FFF3E0;\">\n",
    "    <h3 style=\"color:#E65100;\">ğŸš€ é ‚ç´šé–‹æºå°ˆæ¡ˆæ¨è–¦</h3>\n",
    "    <p><strong>åƒèˆ‡é–‹æºçš„å¥½è™•:</strong></p>\n",
    "    <ul style=\"line-height:1.8;\">\n",
    "        <li>âœ… å­¸ç¿’æ¥­ç•Œæœ€ä½³å¯¦è¸èˆ‡ä»£ç¢¼é¢¨æ ¼</li>\n",
    "        <li>âœ… å»ºç«‹å€‹äººå“ç‰Œ,GitHub æ˜¯æœ€å¥½çš„ç°¡æ­·</li>\n",
    "        <li>âœ… èˆ‡å…¨çƒé–‹ç™¼è€…äº¤æµ,æ‹“å±•äººè„ˆ</li>\n",
    "        <li>âœ… æ·±å…¥ç†è§£æ¡†æ¶åŸç†èˆ‡è¨­è¨ˆæ€æƒ³</li>\n",
    "        <li>âœ… ç‚ºç¤¾ç¾¤è²¢ç»,ç²å¾—æˆå°±æ„Ÿ</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "display(HTML(\"<h3>ğŸ“Š é–‹æºå°ˆæ¡ˆè©³ç´°åˆ—è¡¨</h3>\"))\n",
    "display(df_opensource.style.hide(axis='index').set_properties(**{'text-align': 'center', 'font-size': '10pt'}))\n",
    "\n",
    "print(\"\\nğŸ¯ å°ˆæ¡ˆé¸æ“‡å»ºè­°:\")\n",
    "print(\"  ã€å…¥é–€ç´š (é©åˆåˆå­¸è€…):ã€‘\")\n",
    "print(\"    - NLTK: å­¸ç¿’åŸºæœ¬ NLP æ¦‚å¿µ\")\n",
    "print(\"    - spaCy: å·¥æ¥­ç´š NLP å·¥å…·,æ–‡æª”å®Œå–„\")\n",
    "print(\"  ã€é€²éšç´š (é©åˆæœ‰ç¶“é©—è€…):ã€‘\")\n",
    "print(\"    - Hugging Face Transformers: Transformer ç”Ÿæ…‹æ ¸å¿ƒ\")\n",
    "print(\"    - LangChain: LLM æ‡‰ç”¨é–‹ç™¼å¿…å‚™\")\n",
    "print(\"    - Sentence Transformers: èªç¾©æœç´¢èˆ‡ç›¸ä¼¼åº¦\")\n",
    "print(\"  ã€é«˜ç´š (é©åˆå°ˆå®¶):ã€‘\")\n",
    "print(\"    - FastChat: è¨“ç·´é–‹æºå°è©±æ¨¡å‹\")\n",
    "print(\"    - ChatGLM: ä¸­æ–‡å°è©±æ¨¡å‹,å¯å•†ç”¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 é–‹æºè²¢ç»å…¥é–€æŒ‡å—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(\"\"\"\n",
    "<div style=\"border:3px solid #9C27B0; padding:20px; border-radius:15px; background-color:#F3E5F5;\">\n",
    "    <h3 style=\"color:#6A1B9A;\">ğŸ¤ é–‹æºè²¢ç»äº”æ­¥æ³•</h3>\n",
    "    \n",
    "    <h4 style=\"color:#7B1FA2;\">æ­¥é©Ÿ 1: é¸æ“‡åˆé©çš„å°ˆæ¡ˆ (ç¬¬ 1 é€±)</h4>\n",
    "    <ul style=\"line-height:1.8;\">\n",
    "        <li>é¸æ“‡ä½ æ­£åœ¨ä½¿ç”¨çš„å·¥å…·/æ¡†æ¶</li>\n",
    "        <li>æŸ¥çœ‹ GitHub Issues,å°‹æ‰¾ \"good first issue\" æ¨™ç±¤</li>\n",
    "        <li>é–±è®€ CONTRIBUTING.md äº†è§£è²¢ç»æŒ‡å—</li>\n",
    "        <li>åŠ å…¥ç¤¾ç¾¤ Discord/Slack,äº†è§£æ°›åœ</li>\n",
    "    </ul>\n",
    "    \n",
    "    <h4 style=\"color:#7B1FA2;\">æ­¥é©Ÿ 2: ç†Ÿæ‚‰ä»£ç¢¼åº« (ç¬¬ 2-3 é€±)</h4>\n",
    "    <ul style=\"line-height:1.8;\">\n",
    "        <li>Fork å°ˆæ¡ˆåˆ°è‡ªå·±çš„ GitHub</li>\n",
    "        <li>Clone åˆ°æœ¬åœ°,æ­å»ºé–‹ç™¼ç’°å¢ƒ</li>\n",
    "        <li>é‹è¡Œæ¸¬è©¦,ç¢ºä¿ç’°å¢ƒæ­£ç¢º</li>\n",
    "        <li>é–±è®€æ ¸å¿ƒæ¨¡çµ„ä»£ç¢¼,ç†è§£æ¶æ§‹</li>\n",
    "    </ul>\n",
    "    \n",
    "    <h4 style=\"color:#7B1FA2;\">æ­¥é©Ÿ 3: å¾å°è²¢ç»é–‹å§‹ (ç¬¬ 4 é€±)</h4>\n",
    "    <ul style=\"line-height:1.8;\">\n",
    "        <li><strong>æ–‡æª”æ”¹é€²:</strong> ä¿®æ­£æ‹¼å¯«éŒ¯èª¤ã€è£œå……èªªæ˜</li>\n",
    "        <li><strong>Bug ä¿®å¾©:</strong> é¸æ“‡ç°¡å–®çš„ Bug ä¿®å¾© (good first issue)</li>\n",
    "        <li><strong>æ¸¬è©¦è£œå……:</strong> ç‚ºæœªè¦†è“‹çš„åŠŸèƒ½æ·»åŠ æ¸¬è©¦</li>\n",
    "        <li><strong>ç¯„ä¾‹ä»£ç¢¼:</strong> è²¢ç»æ•™å­¸ç¯„ä¾‹</li>\n",
    "    </ul>\n",
    "    \n",
    "    <h4 style=\"color:#7B1FA2;\">æ­¥é©Ÿ 4: æäº¤ Pull Request (ç¬¬ 5 é€±)</h4>\n",
    "    <ul style=\"line-height:1.8;\">\n",
    "        <li>å‰µå»ºæ–°åˆ†æ”¯: <code>git checkout -b fix-issue-123</code></li>\n",
    "        <li>é€²è¡Œä¿®æ”¹ä¸¦æäº¤: <code>git commit -m \"Fix: resolve issue #123\"</code></li>\n",
    "        <li>æ¨é€åˆ° Fork: <code>git push origin fix-issue-123</code></li>\n",
    "        <li>åœ¨ GitHub å‰µå»º Pull Request,è©³ç´°æè¿°ä¿®æ”¹</li>\n",
    "    </ul>\n",
    "    \n",
    "    <h4 style=\"color:#7B1FA2;\">æ­¥é©Ÿ 5: å›æ‡‰ Review (æŒçºŒ)</h4>\n",
    "    <ul style=\"line-height:1.8;\">\n",
    "        <li>è€å¿ƒç­‰å¾… Maintainer Review (å¯èƒ½éœ€è¦æ•¸å¤©)</li>\n",
    "        <li>è™›å¿ƒæ¥å—åé¥‹,åŠæ™‚ä¿®æ”¹</li>\n",
    "        <li>ä¿æŒæºé€š,èªªæ˜è¨­è¨ˆæ€è·¯</li>\n",
    "        <li>PR åˆä½µå¾Œ,æ…¶ç¥ä½ çš„è²¢ç»!</li>\n",
    "    </ul>\n",
    "    \n",
    "    <h4 style=\"color:#D32F2F;\">âš ï¸ æ³¨æ„äº‹é …:</h4>\n",
    "    <ul style=\"line-height:1.8;\">\n",
    "        <li>éµå®ˆé …ç›®çš„ä»£ç¢¼é¢¨æ ¼èˆ‡è¦ç¯„</li>\n",
    "        <li>æäº¤å‰ç¢ºä¿æ‰€æœ‰æ¸¬è©¦é€šé</li>\n",
    "        <li>PR æè¿°è¦æ¸…æ™°,èªªæ˜ Why è€Œé What</li>\n",
    "        <li>ä¸è¦æ°£é¤’!ç¬¬ä¸€å€‹ PR è¢«æ‹’çµ•å¾ˆæ­£å¸¸</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "print(\"\\nğŸ’¡ è²¢ç»é¡å‹æ¨è–¦ (å¾æ˜“åˆ°é›£):\")\n",
    "print(\"  1. ğŸŸ¢ æ–‡æª”æ”¹é€² (é›£åº¦: 1/5, æœ€å®¹æ˜“è¢«æ¥å—)\")\n",
    "print(\"  2. ğŸŸ¢ æ·»åŠ ç¯„ä¾‹ä»£ç¢¼ (é›£åº¦: 2/5, å¹«åŠ©ä»–äººå­¸ç¿’)\")\n",
    "print(\"  3. ğŸŸ¡ Bug ä¿®å¾© (é›£åº¦: 3/5, æå‡é …ç›®è³ªé‡)\")\n",
    "print(\"  4. ğŸŸ¡ æ·»åŠ æ¸¬è©¦ (é›£åº¦: 3/5, æé«˜ä»£ç¢¼è¦†è“‹ç‡)\")\n",
    "print(\"  5. ğŸ”´ æ–°åŠŸèƒ½é–‹ç™¼ (é›£åº¦: 4/5, éœ€è¦è¨è«–èˆ‡è¨­è¨ˆ)\")\n",
    "print(\"  6. ğŸ”´ æ€§èƒ½å„ªåŒ– (é›£åº¦: 5/5, éœ€è¦æ·±å…¥ç†è§£)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a>\n",
    "## 7. å¯¦æˆ°ç·´ç¿’å¹³å°èˆ‡ç«¶è³½\n",
    "\n",
    "### 7.1 åœ¨ç·šç·´ç¿’å¹³å°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¦æˆ°ç·´ç¿’å¹³å°\n",
    "practice_platforms = {\n",
    "    'å¹³å°': ['Kaggle', 'LeetCode', 'HackerRank', 'Codalab', 'AICrowd', 'DrivenData'],\n",
    "    'é¡å‹': ['æ•¸æ“šç«¶è³½', 'ç®—æ³•ç·¨ç¨‹', 'å¤šé ˜åŸŸæŒ‘æˆ°', 'å­¸è¡“ç«¶è³½', 'AI ç«¶è³½', 'ç¤¾æœƒå…¬ç›Š'],\n",
    "    'NLP è³‡æº': ['è±å¯Œ', 'å°‘', 'ä¸­ç­‰', 'è±å¯Œ', 'è±å¯Œ', 'ä¸­ç­‰'],\n",
    "    'é›£åº¦': ['ä¸­-é«˜', 'ä¸­', 'å…¥é–€-ä¸­', 'é«˜', 'ä¸­-é«˜', 'ä¸­'],\n",
    "    'çé‡‘': ['é«˜ ($50K+)', 'ç„¡', 'æœ‰ ($10K)', 'å­¸è¡“ç‚ºä¸»', 'ä¸­ ($20K)', 'ä¸­ ($10K)'],\n",
    "    'æ¨è–¦åº¦': [5, 3, 4, 4, 4, 3]\n",
    "}\n",
    "\n",
    "df_practice = pd.DataFrame(practice_platforms)\n",
    "\n",
    "display(HTML(\"<h3>ğŸ† å¯¦æˆ°ç·´ç¿’å¹³å°å°æ¯”</h3>\"))\n",
    "display(df_practice.style.hide(axis='index').set_properties(**{'text-align': 'center', 'font-size': '10pt'}))\n",
    "\n",
    "print(\"\\nğŸ¯ å¹³å°é¸æ“‡å»ºè­°:\")\n",
    "print(\"  ã€Kaggle (å¼·çƒˆæ¨è–¦):ã€‘\")\n",
    "print(\"    - æœ€æ´»èºçš„æ•¸æ“šç§‘å­¸ç¤¾ç¾¤\")\n",
    "print(\"    - è±å¯Œçš„ NLP ç«¶è³½èˆ‡æ•¸æ“šé›†\")\n",
    "print(\"    - Notebooks å¯å­¸ç¿’ä»–äººæ–¹æ¡ˆ\")\n",
    "print(\"    - æ’åç³»çµ±æ¿€å‹µé€²æ­¥\")\n",
    "print(\"  ã€ç¶“å…¸ NLP ç«¶è³½æ¨è–¦:ã€‘\")\n",
    "print(\"    - Quora Question Pairs (æ–‡æœ¬ç›¸ä¼¼åº¦)\")\n",
    "print(\"    - Toxic Comment Classification (æ–‡æœ¬åˆ†é¡)\")\n",
    "print(\"    - Jigsaw Unintended Bias (å…¬å¹³æ€§)\")\n",
    "print(\"    - Google QUEST Q&A (å•ç­”ç³»çµ±)\")\n",
    "print(\"    - Tweet Sentiment Extraction (æƒ…æ„Ÿåˆ†æ)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 NLP ç¶“å…¸æ•¸æ“šé›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP ç¶“å…¸æ•¸æ“šé›†\n",
    "datasets = {\n",
    "    'æ•¸æ“šé›†': [\n",
    "        'GLUE',\n",
    "        'SQuAD',\n",
    "        'IMDb',\n",
    "        'CoNLL-2003',\n",
    "        'WMT',\n",
    "        'CNN/Daily Mail',\n",
    "        'MultiNLI',\n",
    "        'SST-2',\n",
    "        'CMRC 2018',\n",
    "        'CLUE'\n",
    "    ],\n",
    "    'ä»»å‹™é¡å‹': [\n",
    "        'é€šç”¨èªè¨€ç†è§£',\n",
    "        'é–±è®€ç†è§£',\n",
    "        'æƒ…æ„Ÿåˆ†æ',\n",
    "        'NER',\n",
    "        'æ©Ÿå™¨ç¿»è­¯',\n",
    "        'æ–‡æœ¬æ‘˜è¦',\n",
    "        'è‡ªç„¶èªè¨€æ¨ç†',\n",
    "        'æƒ…æ„Ÿåˆ†æ',\n",
    "        'ä¸­æ–‡é–±è®€ç†è§£',\n",
    "        'ä¸­æ–‡é€šç”¨ç†è§£'\n",
    "    ],\n",
    "    'è¦æ¨¡': ['å¤šä»»å‹™', '150K', '50K', '20K', 'æ•¸ç™¾è¬', '300K', '433K', '70K', '18K', 'å¤šä»»å‹™'],\n",
    "    'èªè¨€': ['è‹±æ–‡', 'è‹±æ–‡', 'è‹±æ–‡', 'è‹±æ–‡', 'å¤šèªè¨€', 'è‹±æ–‡', 'è‹±æ–‡', 'è‹±æ–‡', 'ä¸­æ–‡', 'ä¸­æ–‡'],\n",
    "    'é›£åº¦': ['é«˜', 'ä¸­', 'ä¸­', 'ä¸­', 'é«˜', 'é«˜', 'é«˜', 'ä¸­', 'ä¸­', 'é«˜'],\n",
    "    'æ¨è–¦åº¦': [5, 5, 5, 5, 4, 4, 4, 4, 5, 5]\n",
    "}\n",
    "\n",
    "df_datasets = pd.DataFrame(datasets)\n",
    "\n",
    "display(HTML(\"<h3>ğŸ“š NLP ç¶“å…¸æ•¸æ“šé›†æ¸…å–®</h3>\"))\n",
    "display(df_datasets.style.hide(axis='index').set_properties(**{'text-align': 'center', 'font-size': '10pt'}))\n",
    "\n",
    "print(\"\\nğŸ¯ æ•¸æ“šé›†é¸æ“‡å»ºè­°:\")\n",
    "print(\"  ã€é€šç”¨ Benchmark (å¿…ç·´):ã€‘\")\n",
    "print(\"    - GLUE: BERT ç­‰æ¨¡å‹çš„æ¨™æº–æ¸¬è©¦é›†\")\n",
    "print(\"    - SQuAD: å•ç­”ç³»çµ±æ¨™æº–æ•¸æ“šé›†\")\n",
    "print(\"  ã€å–®ä»»å‹™ç·´ç¿’:ã€‘\")\n",
    "print(\"    - IMDb: æƒ…æ„Ÿåˆ†æå…¥é–€é¦–é¸\")\n",
    "print(\"    - CoNLL-2003: NER ç¶“å…¸æ•¸æ“šé›†\")\n",
    "print(\"    - CNN/Daily Mail: æ‘˜è¦ä»»å‹™\")\n",
    "print(\"  ã€ä¸­æ–‡ NLP:ã€‘\")\n",
    "print(\"    - CMRC 2018: ä¸­æ–‡é–±è®€ç†è§£\")\n",
    "print(\"    - CLUE: ä¸­æ–‡ GLUE,å¤šä»»å‹™ Benchmark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"8\"></a>\n",
    "## 8. æŒçºŒå­¸ç¿’èˆ‡çŸ¥è­˜ç®¡ç†\n",
    "\n",
    "### 8.1 ä¿¡æ¯æºæ¨è–¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¿¡æ¯æºæ¨è–¦\n",
    "info_sources = {\n",
    "    'é¡å‹': [\n",
    "        'è«–æ–‡å¹³å°', 'è«–æ–‡å¹³å°', 'å­¸è¡“æœƒè­°', 'åšå®¢/Newsletter',\n",
    "        'Twitter', 'Reddit', 'YouTube', 'Podcast',\n",
    "        'ä¸­æ–‡ç¤¾ç¾¤', 'ä¸­æ–‡ç¤¾ç¾¤'\n",
    "    ],\n",
    "    'åç¨±': [\n",
    "        'arXiv',\n",
    "        'Papers with Code',\n",
    "        'ACL, EMNLP, NeurIPS, ICML',\n",
    "        'The Batch (Andrew Ng), Import AI',\n",
    "        'Follow: Yann LeCun, Andrej Karpathy, Sebastian Ruder',\n",
    "        'r/MachineLearning, r/LanguageTechnology',\n",
    "        'Two Minute Papers, Yannic Kilcher',\n",
    "        'The TWIML AI Podcast, Gradient Dissent',\n",
    "        'æ©Ÿå™¨ä¹‹å¿ƒ, AI ç§‘æŠ€è©•è«–',\n",
    "        'çŸ¥ä¹å°ˆæ¬„, GitHub Trending'\n",
    "    ],\n",
    "    'æ›´æ–°é »ç‡': ['æ¯æ—¥', 'å³æ™‚', 'å¹´æœƒ', 'æ¯é€±', 'å³æ™‚', 'å³æ™‚', 'æ¯é€±', 'æ¯é€±', 'æ¯æ—¥', 'æ¯æ—¥'],\n",
    "    'è³ªé‡': ['é«˜', 'é«˜', 'æ¥µé«˜', 'é«˜', 'ä¸­-é«˜', 'ä¸­', 'é«˜', 'é«˜', 'ä¸­', 'ä¸­-é«˜'],\n",
    "    'æ¨è–¦åº¦': [5, 5, 5, 5, 4, 3, 4, 4, 4, 4]\n",
    "}\n",
    "\n",
    "df_sources = pd.DataFrame(info_sources)\n",
    "\n",
    "display(HTML(\"\"\"\n",
    "<div style=\"border:3px solid #4CAF50; padding:20px; border-radius:15px; background-color:#F1F8E9;\">\n",
    "    <h3 style=\"color:#2E7D32;\">ğŸŒ æŒçºŒå­¸ç¿’ä¿¡æ¯æºæ¨è–¦</h3>\n",
    "    <p><strong>æ§‹å»ºå€‹äººå­¸ç¿’ç³»çµ±:</strong></p>\n",
    "    <ul style=\"line-height:1.8;\">\n",
    "        <li>ğŸ“° <strong>æ¯æ—¥:</strong> arXiv-sanity (ç¯©é¸æœ€æ–°è«–æ–‡), Twitter (é—œæ³¨å¤§ç‰›)</li>\n",
    "        <li>ğŸ“… <strong>æ¯é€±:</strong> The Batch Newsletter, YouTube (Two Minute Papers)</li>\n",
    "        <li>ğŸ“– <strong>æ¯æœˆ:</strong> ç²¾è®€ 2-3 ç¯‡é‡è¦è«–æ–‡,ç¸½çµç­†è¨˜</li>\n",
    "        <li>ğŸ“ <strong>æ¯å­£:</strong> å®Œæˆä¸€å€‹å®Œæ•´é …ç›®,åƒåŠ ä¸€æ¬¡ç«¶è³½</li>\n",
    "        <li>ğŸ† <strong>æ¯å¹´:</strong> åƒåŠ é ‚æœƒ (ACL/NeurIPS),æ‹“å±•äººè„ˆ</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "display(HTML(\"<h3>ğŸ“Š ä¿¡æ¯æºè©³ç´°åˆ—è¡¨</h3>\"))\n",
    "display(df_sources.style.hide(axis='index').set_properties(**{'text-align': 'left', 'font-size': '10pt'}))\n",
    "\n",
    "print(\"\\nğŸ¯ ä¿¡æ¯éæ¿¾ç­–ç•¥:\")\n",
    "print(\"  1. arXiv: é—œæ³¨ cs.CL (NLP) åˆ†é¡,è¨‚é–± RSS\")\n",
    "print(\"  2. Papers with Code: æŸ¥çœ‹ SOTA æ’è¡Œæ¦œ,è·Ÿè¹¤æœ€æ–°é€²å±•\")\n",
    "print(\"  3. Twitter: é—œæ³¨é ˜åŸŸå¤§ç‰›,ç²å–ç¬¬ä¸€æ‰‹è³‡è¨Š\")\n",
    "print(\"  4. Newsletter: è¨‚é–±ç²¾é¸å…§å®¹,ç¯€çœç¯©é¸æ™‚é–“\")\n",
    "print(\"  5. å­¸è¡“æœƒè­°: æ¯å¹´è‡³å°‘ç²¾è®€ä¸€å€‹é ‚æœƒçš„ Best Papers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 çŸ¥è­˜ç®¡ç†ç³»çµ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(\"\"\"\n",
    "<div style=\"border:3px solid #FF9800; padding:20px; border-radius:15px; background-color:#FFF3E0;\">\n",
    "    <h3 style=\"color:#E65100;\">ğŸ—‚ï¸ å€‹äººçŸ¥è­˜ç®¡ç†ç³»çµ±æ§‹å»º</h3>\n",
    "    \n",
    "    <h4 style=\"color:#EF6C00;\">1. è«–æ–‡ç®¡ç† (Zotero / Mendeley)</h4>\n",
    "    <ul style=\"line-height:1.8;\">\n",
    "        <li>å»ºç«‹åˆ†é¡: è©å‘é‡ã€Transformerã€LLMã€æ‡‰ç”¨ç­‰</li>\n",
    "        <li>æ·»åŠ æ¨™ç±¤: å·²è®€ã€ç²¾è®€ã€å¾…è®€ã€ç¶“å…¸</li>\n",
    "        <li>æ’°å¯«æ‘˜è¦: è¨˜éŒ„æ ¸å¿ƒè²¢ç»èˆ‡é—œéµæ€æƒ³</li>\n",
    "        <li>ç®¡ç† PDF: é«˜äº®é‡é»,æ·»åŠ æ‰¹è¨»</li>\n",
    "    </ul>\n",
    "    \n",
    "    <h4 style=\"color:#EF6C00;\">2. ç­†è¨˜æ•´ç† (Notion / Obsidian)</h4>\n",
    "    <ul style=\"line-height:1.8;\">\n",
    "        <li><strong>çŸ¥è­˜åº«çµæ§‹:</strong>\n",
    "            <ul>\n",
    "                <li>åŸºç¤çŸ¥è­˜ (æ•¸å­¸ã€ç®—æ³•ã€ç·¨ç¨‹)</li>\n",
    "                <li>NLP æ ¸å¿ƒ (é è™•ç†ã€æ¨¡å‹ã€ä»»å‹™)</li>\n",
    "                <li>å·¥ç¨‹å¯¦è¸ (éƒ¨ç½²ã€å„ªåŒ–ã€å·¥å…·)</li>\n",
    "                <li>é …ç›®ç¶“é©— (ä»£ç¢¼ç‰‡æ®µã€è¸©å‘è¨˜éŒ„)</li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li><strong>ç­†è¨˜æ¨¡æ¿:</strong> è«–æ–‡ç­†è¨˜ã€æŠ€è¡“ç­†è¨˜ã€é …ç›®è¨˜éŒ„</li>\n",
    "        <li><strong>é›™å‘éˆæ¥:</strong> å»ºç«‹çŸ¥è­˜é»ä¹‹é–“çš„é—œè¯</li>\n",
    "    </ul>\n",
    "    \n",
    "    <h4 style=\"color:#EF6C00;\">3. ä»£ç¢¼ç®¡ç† (GitHub)</h4>\n",
    "    <ul style=\"line-height:1.8;\">\n",
    "        <li>å€‹äººä»£ç¢¼åº«: åˆ†é¡æ•´ç†å­¸ç¿’ä»£ç¢¼</li>\n",
    "        <li>é …ç›®å±•ç¤º: å®Œæ•´é …ç›®æ”¾åœ¨ Pinned Repos</li>\n",
    "        <li>README æ’°å¯«: æ¸…æ™°èªªæ˜é …ç›®èƒŒæ™¯èˆ‡ä½¿ç”¨æ–¹æ³•</li>\n",
    "        <li>æŒçºŒæ›´æ–°: å®šæœŸæäº¤,ä¿æŒæ´»èº</li>\n",
    "    </ul>\n",
    "    \n",
    "    <h4 style=\"color:#EF6C00;\">4. å­¸ç¿’è¨ˆåŠƒ (Trello / Notion)</h4>\n",
    "    <ul style=\"line-height:1.8;\">\n",
    "        <li>çœ‹æ¿ç®¡ç†: å¾…å­¸ç¿’ã€é€²è¡Œä¸­ã€å·²å®Œæˆ</li>\n",
    "        <li>ç›®æ¨™è¨­å®š: å­£åº¦ç›®æ¨™ã€æœˆåº¦ç›®æ¨™ã€é€±ç›®æ¨™</li>\n",
    "        <li>é€²åº¦è¿½è¹¤: è¨˜éŒ„å­¸ç¿’æ™‚é–“èˆ‡ç”¢å‡º</li>\n",
    "        <li>å®šæœŸå›é¡§: æ¯æœˆç¸½çµ,èª¿æ•´è¨ˆåŠƒ</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\"\"\"))\n",
    "\n",
    "print(\"\\nğŸ’¡ çŸ¥è­˜ç®¡ç†é»ƒé‡‘æ³•å‰‡:\")\n",
    "print(\"  1. è²»æ›¼å­¸ç¿’æ³•: ç”¨è‡ªå·±çš„è©±æ•™æœƒåˆ¥äºº\")\n",
    "print(\"  2. è¼¸å…¥è¼¸å‡ºä¸¦é‡: çœ‹è«–æ–‡ (è¼¸å…¥) + å¯«åšå®¢ (è¼¸å‡º)\")\n",
    "print(\"  3. å®šæœŸè¤‡ç¿’: åˆ©ç”¨é–“éš”é‡è¤‡è¨˜æ†¶æ³•\")\n",
    "print(\"  4. çŸ¥è­˜é€£æ¥: å»ºç«‹çŸ¥è­˜åœ–è­œ,å½¢æˆé«”ç³»\")\n",
    "print(\"  5. è¡Œå‹•å°å‘: å­¸åˆ°çš„çŸ¥è­˜è¦æ‡‰ç”¨åˆ°é …ç›®ä¸­\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“š æœ¬èª²ç¸½çµ\n",
    "\n",
    "### æ ¸å¿ƒè¦é»å›é¡§:\n",
    "\n",
    "1. **NLP å·¥ç¨‹å¸«æŠ€èƒ½æ¨¹:**\n",
    "   - äº”å¤§é ˜åŸŸ: åŸºç¤æŠ€èƒ½ã€æ©Ÿå™¨å­¸ç¿’ã€NLP æ ¸å¿ƒã€å·¥ç¨‹èƒ½åŠ›ã€é ˜åŸŸçŸ¥è­˜\n",
    "   - é«˜å„ªå…ˆç´šæŠ€èƒ½: ç·¨ç¨‹èƒ½åŠ›ã€æ–‡æœ¬é è™•ç†ã€æ–‡æœ¬è¡¨ç¤ºã€NLP ä»»å‹™ã€æ·±åº¦å­¸ç¿’æ¡†æ¶\n",
    "\n",
    "2. **äº”éšæ®µæˆé•·è·¯å¾‘:**\n",
    "   - å…¥é–€è€… (0-3æœˆ): Python + åŸºç¤ NLP\n",
    "   - åˆç´š (3-6æœˆ): æ·±åº¦å­¸ç¿’ + RNN/LSTM\n",
    "   - ä¸­ç´š (6-12æœˆ): Transformer + BERT/GPT\n",
    "   - é«˜ç´š (1-2å¹´): LLM + ç³»çµ±è¨­è¨ˆ\n",
    "   - å°ˆå®¶ (2+å¹´): å‰æ²¿ç ”ç©¶ + é–‹æºè²¢ç»\n",
    "\n",
    "3. **å­¸ç¿’è³‡æºæ¨è–¦:**\n",
    "   - **æ›¸ç±:** æ·±åº¦å­¸ç¿’èŠ±æ›¸ã€NLP with Transformers\n",
    "   - **èª²ç¨‹:** CS224Nã€Hugging Face Courseã€Fast.ai\n",
    "   - **è«–æ–‡:** Word2Vecã€Transformerã€BERTã€GPT ç³»åˆ—\n",
    "\n",
    "4. **é–‹æºå°ˆæ¡ˆåƒèˆ‡:**\n",
    "   - æ¨è–¦å°ˆæ¡ˆ: Hugging Faceã€spaCyã€LangChain\n",
    "   - è²¢ç»é¡å‹: æ–‡æª”ã€Bug ä¿®å¾©ã€æ–°åŠŸèƒ½\n",
    "   - å¾ \"good first issue\" é–‹å§‹\n",
    "\n",
    "5. **æŒçºŒå­¸ç¿’ç³»çµ±:**\n",
    "   - ä¿¡æ¯æº: arXivã€Papers with Codeã€Twitter\n",
    "   - çŸ¥è­˜ç®¡ç†: Zotero + Notion + GitHub\n",
    "   - å­¸ç¿’è¨ˆåŠƒ: æ—¥/é€±/æœˆ/å­£åº¦ç›®æ¨™\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ ä¸‹ç¯€é å‘Š\n",
    "\n",
    "**CH09-04: è·æ¶¯ç™¼å±•èˆ‡å¯¦æˆ°å»ºè­°**\n",
    "\n",
    "æˆ‘å€‘å°‡æ¢è¨:\n",
    "- NLP å·¥ç¨‹å¸«è·æ¶¯ç™¼å±•è·¯å¾‘\n",
    "- æ±‚è·ä½œå“é›†å»ºè­°\n",
    "- æŠ€è¡“é¢è©¦æº–å‚™æŒ‡å—\n",
    "- ç”¢æ¥­è¶¨å‹¢åˆ†æèˆ‡æ©Ÿæœƒ\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“– å»¶ä¼¸é–±è®€\n",
    "\n",
    "1. **å­¸ç¿’æ–¹æ³•:**\n",
    "   - [How to Read a Paper (S. Keshav)](http://ccr.sigcomm.org/online/files/p83-keshavA.pdf)\n",
    "   - [è²»æ›¼å­¸ç¿’æ³•](https://fs.blog/feynman-learning-technique/)\n",
    "\n",
    "2. **é–‹æºæŒ‡å—:**\n",
    "   - [Open Source Guides](https://opensource.guide/)\n",
    "   - [First Contributions](https://firstcontributions.github.io/)\n",
    "\n",
    "3. **çŸ¥è­˜ç®¡ç†:**\n",
    "   - [Building a Second Brain](https://www.buildingasecondbrain.com/)\n",
    "   - [Zettelkasten Method](https://zettelkasten.de/)\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ™‹ å•é¡Œè¨è«–\n",
    "\n",
    "æœ‰ä»»ä½•å•é¡Œå—?æ­¡è¿åœ¨è¨è«–å€æå•!\n",
    "\n",
    "---\n",
    "\n",
    "**èª²ç¨‹è³‡è¨Š:**\n",
    "- **ä½œè€…:** iSpan NLP Team\n",
    "- **ç‰ˆæœ¬:** v1.0\n",
    "- **æœ€å¾Œæ›´æ–°:** 2025-10-17\n",
    "- **æˆæ¬Š:** MIT License (åƒ…ä¾›æ•™å­¸ä½¿ç”¨)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
