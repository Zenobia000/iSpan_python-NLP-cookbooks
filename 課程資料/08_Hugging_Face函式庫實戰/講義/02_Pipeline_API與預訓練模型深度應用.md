# CH08 è¬›ç¾© 02: Pipeline API èˆ‡é è¨“ç·´æ¨¡å‹æ·±åº¦æ‡‰ç”¨

---

**èª²ç¨‹**: iSpan Python NLP é€Ÿæˆæ•™æ¡ˆ
**ç« ç¯€**: CH08 Hugging Face å‡½å¼åº«å¯¦æˆ°
**è¬›ç¾©ç·¨è™Ÿ**: 02/04
**é è¨ˆæ™‚é–“**: 120 åˆ†é˜
**å°æ‡‰ Notebooks**: `03-07` (æƒ…æ„Ÿåˆ†æã€NERã€é›¶æ¨£æœ¬ã€æ‘˜è¦ã€ç”Ÿæˆ)

---

## ğŸ“š å­¸ç¿’ç›®æ¨™

å®Œæˆæœ¬è¬›ç¾©å¾Œ,ä½ å°‡èƒ½å¤ :

1. âœ… æ·±åº¦æŒæ¡ Pipeline API çš„ 5 å¤§æ ¸å¿ƒä»»å‹™
2. âœ… ç†è§£ä¸åŒé è¨“ç·´æ¨¡å‹çš„é©ç”¨å ´æ™¯
3. âœ… å¯¦ä½œæƒ…æ„Ÿåˆ†æã€NERã€é›¶æ¨£æœ¬åˆ†é¡ç­‰å¯¦éš›æ‡‰ç”¨
4. âœ… æŒæ¡æ–‡æœ¬æ‘˜è¦èˆ‡ç”ŸæˆæŠ€è¡“
5. âœ… è§£æ±ºå¯¦éš›æ¥­å‹™å•é¡Œ

---

## 1. æƒ…æ„Ÿåˆ†æ (Sentiment Analysis)

### 1.1 ä»€éº¼æ˜¯æƒ…æ„Ÿåˆ†æ?

**æƒ…æ„Ÿåˆ†æ**æ˜¯åˆ¤æ–·æ–‡æœ¬è¡¨é”çš„æƒ…ç·’æˆ–æ…‹åº¦ (æ­£é¢ã€è² é¢ã€ä¸­æ€§)ã€‚

#### æ‡‰ç”¨å ´æ™¯

| é ˜åŸŸ | æ‡‰ç”¨ | åƒ¹å€¼ |
|------|------|------|
| **é›»å•†** | ç”¢å“è©•è«–åˆ†æ | å¿«é€Ÿç™¼ç¾å•é¡Œç”¢å“ |
| **ç¤¾äº¤åª’é«”** | å“ç‰Œè²è­½ç›£æ§ | å³æ™‚å±æ©Ÿé è­¦ |
| **å®¢æœ** | å®¢æˆ¶æ»¿æ„åº¦è¿½è¹¤ | æ”¹å–„æœå‹™å“è³ª |
| **é‡‘è** | å¸‚å ´æƒ…ç·’åˆ†æ | è¼”åŠ©æŠ•è³‡æ±ºç­– |

---

### 1.2 ä½¿ç”¨ Pipeline å¯¦ä½œ

#### åŸºç¤ä½¿ç”¨

```python
from transformers import pipeline

# å‰µå»ºæƒ…æ„Ÿåˆ†æå™¨ (ä½¿ç”¨é è¨­æ¨¡å‹)
classifier = pipeline("sentiment-analysis")

# å–®å€‹æ–‡æœ¬
result = classifier("I love this product!")
print(result)
# [{'label': 'POSITIVE', 'score': 0.9998}]

# æ‰¹é‡è™•ç†
texts = [
    "This is amazing!",
    "Terrible experience.",
    "It's okay."
]
results = classifier(texts)

for text, result in zip(texts, results):
    sentiment = result['label']
    confidence = result['score']
    print(f"{text:30} â†’ {sentiment:8} ({confidence:.2%})")
```

**è¼¸å‡º**:
```
This is amazing!               â†’ POSITIVE (99.98%)
Terrible experience.           â†’ NEGATIVE (99.95%)
It's okay.                     â†’ POSITIVE (52.34%)
```

---

### 1.3 ä½¿ç”¨ä¸åŒçš„æ¨¡å‹

#### æ¨¡å‹é¸æ“‡

```python
# è‹±æ–‡æƒ…æ„Ÿåˆ†æ (é è¨­)
classifier_en = pipeline(
    "sentiment-analysis",
    model="distilbert-base-uncased-finetuned-sst-2-english"
)

# ä¸­æ–‡æƒ…æ„Ÿåˆ†æ
classifier_zh = pipeline(
    "sentiment-analysis",
    model="uer/roberta-base-finetuned-chinanews-chinese"
)

# å¤šèªè¨€æƒ…æ„Ÿåˆ†æ
classifier_multi = pipeline(
    "sentiment-analysis",
    model="nlptown/bert-base-multilingual-uncased-sentiment"
)
```

#### ç´°ç²’åº¦æƒ…æ„Ÿåˆ†æ (1-5 æ˜Ÿ)

```python
# 5 åˆ†é¡æƒ…æ„Ÿåˆ†æ
sentiment_5class = pipeline(
    "sentiment-analysis",
    model="nlptown/bert-base-multilingual-uncased-sentiment"
)

text = "The product is pretty good but delivery was slow."
result = sentiment_5class(text)

print(f"Rating: {result[0]['label']}")
print(f"Confidence: {result[0]['score']:.2%}")

# Rating: 3 stars
# Confidence: 65.43%
```

---

### 1.4 å¯¦æˆ°æ¡ˆä¾‹: ç”¢å“è©•è«–åˆ†æ

```python
import pandas as pd
import matplotlib.pyplot as plt

# æ¨¡æ“¬ç”¢å“è©•è«–
reviews = [
    "Best purchase ever! Highly recommend.",
    "Product broke after 2 days. Very disappointed.",
    "Good quality for the price.",
    "Shipping was terrible, product is okay.",
    "Amazing! Exceeded my expectations.",
    "Do not buy. Complete waste of money.",
    "It's fine, nothing special.",
    "Love it! Will buy again."
]

# åˆ†ææƒ…æ„Ÿ
classifier = pipeline("sentiment-analysis")
results = classifier(reviews)

# çµ±è¨ˆ
positive = sum(1 for r in results if r['label'] == 'POSITIVE')
negative = len(results) - positive

print(f"æ­£é¢è©•è«–: {positive} ({positive/len(reviews)*100:.1f}%)")
print(f"è² é¢è©•è«–: {negative} ({negative/len(reviews)*100:.1f}%)")

# å¯è¦–åŒ–
labels = ['Positive', 'Negative']
sizes = [positive, negative]
colors = ['#2ecc71', '#e74c3c']

plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%')
plt.title('Product Review Sentiment Distribution')
plt.show()
```

---

## 2. å‘½åå¯¦é«”è­˜åˆ¥ (Named Entity Recognition, NER)

### 2.1 ä»€éº¼æ˜¯ NER?

**NER** æ˜¯å¾æ–‡æœ¬ä¸­æå–ä¸¦åˆ†é¡å¯¦é«” (äººåã€åœ°åã€çµ„ç¹”ã€æ—¥æœŸç­‰)ã€‚

#### å¸¸è¦‹å¯¦é«”é¡å‹

| é¡å‹ | è‹±æ–‡ | ç¯„ä¾‹ |
|------|------|------|
| äººå | PER (Person) | Steve Jobs, é¦¬é›² |
| åœ°å | LOC (Location) | California, å°åŒ— |
| çµ„ç¹” | ORG (Organization) | Apple, é˜¿é‡Œå·´å·´ |
| æ—¥æœŸ | DATE | 2024-01-01 |
| é‡‘é¡ | MONEY | $1,000 |

---

### 2.2 ä½¿ç”¨ Pipeline å¯¦ä½œ

#### åŸºç¤ NER

```python
# å‰µå»º NER pipeline
ner = pipeline("ner", grouped_entities=True)

text = """
Apple was founded by Steve Jobs, Steve Wozniak, and Ronald Wayne
in April 1976 in Cupertino, California.
"""

entities = ner(text)

# è¼¸å‡ºçµæœ
for entity in entities:
    print(f"{entity['word']:20} â†’ {entity['entity_group']:5} ({entity['score']:.2%})")
```

**è¼¸å‡º**:
```
Apple                â†’ ORG   (99.87%)
Steve Jobs           â†’ PER   (99.92%)
Steve Wozniak        â†’ PER   (99.88%)
Ronald Wayne         â†’ PER   (99.85%)
April 1976           â†’ DATE  (98.76%)
Cupertino            â†’ LOC   (99.65%)
California           â†’ LOC   (99.78%)
```

---

### 2.3 é€²éšé…ç½®

#### ä¸åˆä½µå¯¦é«”

```python
# ä¸åˆä½µ entities (token-level)
ner_token = pipeline("ner")

text = "Steve Jobs founded Apple in California."
entities = ner_token(text)

for entity in entities:
    print(f"Token: {entity['word']:15} | Entity: {entity['entity']:10} | Score: {entity['score']:.2%}")
```

**è¼¸å‡º**:
```
Token: Steve           | Entity: B-PER      | Score: 99.92%
Token: Jobs            | Entity: I-PER      | Score: 99.89%
Token: Apple           | Entity: B-ORG      | Score: 99.87%
Token: California      | Entity: B-LOC      | Score: 99.78%
```

**æ¨™ç±¤èªªæ˜**:
- `B-PER`: Beginning of Person
- `I-PER`: Inside Person
- `B-ORG`: Beginning of Organization

---

### 2.4 å¯¦æˆ°æ¡ˆä¾‹: æ–°èæ–‡ç« å¯¦é«”æå–

```python
# æ–°èæ–‡ç« ç¯„ä¾‹
article = """
OpenAI CEO Sam Altman announced the release of GPT-4 in San Francisco
on March 14, 2023. The new model, developed in collaboration with
Microsoft, represents a major breakthrough in artificial intelligence.
The company plans to invest $10 billion in AI research over the next
five years.
"""

# NER åˆ†æ
ner = pipeline("ner", grouped_entities=True)
entities = ner(article)

# æŒ‰é¡å‹åˆ†çµ„
from collections import defaultdict
entities_by_type = defaultdict(list)

for entity in entities:
    entities_by_type[entity['entity_group']].append(entity['word'])

# è¼¸å‡º
print("ğŸ“° æ–°èæ–‡ç« å¯¦é«”æå–çµæœ\n")
for entity_type, words in entities_by_type.items():
    print(f"{entity_type}:")
    for word in set(words):  # å»é‡
        print(f"  - {word}")
    print()
```

**è¼¸å‡º**:
```
ğŸ“° æ–°èæ–‡ç« å¯¦é«”æå–çµæœ

PER:
  - Sam Altman

ORG:
  - OpenAI
  - Microsoft

LOC:
  - San Francisco

DATE:
  - March 14, 2023
```

---

## 3. é›¶æ¨£æœ¬åˆ†é¡ (Zero-Shot Classification)

### 3.1 ä»€éº¼æ˜¯é›¶æ¨£æœ¬åˆ†é¡?

**é›¶æ¨£æœ¬åˆ†é¡**å…è¨±ä½ **ä¸éœ€è¦è¨“ç·´æ•¸æ“š**å°±èƒ½å°æ–‡æœ¬é€²è¡Œåˆ†é¡ã€‚

#### å‚³çµ±åˆ†é¡ vs é›¶æ¨£æœ¬åˆ†é¡

| æ–¹æ³• | éœ€è¦è¨“ç·´æ•¸æ“š? | éˆæ´»æ€§ | é©ç”¨å ´æ™¯ |
|------|-------------|--------|----------|
| **å‚³çµ±åˆ†é¡** | âœ… éœ€è¦ (1000+ æ¨£æœ¬) | ä½ (å›ºå®šé¡åˆ¥) | é•·æœŸç©©å®šä»»å‹™ |
| **é›¶æ¨£æœ¬åˆ†é¡** | âŒ ä¸éœ€è¦ | é«˜ (å‹•æ…‹é¡åˆ¥) | å¿«é€ŸåŸå‹ã€éˆæ´»ä»»å‹™ |

---

### 3.2 ä½¿ç”¨ Pipeline å¯¦ä½œ

#### åŸºç¤ä½¿ç”¨

```python
# å‰µå»ºé›¶æ¨£æœ¬åˆ†é¡å™¨
classifier = pipeline(
    "zero-shot-classification",
    model="facebook/bart-large-mnli"
)

# æ–‡æœ¬
text = "I'm having trouble logging into my account."

# å€™é¸æ¨™ç±¤ (ç„¡éœ€è¨“ç·´!)
candidate_labels = [
    "Technical Support",
    "Billing Question",
    "Product Inquiry",
    "Account Issue"
]

# åˆ†é¡
result = classifier(text, candidate_labels)

# è¼¸å‡º
print(f"Text: {text}\n")
for label, score in zip(result['labels'], result['scores']):
    print(f"{label:20} â†’ {score:.2%}")
```

**è¼¸å‡º**:
```
Text: I'm having trouble logging into my account.

Account Issue        â†’ 89.76%
Technical Support    â†’ 6.45%
Billing Question     â†’ 2.34%
Product Inquiry      â†’ 1.45%
```

---

### 3.3 å¤šæ¨™ç±¤åˆ†é¡

```python
# å¤šæ¨™ç±¤åˆ†é¡ (ä¸€å€‹æ–‡æœ¬å¯æœ‰å¤šå€‹æ¨™ç±¤)
text = "This smartphone has excellent camera quality but poor battery life."

labels = ["Camera Quality", "Battery Life", "Screen Quality", "Price"]

result = classifier(
    text,
    labels,
    multi_label=True  # å•Ÿç”¨å¤šæ¨™ç±¤
)

print("Multi-Label Results:\n")
for label, score in zip(result['labels'], result['scores']):
    if score > 0.5:  # åªé¡¯ç¤ºé«˜ä¿¡å¿ƒæ¨™ç±¤
        print(f"âœ“ {label:20} ({score:.2%})")
```

**è¼¸å‡º**:
```
Multi-Label Results:

âœ“ Camera Quality      (95.34%)
âœ“ Battery Life        (92.18%)
```

---

### 3.4 å¯¦æˆ°æ¡ˆä¾‹: å®¢æœéƒµä»¶è‡ªå‹•è·¯ç”±

```python
# å®¢æœéƒµä»¶åˆ†é¡ç³»çµ±
classifier = pipeline("zero-shot-classification")

# éƒ¨é–€æ¨™ç±¤
departments = [
    "Technical Support",
    "Billing & Payments",
    "Shipping & Delivery",
    "Product Questions",
    "Returns & Refunds"
]

# éƒµä»¶ç¯„ä¾‹
emails = [
    "My order hasn't arrived yet. Where is it?",
    "I was charged twice for the same order.",
    "How do I reset my password?",
    "Can I return this product if I don't like it?",
    "What are the specifications of this laptop?"
]

# æ‰¹é‡åˆ†é¡
print("ğŸ“§ å®¢æœéƒµä»¶è‡ªå‹•è·¯ç”±\n")
for i, email in enumerate(emails, 1):
    result = classifier(email, departments)
    top_label = result['labels'][0]
    confidence = result['scores'][0]

    print(f"Email {i}: {email[:50]}...")
    print(f"  â†’ Route to: {top_label} ({confidence:.1%})\n")
```

---

## 4. æ–‡æœ¬æ‘˜è¦ (Summarization)

### 4.1 ä»€éº¼æ˜¯æ–‡æœ¬æ‘˜è¦?

**æ–‡æœ¬æ‘˜è¦**æ˜¯å°‡é•·æ–‡æœ¬æ¿ƒç¸®æˆç°¡çŸ­æ‘˜è¦,ä¿ç•™æ ¸å¿ƒè³‡è¨Šã€‚

#### æ‘˜è¦é¡å‹

| é¡å‹ | èªªæ˜ | ç¯„ä¾‹ |
|------|------|------|
| **æŠ½å–å¼** | ç›´æ¥é¸å–åŸæ–‡å¥å­ | å‚³çµ±æ–¹æ³• (TextRank) |
| **ç”Ÿæˆå¼** | ç”Ÿæˆæ–°çš„æ‘˜è¦æ–‡æœ¬ | Transformer æ¨¡å‹ (T5, BART) |

---

### 4.2 ä½¿ç”¨ Pipeline å¯¦ä½œ

#### åŸºç¤æ‘˜è¦

```python
# å‰µå»ºæ‘˜è¦å™¨
summarizer = pipeline("summarization", model="facebook/bart-large-cnn")

# é•·æ–‡æœ¬
article = """
Artificial intelligence (AI) is intelligence demonstrated by machines,
in contrast to the natural intelligence displayed by humans and animals.
Leading AI textbooks define the field as the study of "intelligent agents":
any device that perceives its environment and takes actions that maximize
its chance of successfully achieving its goals. Colloquially, the term
"artificial intelligence" is often used to describe machines (or computers)
that mimic "cognitive" functions that humans associate with the human mind,
such as "learning" and "problem solving".

As machines become increasingly capable, tasks considered to require
"intelligence" are often removed from the definition of AI, a phenomenon
known as the AI effect. A quip in Tesler's Theorem says "AI is whatever
hasn't been done yet." For instance, optical character recognition is
frequently excluded from things considered to be AI, having become a
routine technology. Modern machine capabilities generally classified as
AI include successfully understanding human speech, competing at the
highest level in strategic game systems, autonomously operating cars,
intelligent routing in content delivery networks, and military simulations.
"""

# ç”Ÿæˆæ‘˜è¦
summary = summarizer(
    article,
    max_length=100,
    min_length=30,
    do_sample=False
)

print("ğŸ“„ åŸæ–‡é•·åº¦:", len(article.split()))
print("\næ‘˜è¦:")
print(summary[0]['summary_text'])
```

---

### 4.3 é€²éšåƒæ•¸èª¿æ•´

```python
# ä¸åŒé•·åº¦çš„æ‘˜è¦
summary_short = summarizer(
    article,
    max_length=50,
    min_length=20,
    do_sample=False
)

summary_medium = summarizer(
    article,
    max_length=100,
    min_length=50,
    do_sample=False
)

summary_long = summarizer(
    article,
    max_length=150,
    min_length=80,
    do_sample=False
)

print("ç°¡çŸ­æ‘˜è¦ (50 words):")
print(summary_short[0]['summary_text'])

print("\nä¸­ç­‰æ‘˜è¦ (100 words):")
print(summary_medium[0]['summary_text'])

print("\nè©³ç´°æ‘˜è¦ (150 words):")
print(summary_long[0]['summary_text'])
```

---

### 4.4 å¯¦æˆ°æ¡ˆä¾‹: æ–°èæ‘˜è¦ç³»çµ±

```python
# æ–°èæ–‡ç« ç¯„ä¾‹
news_article = """
(é•·ç¯‡æ–°èå…§å®¹...)
"""

# æ‘˜è¦å™¨
summarizer = pipeline("summarization")

# ç”Ÿæˆæ‘˜è¦
summary = summarizer(
    news_article,
    max_length=130,
    min_length=30,
    do_sample=False
)[0]['summary_text']

# è¼¸å‡ºæ ¼å¼åŒ–
print("=" * 70)
print("ğŸ“° æ–°èå¿«è¨Š")
print("=" * 70)
print(f"\n{summary}\n")
print("=" * 70)
```

---

## 5. æ–‡æœ¬ç”Ÿæˆ (Text Generation)

### 5.1 ä»€éº¼æ˜¯æ–‡æœ¬ç”Ÿæˆ?

**æ–‡æœ¬ç”Ÿæˆ**æ˜¯çµ¦å®šé–‹é ­ (prompt),æ¨¡å‹è‡ªå‹•çºŒå¯«å¾ŒçºŒæ–‡æœ¬ã€‚

#### æ‡‰ç”¨å ´æ™¯

- âœï¸ AI å¯«ä½œåŠ©æ‰‹
- ğŸ’¬ èŠå¤©æ©Ÿå™¨äºº
- ğŸ“§ éƒµä»¶è‡ªå‹•å›è¦†
- ğŸ“ å…§å®¹å‰µä½œè¼”åŠ©

---

### 5.2 ä½¿ç”¨ Pipeline å¯¦ä½œ

#### åŸºç¤ç”Ÿæˆ

```python
# å‰µå»ºæ–‡æœ¬ç”Ÿæˆå™¨
generator = pipeline("text-generation", model="gpt2")

# Prompt
prompt = "Artificial intelligence will"

# ç”Ÿæˆæ–‡æœ¬
output = generator(
    prompt,
    max_length=50,
    num_return_sequences=3,
    temperature=0.7
)

print(f"Prompt: {prompt}\n")
for i, result in enumerate(output, 1):
    print(f"Version {i}:")
    print(result['generated_text'])
    print()
```

---

### 5.3 åƒæ•¸èª¿æ•´

#### æº«åº¦ (Temperature)

```python
# ä½æº«åº¦ (0.3) - ä¿å®ˆã€ç¢ºå®šæ€§é«˜
output_low_temp = generator(
    "Once upon a time",
    max_length=50,
    temperature=0.3,
    num_return_sequences=1
)

# é«˜æº«åº¦ (1.5) - å‰µæ„ã€å¤šæ¨£æ€§é«˜
output_high_temp = generator(
    "Once upon a time",
    max_length=50,
    temperature=1.5,
    num_return_sequences=1
)

print("ä½æº«åº¦ (0.3) - æ›´ä¿å®ˆ:")
print(output_low_temp[0]['generated_text'])

print("\né«˜æº«åº¦ (1.5) - æ›´å‰µæ„:")
print(output_high_temp[0]['generated_text'])
```

#### Top-k å’Œ Top-p æ¡æ¨£

```python
# Top-k sampling (åªå¾æœ€å¯èƒ½çš„ k å€‹è©ä¸­é¸)
output_topk = generator(
    "The future of technology is",
    max_length=50,
    top_k=50,
    num_return_sequences=1
)

# Top-p (nucleus) sampling
output_topp = generator(
    "The future of technology is",
    max_length=50,
    top_p=0.9,
    num_return_sequences=1
)
```

---

### 5.4 å¯¦æˆ°æ¡ˆä¾‹: AI å¯«ä½œåŠ©æ‰‹

```python
# ä¸åŒé¢¨æ ¼çš„æ–‡æœ¬ç”Ÿæˆ
prompts = {
    "æ–°èå ±å°": "Breaking news: Scientists have discovered",
    "æ•…äº‹å‰µä½œ": "In a distant galaxy, a young hero",
    "æŠ€è¡“æ–‡ç« ": "Machine learning is a subset of AI that",
    "ç”¢å“æè¿°": "Introducing our latest smartphone with"
}

generator = pipeline("text-generation", model="gpt2")

for style, prompt in prompts.items():
    print(f"\nğŸ“ {style}:")
    print("-" * 60)

    output = generator(
        prompt,
        max_length=80,
        num_return_sequences=1,
        temperature=0.8
    )

    print(output[0]['generated_text'])
```

---

## 6. æ¨¡å‹é¸æ“‡æŒ‡å—

### 6.1 ä»»å‹™ vs æ¨¡å‹å°ç…§è¡¨

| ä»»å‹™ | æ¨è–¦æ¨¡å‹ | å¤§å° | é€Ÿåº¦ | ç²¾åº¦ |
|------|---------|------|------|------|
| **æƒ…æ„Ÿåˆ†æ** | `distilbert-base-uncased-finetuned-sst-2` | å° | âš¡âš¡âš¡ | â­â­â­â­ |
| **NER** | `dslim/bert-base-NER` | ä¸­ | âš¡âš¡ | â­â­â­â­â­ |
| **é›¶æ¨£æœ¬** | `facebook/bart-large-mnli` | å¤§ | âš¡ | â­â­â­â­â­ |
| **æ‘˜è¦** | `facebook/bart-large-cnn` | å¤§ | âš¡ | â­â­â­â­â­ |
| **ç”Ÿæˆ** | `gpt2` / `gpt2-medium` | ä¸­-å¤§ | âš¡âš¡ | â­â­â­â­ |

---

### 6.2 ä¸­æ–‡æ¨¡å‹æ¨è–¦

```python
# ä¸­æ–‡æƒ…æ„Ÿåˆ†æ
sentiment_zh = pipeline(
    "sentiment-analysis",
    model="uer/roberta-base-finetuned-chinanews-chinese"
)

# ä¸­æ–‡ NER
ner_zh = pipeline(
    "ner",
    model="ckiplab/bert-base-chinese-ner",
    grouped_entities=True
)

# ä¸­æ–‡æ–‡æœ¬ç”Ÿæˆ
generator_zh = pipeline(
    "text-generation",
    model="uer/gpt2-chinese-cluecorpussmall"
)
```

---

## 7. æ€§èƒ½å„ªåŒ–æŠ€å·§

### 7.1 æ‰¹é‡è™•ç†

```python
# âŒ æ…¢: é€å€‹è™•ç†
texts = ["text1", "text2", ..., "text1000"]

results = []
for text in texts:
    result = classifier(text)  # 1000 æ¬¡èª¿ç”¨
    results.append(result)

# âœ… å¿«: æ‰¹é‡è™•ç†
results = classifier(texts, batch_size=32)  # ~30 æ¬¡èª¿ç”¨
```

**åŠ é€Ÿæ¯”**: ~30x

---

### 7.2 ä½¿ç”¨ GPU

```python
import torch

# æª¢æŸ¥ GPU
device = 0 if torch.cuda.is_available() else -1

# åœ¨ GPU ä¸Šé‹è¡Œ
classifier = pipeline(
    "sentiment-analysis",
    device=device  # 0 = GPU, -1 = CPU
)
```

---

### 7.3 æ¨¡å‹é‡åŒ–

```python
# ä½¿ç”¨é‡åŒ–æ¨¡å‹ (æ›´å°æ›´å¿«)
classifier_quantized = pipeline(
    "sentiment-analysis",
    model="distilbert-base-uncased-finetuned-sst-2-english",
    device=-1  # CPU
)

# å‹•æ…‹é‡åŒ– (é€²éš)
import torch
model = classifier_quantized.model
quantized_model = torch.quantization.quantize_dynamic(
    model,
    {torch.nn.Linear},
    dtype=torch.qint8
)
```

---

## 8. èª²å¾Œç·´ç¿’

### ç·´ç¿’ 1: æƒ…æ„Ÿåˆ†æå„€è¡¨æ¿

å»ºç«‹ä¸€å€‹ç”¢å“è©•è«–åˆ†æç³»çµ±:
1. è®€å– 100+ æ¢è©•è«–
2. åˆ†ææƒ…æ„Ÿ
3. ç”Ÿæˆçµ±è¨ˆå ±è¡¨
4. å¯è¦–åŒ–çµæœ

### ç·´ç¿’ 2: æ™ºèƒ½å®¢æœè·¯ç”±

å¯¦ä½œå®¢æœéƒµä»¶è‡ªå‹•åˆ†é¡:
1. å®šç¾© 5 å€‹éƒ¨é–€é¡åˆ¥
2. ä½¿ç”¨é›¶æ¨£æœ¬åˆ†é¡
3. è¨ˆç®—æº–ç¢ºç‡

### ç·´ç¿’ 3: æ–°èæ‘˜è¦å™¨

å»ºç«‹æ–°èæ‘˜è¦å·¥å…·:
1. çˆ¬å– 5 ç¯‡æ–°è
2. ç”Ÿæˆæ‘˜è¦
3. æ¯”è¼ƒä¸åŒæ¨¡å‹æ•ˆæœ

---

## 9. ç¸½çµ

### âœ… æ ¸å¿ƒè¦é»

1. **5 å¤§æ ¸å¿ƒä»»å‹™**
   - æƒ…æ„Ÿåˆ†æ: åˆ¤æ–·æƒ…ç·’
   - NER: æå–å¯¦é«”
   - é›¶æ¨£æœ¬åˆ†é¡: ç„¡éœ€è¨“ç·´æ•¸æ“š
   - æ‘˜è¦: æ¿ƒç¸®é•·æ–‡æœ¬
   - ç”Ÿæˆ: çºŒå¯«æ–‡æœ¬

2. **Pipeline å„ªå‹¢**
   - ç°¡å–®æ˜“ç”¨ (3 è¡Œä»£ç¢¼)
   - è‡ªå‹•è™•ç†é è™•ç†
   - æ”¯æ´æ‰¹é‡æ“ä½œ

3. **æ¨¡å‹é¸æ“‡**
   - æ ¹æ“šä»»å‹™é¸æ¨¡å‹
   - å¹³è¡¡é€Ÿåº¦èˆ‡ç²¾åº¦
   - è€ƒæ…®èªè¨€éœ€æ±‚

### ğŸ¯ ä¸‹ä¸€æ­¥

è¬›ç¾© 03: æ¨¡å‹å¾®èª¿èˆ‡éƒ¨ç½²å¯¦æˆ°

---

**è¬›ç¾©ç‰ˆæœ¬**: v1.0
**æœ€å¾Œæ›´æ–°**: 2025-10-17
**ä½œè€…**: iSpan NLP Team / Claude AI
