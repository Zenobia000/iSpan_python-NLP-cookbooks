{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CH08-09: 專案實戰 - 客戶意見分析儀 (Customer Feedback Analyzer)\n",
    "\n",
    "---\n",
    "\n",
    "## 📚 專案目標\n",
    "\n",
    "建立一套**完整的客戶意見分析系統**,能夠:\n",
    "\n",
    "1. 🎯 **情感分析**: 自動判斷客戶評論是正面/負面/中性\n",
    "2. 🏷️ **主題分類**: 識別評論涉及的產品類別或問題類型\n",
    "3. 🔍 **關鍵字提取**: 找出客戶最關注的議題\n",
    "4. 📊 **可視化儀表板**: 呈現分析結果與趨勢\n",
    "5. 🚀 **實際部署**: 建立 API 供業務系統調用\n",
    "\n",
    "### 商業價值\n",
    "\n",
    "- **自動化處理**: 每天數千筆評論自動分析\n",
    "- **即時反饋**: 快速發現客戶不滿與產品問題\n",
    "- **數據驅動**: 客觀量化客戶滿意度\n",
    "- **成本節省**: 減少人工審閱時間 90%\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 專案架構\n",
    "\n",
    "```\n",
    "客戶評論 (Raw Reviews)\n",
    "    ↓\n",
    "預處理 (Preprocessing)\n",
    "    ├── 去除噪音\n",
    "    ├── 文本清理\n",
    "    └── Tokenization\n",
    "    ↓\n",
    "NLP 分析 (NLP Pipeline)\n",
    "    ├── 情感分析 (Sentiment)\n",
    "    ├── 主題分類 (Topic)\n",
    "    └── 關鍵字提取 (Keywords)\n",
    "    ↓\n",
    "結果整合 (Aggregation)\n",
    "    ├── 統計分析\n",
    "    ├── 趨勢分析\n",
    "    └── 異常檢測\n",
    "    ↓\n",
    "可視化輸出 (Visualization)\n",
    "    ├── 情感分布圖\n",
    "    ├── 主題熱點圖\n",
    "    └── 詞雲 (Word Cloud)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 🔧 環境準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# !pip install transformers datasets torch\n",
    "# !pip install pandas numpy matplotlib seaborn plotly\n",
    "# !pip install wordcloud scikit-learn nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from transformers import pipeline\n",
    "from collections import Counter\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"✅ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📊 數據準備\n",
    "\n",
    "### 1. 生成模擬客戶評論數據\n",
    "\n",
    "在實際應用中,你會從以下來源獲取數據:\n",
    "- 電商平台 (Amazon, PChome)\n",
    "- Google Reviews\n",
    "- 客服系統\n",
    "- 社交媒體 (Facebook, Twitter)\n",
    "\n",
    "這裡我們生成模擬數據進行演示:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic customer reviews\n",
    "np.random.seed(42)\n",
    "\n",
    "# Sample reviews with different sentiments and topics\n",
    "positive_reviews = [\n",
    "    \"Excellent product! Fast shipping and great quality. Highly recommend!\",\n",
    "    \"Love this item! Exactly as described. Will buy again.\",\n",
    "    \"Amazing customer service. They resolved my issue quickly.\",\n",
    "    \"Best purchase I've made this year. Super satisfied!\",\n",
    "    \"Great value for money. The product exceeded my expectations.\",\n",
    "    \"Fast delivery and product is in perfect condition. Very happy!\",\n",
    "    \"Outstanding quality! This is exactly what I was looking for.\",\n",
    "    \"Fantastic experience from order to delivery. Five stars!\",\n",
    "]\n",
    "\n",
    "negative_reviews = [\n",
    "    \"Terrible quality. Product broke after two days. Very disappointed.\",\n",
    "    \"Shipping took forever. Item arrived damaged. Not happy.\",\n",
    "    \"Poor customer service. They didn't respond to my complaints.\",\n",
    "    \"Complete waste of money. Product doesn't work as advertised.\",\n",
    "    \"Do not buy! Cheap materials and terrible build quality.\",\n",
    "    \"Worst purchase ever. Requesting a full refund immediately.\",\n",
    "    \"Product is defective. Customer support was unhelpful.\",\n",
    "    \"Very disappointed with the quality. Not worth the price.\",\n",
    "]\n",
    "\n",
    "neutral_reviews = [\n",
    "    \"Product is okay. Nothing special but does the job.\",\n",
    "    \"Average quality. Shipping was standard. No complaints.\",\n",
    "    \"It's fine. Meets basic expectations but nothing more.\",\n",
    "    \"Decent product for the price. Not amazing, not terrible.\",\n",
    "    \"Standard item. Delivery was on time. No issues.\",\n",
    "    \"Acceptable quality. Could be better but works as intended.\",\n",
    "]\n",
    "\n",
    "# Topics\n",
    "topics = ['Product Quality', 'Shipping', 'Customer Service', 'Pricing', 'Features']\n",
    "\n",
    "# Generate dataset\n",
    "num_reviews = 300\n",
    "reviews_data = []\n",
    "\n",
    "for i in range(num_reviews):\n",
    "    # Random sentiment distribution: 50% positive, 30% negative, 20% neutral\n",
    "    sentiment_choice = np.random.choice(['positive', 'negative', 'neutral'], p=[0.5, 0.3, 0.2])\n",
    "    \n",
    "    if sentiment_choice == 'positive':\n",
    "        review_text = np.random.choice(positive_reviews)\n",
    "    elif sentiment_choice == 'negative':\n",
    "        review_text = np.random.choice(negative_reviews)\n",
    "    else:\n",
    "        review_text = np.random.choice(neutral_reviews)\n",
    "    \n",
    "    # Generate random date (last 30 days)\n",
    "    review_date = datetime.now() - timedelta(days=np.random.randint(0, 30))\n",
    "    \n",
    "    # Random rating (1-5 stars)\n",
    "    if sentiment_choice == 'positive':\n",
    "        rating = np.random.choice([4, 5], p=[0.3, 0.7])\n",
    "    elif sentiment_choice == 'negative':\n",
    "        rating = np.random.choice([1, 2], p=[0.6, 0.4])\n",
    "    else:\n",
    "        rating = 3\n",
    "    \n",
    "    reviews_data.append({\n",
    "        'id': f'REV{i+1:04d}',\n",
    "        'date': review_date.strftime('%Y-%m-%d'),\n",
    "        'rating': rating,\n",
    "        'review': review_text,\n",
    "        'topic': np.random.choice(topics)\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(reviews_data)\n",
    "\n",
    "print(f\"✅ Generated {len(df):,} synthetic customer reviews\")\n",
    "print(f\"\\n📊 Dataset shape: {df.shape}\")\n",
    "print(f\"\\n🔍 Sample data:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset overview\n",
    "print(\"📋 Dataset Information:\\n\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\n📈 Rating Distribution:\")\n",
    "print(df['rating'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 數據探索性分析 (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize rating distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Rating counts\n",
    "rating_counts = df['rating'].value_counts().sort_index()\n",
    "axes[0].bar(rating_counts.index, rating_counts.values, color='steelblue')\n",
    "axes[0].set_title('Rating Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Rating (Stars)')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_xticks([1, 2, 3, 4, 5])\n",
    "\n",
    "# Topic distribution\n",
    "topic_counts = df['topic'].value_counts()\n",
    "axes[1].barh(topic_counts.index, topic_counts.values, color='coral')\n",
    "axes[1].set_title('Topic Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Count')\n",
    "axes[1].set_ylabel('Topic')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series: reviews over time\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "daily_reviews = df.groupby('date').size().reset_index(name='count')\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(daily_reviews['date'], daily_reviews['count'], marker='o', linewidth=2, color='steelblue')\n",
    "plt.title('Daily Review Volume', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Reviews')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🤖 NLP 模型載入\n",
    "\n",
    "### 載入情感分析模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sentiment analysis pipeline\n",
    "print(\"📦 Loading sentiment analysis model...\")\n",
    "\n",
    "sentiment_analyzer = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "    device=0 if __import__('torch').cuda.is_available() else -1  # Use GPU if available\n",
    ")\n",
    "\n",
    "print(\"✅ Sentiment analyzer loaded!\")\n",
    "\n",
    "# Test the model\n",
    "test_text = \"This product is amazing! I love it!\"\n",
    "result = sentiment_analyzer(test_text)[0]\n",
    "print(f\"\\n🧪 Test prediction:\")\n",
    "print(f\"   Text: {test_text}\")\n",
    "print(f\"   Sentiment: {result['label']} (Score: {result['score']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🔍 情感分析\n",
    "\n",
    "### 批量處理所有評論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze sentiment for all reviews\n",
    "print(\"🔄 Analyzing sentiment for all reviews...\\n\")\n",
    "\n",
    "# Process in batches for efficiency\n",
    "batch_size = 32\n",
    "sentiments = []\n",
    "sentiment_scores = []\n",
    "\n",
    "for i in range(0, len(df), batch_size):\n",
    "    batch = df['review'].iloc[i:i+batch_size].tolist()\n",
    "    results = sentiment_analyzer(batch)\n",
    "    \n",
    "    for result in results:\n",
    "        sentiments.append(result['label'])\n",
    "        sentiment_scores.append(result['score'])\n",
    "    \n",
    "    # Progress indicator\n",
    "    progress = min((i + batch_size) / len(df) * 100, 100)\n",
    "    print(f\"\\rProgress: {progress:.1f}% ({min(i+batch_size, len(df))}/{len(df)})\", end='')\n",
    "\n",
    "print(\"\\n\\n✅ Sentiment analysis completed!\")\n",
    "\n",
    "# Add results to DataFrame\n",
    "df['predicted_sentiment'] = sentiments\n",
    "df['sentiment_confidence'] = sentiment_scores\n",
    "\n",
    "print(f\"\\n📊 Sentiment Distribution:\")\n",
    "print(df['predicted_sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample predictions\n",
    "print(\"\\n🔍 Sample Predictions:\\n\")\n",
    "sample_df = df[['review', 'predicted_sentiment', 'sentiment_confidence']].head(10)\n",
    "for idx, row in sample_df.iterrows():\n",
    "    print(f\"Review: {row['review'][:60]}...\")\n",
    "    print(f\"Sentiment: {row['predicted_sentiment']} (Confidence: {row['sentiment_confidence']:.2%})\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 情感分析結果可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sentiment distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Sentiment pie chart\n",
    "sentiment_counts = df['predicted_sentiment'].value_counts()\n",
    "colors = ['#2ecc71', '#e74c3c']  # Green for positive, red for negative\n",
    "axes[0, 0].pie(\n",
    "    sentiment_counts.values,\n",
    "    labels=sentiment_counts.index,\n",
    "    autopct='%1.1f%%',\n",
    "    startangle=90,\n",
    "    colors=colors\n",
    ")\n",
    "axes[0, 0].set_title('Overall Sentiment Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# 2. Confidence distribution\n",
    "axes[0, 1].hist(df['sentiment_confidence'], bins=30, color='steelblue', edgecolor='black')\n",
    "axes[0, 1].set_title('Sentiment Confidence Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Confidence Score')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].axvline(df['sentiment_confidence'].mean(), color='red', linestyle='--', label='Mean')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# 3. Sentiment by topic\n",
    "sentiment_by_topic = pd.crosstab(df['topic'], df['predicted_sentiment'])\n",
    "sentiment_by_topic.plot(kind='bar', ax=axes[1, 0], color=colors, width=0.7)\n",
    "axes[1, 0].set_title('Sentiment by Topic', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Topic')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "axes[1, 0].legend(title='Sentiment')\n",
    "\n",
    "# 4. Rating vs Sentiment\n",
    "rating_sentiment = pd.crosstab(df['rating'], df['predicted_sentiment'], normalize='index') * 100\n",
    "rating_sentiment.plot(kind='bar', ax=axes[1, 1], color=colors, width=0.7)\n",
    "axes[1, 1].set_title('Sentiment Distribution by Rating', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Rating (Stars)')\n",
    "axes[1, 1].set_ylabel('Percentage (%)')\n",
    "axes[1, 1].tick_params(axis='x', rotation=0)\n",
    "axes[1, 1].legend(title='Sentiment')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🏷️ 關鍵字提取\n",
    "\n",
    "### 提取高頻詞彙"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing for keyword extraction\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK data (run once)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def extract_keywords(text, top_n=10):\n",
    "    \"\"\"\n",
    "    Extract top keywords from text\n",
    "    Args:\n",
    "        text: input text\n",
    "        top_n: number of top keywords to return\n",
    "    Returns:\n",
    "        list of (keyword, frequency) tuples\n",
    "    \"\"\"\n",
    "    # Lowercase and remove special characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text.lower())\n",
    "    \n",
    "    # Tokenize\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords and short words\n",
    "    keywords = [w for w in words if w not in stop_words and len(w) > 3]\n",
    "    \n",
    "    # Count frequencies\n",
    "    word_freq = Counter(keywords)\n",
    "    \n",
    "    return word_freq.most_common(top_n)\n",
    "\n",
    "print(\"✅ Keyword extraction function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract keywords from positive and negative reviews separately\n",
    "positive_text = ' '.join(df[df['predicted_sentiment'] == 'POSITIVE']['review'])\n",
    "negative_text = ' '.join(df[df['predicted_sentiment'] == 'NEGATIVE']['review'])\n",
    "\n",
    "positive_keywords = extract_keywords(positive_text, top_n=15)\n",
    "negative_keywords = extract_keywords(negative_text, top_n=15)\n",
    "\n",
    "print(\"✅ Top Keywords in Positive Reviews:\")\n",
    "for word, freq in positive_keywords:\n",
    "    print(f\"   {word}: {freq}\")\n",
    "\n",
    "print(\"\\n❌ Top Keywords in Negative Reviews:\")\n",
    "for word, freq in negative_keywords:\n",
    "    print(f\"   {word}: {freq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 詞雲可視化 (Word Cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate word clouds\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Positive word cloud\n",
    "positive_wordcloud = WordCloud(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    background_color='white',\n",
    "    colormap='Greens',\n",
    "    stopwords=stop_words\n",
    ").generate(positive_text)\n",
    "\n",
    "axes[0].imshow(positive_wordcloud, interpolation='bilinear')\n",
    "axes[0].set_title('Positive Reviews - Word Cloud', fontsize=14, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Negative word cloud\n",
    "negative_wordcloud = WordCloud(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    background_color='white',\n",
    "    colormap='Reds',\n",
    "    stopwords=stop_words\n",
    ").generate(negative_text)\n",
    "\n",
    "axes[1].imshow(negative_wordcloud, interpolation='bilinear')\n",
    "axes[1].set_title('Negative Reviews - Word Cloud', fontsize=14, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📊 綜合分析報告\n",
    "\n",
    "### 生成業務洞察報告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive analysis report\n",
    "def generate_analysis_report(df):\n",
    "    \"\"\"\n",
    "    Generate business insights report\n",
    "    \"\"\"\n",
    "    report = {}\n",
    "    \n",
    "    # Overall metrics\n",
    "    total_reviews = len(df)\n",
    "    avg_rating = df['rating'].mean()\n",
    "    positive_pct = (df['predicted_sentiment'] == 'POSITIVE').sum() / total_reviews * 100\n",
    "    negative_pct = (df['predicted_sentiment'] == 'NEGATIVE').sum() / total_reviews * 100\n",
    "    avg_confidence = df['sentiment_confidence'].mean()\n",
    "    \n",
    "    report['overview'] = {\n",
    "        'total_reviews': total_reviews,\n",
    "        'avg_rating': round(avg_rating, 2),\n",
    "        'positive_percentage': round(positive_pct, 1),\n",
    "        'negative_percentage': round(negative_pct, 1),\n",
    "        'avg_confidence': round(avg_confidence, 3)\n",
    "    }\n",
    "    \n",
    "    # Topic-level insights\n",
    "    topic_analysis = df.groupby('topic').agg({\n",
    "        'rating': 'mean',\n",
    "        'predicted_sentiment': lambda x: (x == 'POSITIVE').sum() / len(x) * 100\n",
    "    }).round(2)\n",
    "    topic_analysis.columns = ['avg_rating', 'positive_pct']\n",
    "    report['topic_insights'] = topic_analysis.to_dict('index')\n",
    "    \n",
    "    # Identify problem areas (topics with low ratings)\n",
    "    problem_topics = topic_analysis[topic_analysis['avg_rating'] < 3.5].index.tolist()\n",
    "    report['problem_areas'] = problem_topics\n",
    "    \n",
    "    # Identify strengths (topics with high ratings)\n",
    "    strength_topics = topic_analysis[topic_analysis['avg_rating'] >= 4.5].index.tolist()\n",
    "    report['strengths'] = strength_topics\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Generate report\n",
    "report = generate_analysis_report(df)\n",
    "\n",
    "# Print formatted report\n",
    "print(\"=\" * 70)\n",
    "print(\"📊 CUSTOMER FEEDBACK ANALYSIS REPORT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n📌 OVERVIEW\")\n",
    "print(f\"   Total Reviews Analyzed: {report['overview']['total_reviews']:,}\")\n",
    "print(f\"   Average Rating: {report['overview']['avg_rating']} / 5.0\")\n",
    "print(f\"   Positive Sentiment: {report['overview']['positive_percentage']}%\")\n",
    "print(f\"   Negative Sentiment: {report['overview']['negative_percentage']}%\")\n",
    "print(f\"   Average Confidence: {report['overview']['avg_confidence']:.1%}\")\n",
    "\n",
    "print(\"\\n📈 TOPIC-LEVEL INSIGHTS\")\n",
    "for topic, metrics in report['topic_insights'].items():\n",
    "    print(f\"   {topic}:\")\n",
    "    print(f\"      - Avg Rating: {metrics['avg_rating']}\")\n",
    "    print(f\"      - Positive %: {metrics['positive_pct']}%\")\n",
    "\n",
    "if report['problem_areas']:\n",
    "    print(\"\\n⚠️  PROBLEM AREAS (Require Attention)\")\n",
    "    for topic in report['problem_areas']:\n",
    "        print(f\"   - {topic}\")\n",
    "else:\n",
    "    print(\"\\n✅ No major problem areas identified!\")\n",
    "\n",
    "if report['strengths']:\n",
    "    print(\"\\n💪 STRENGTHS (Performing Well)\")\n",
    "    for topic in report['strengths']:\n",
    "        print(f\"   - {topic}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📈 時間趨勢分析\n",
    "\n",
    "### 情感隨時間的變化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment trend over time\n",
    "df_sorted = df.sort_values('date')\n",
    "daily_sentiment = df_sorted.groupby(['date', 'predicted_sentiment']).size().unstack(fill_value=0)\n",
    "\n",
    "# Plot sentiment trend\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(daily_sentiment.index, daily_sentiment['POSITIVE'], marker='o', label='Positive', linewidth=2, color='green')\n",
    "plt.plot(daily_sentiment.index, daily_sentiment['NEGATIVE'], marker='o', label='Negative', linewidth=2, color='red')\n",
    "plt.fill_between(daily_sentiment.index, daily_sentiment['POSITIVE'], alpha=0.3, color='green')\n",
    "plt.fill_between(daily_sentiment.index, daily_sentiment['NEGATIVE'], alpha=0.3, color='red')\n",
    "\n",
    "plt.title('Sentiment Trend Over Time', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Reviews')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 🚀 部署準備\n",
    "\n",
    "### 1. 建立分析函數 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create reusable analysis function\n",
    "class CustomerFeedbackAnalyzer:\n",
    "    \"\"\"\n",
    "    Customer Feedback Analyzer - Production-ready class\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        print(\"🔄 Initializing Customer Feedback Analyzer...\")\n",
    "        self.sentiment_analyzer = pipeline(\n",
    "            \"sentiment-analysis\",\n",
    "            model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "            device=-1  # CPU for production\n",
    "        )\n",
    "        print(\"✅ Analyzer ready!\")\n",
    "    \n",
    "    def analyze_sentiment(self, text):\n",
    "        \"\"\"\n",
    "        Analyze sentiment of a single review\n",
    "        Args:\n",
    "            text: review text\n",
    "        Returns:\n",
    "            dict with sentiment and confidence\n",
    "        \"\"\"\n",
    "        result = self.sentiment_analyzer(text)[0]\n",
    "        return {\n",
    "            'sentiment': result['label'],\n",
    "            'confidence': round(result['score'], 4)\n",
    "        }\n",
    "    \n",
    "    def batch_analyze(self, reviews):\n",
    "        \"\"\"\n",
    "        Batch analyze multiple reviews\n",
    "        Args:\n",
    "            reviews: list of review texts\n",
    "        Returns:\n",
    "            list of analysis results\n",
    "        \"\"\"\n",
    "        results = self.sentiment_analyzer(reviews)\n",
    "        return [\n",
    "            {\n",
    "                'sentiment': r['label'],\n",
    "                'confidence': round(r['score'], 4)\n",
    "            }\n",
    "            for r in results\n",
    "        ]\n",
    "    \n",
    "    def get_summary_stats(self, results):\n",
    "        \"\"\"\n",
    "        Calculate summary statistics\n",
    "        Args:\n",
    "            results: list of analysis results\n",
    "        Returns:\n",
    "            dict with summary statistics\n",
    "        \"\"\"\n",
    "        total = len(results)\n",
    "        positive = sum(1 for r in results if r['sentiment'] == 'POSITIVE')\n",
    "        negative = total - positive\n",
    "        \n",
    "        return {\n",
    "            'total_reviews': total,\n",
    "            'positive_count': positive,\n",
    "            'negative_count': negative,\n",
    "            'positive_percentage': round(positive / total * 100, 2),\n",
    "            'negative_percentage': round(negative / total * 100, 2)\n",
    "        }\n",
    "\n",
    "# Initialize analyzer\n",
    "analyzer = CustomerFeedbackAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the analyzer\n",
    "test_reviews = [\n",
    "    \"This product is absolutely fantastic!\",\n",
    "    \"Terrible experience, will never buy again.\",\n",
    "    \"Good quality but shipping was slow.\"\n",
    "]\n",
    "\n",
    "print(\"🧪 Testing analyzer with sample reviews:\\n\")\n",
    "results = analyzer.batch_analyze(test_reviews)\n",
    "\n",
    "for review, result in zip(test_reviews, results):\n",
    "    print(f\"Review: {review}\")\n",
    "    print(f\"Sentiment: {result['sentiment']} (Confidence: {result['confidence']:.2%})\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "# Get summary\n",
    "summary = analyzer.get_summary_stats(results)\n",
    "print(\"\\n📊 Summary Statistics:\")\n",
    "print(json.dumps(summary, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 導出分析結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results to CSV\n",
    "output_path = \"./customer_feedback_analysis_results.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"✅ Results exported to: {output_path}\")\n",
    "\n",
    "# Export summary report to JSON\n",
    "report_path = \"./analysis_report.json\"\n",
    "with open(report_path, 'w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "print(f\"✅ Report exported to: {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📚 總結與延伸應用\n",
    "\n",
    "### ✅ 你學到了什麼\n",
    "\n",
    "1. **端到端專案流程**:\n",
    "   - 數據收集與準備\n",
    "   - NLP 模型應用\n",
    "   - 結果分析與可視化\n",
    "   - 業務洞察生成\n",
    "   - 模型部署準備\n",
    "\n",
    "2. **實戰技能**:\n",
    "   - Hugging Face Pipeline 在生產環境的應用\n",
    "   - 批量處理大量文本數據\n",
    "   - 關鍵字提取與詞雲生成\n",
    "   - 多維度數據可視化\n",
    "   - 可重用的分析類別設計\n",
    "\n",
    "3. **商業價值**:\n",
    "   - 自動化客戶反饋分析\n",
    "   - 快速識別問題領域\n",
    "   - 數據驅動決策支持\n",
    "\n",
    "### 🚀 延伸應用方向\n",
    "\n",
    "1. **整合更多 NLP 功能**:\n",
    "   - 命名實體識別 (提取產品名稱、品牌)\n",
    "   - 主題建模 (LDA, BERTopic)\n",
    "   - 零樣本分類 (自動分類問題類型)\n",
    "\n",
    "2. **建立 Web API**:\n",
    "   ```python\n",
    "   # FastAPI example\n",
    "   from fastapi import FastAPI\n",
    "   \n",
    "   app = FastAPI()\n",
    "   analyzer = CustomerFeedbackAnalyzer()\n",
    "   \n",
    "   @app.post(\"/analyze\")\n",
    "   def analyze_review(text: str):\n",
    "       return analyzer.analyze_sentiment(text)\n",
    "   ```\n",
    "\n",
    "3. **即時監控儀表板**:\n",
    "   - 使用 Streamlit 或 Dash 建立互動式儀表板\n",
    "   - 整合 Plotly 製作動態圖表\n",
    "   - 設定警報系統 (負評超過閾值時通知)\n",
    "\n",
    "4. **多語言支持**:\n",
    "   - 使用多語言模型 (XLM-RoBERTa)\n",
    "   - 整合翻譯 API\n",
    "   - 支援中文、日文等亞洲語言\n",
    "\n",
    "5. **進階分析**:\n",
    "   - 情感強度分析 (1-5 星細緻度)\n",
    "   - 情緒識別 (喜悅、憤怒、失望等)\n",
    "   - 異常檢測 (突發負評警報)\n",
    "\n",
    "### 💼 商業應用場景\n",
    "\n",
    "| 產業 | 應用場景 | 價值 |\n",
    "|------|----------|------|\n",
    "| **電商** | 產品評論分析 | 快速識別問題產品,改善客戶體驗 |\n",
    "| **餐飲** | Google/Yelp 評論監控 | 即時回應負評,維護品牌聲譽 |\n",
    "| **旅遊** | 酒店/景點評價分析 | 優化服務品質,提升競爭力 |\n",
    "| **金融** | 客服對話分析 | 評估服務品質,訓練客服人員 |\n",
    "| **SaaS** | 用戶反饋分析 | 產品迭代優先級排序 |\n",
    "\n",
    "---\n",
    "\n",
    "## 🔗 參考資源\n",
    "\n",
    "- [Hugging Face Transformers](https://huggingface.co/docs/transformers/)\n",
    "- [DistilBERT Model Card](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
    "- [WordCloud Documentation](https://github.com/amueller/word_cloud)\n",
    "- [Plotly Python](https://plotly.com/python/)\n",
    "\n",
    "---\n",
    "\n",
    "**下一節**: `10_進階技巧與優化.ipynb` - 模型量化、推理加速、部署優化 ⚡"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
