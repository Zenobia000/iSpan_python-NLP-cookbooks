{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CH08-06: æ–‡æœ¬æ‘˜è¦ (Summarization)\n",
    "\n",
    "**èª²ç¨‹**: iSpan Python NLP Cookbooks v2\n",
    "**ç« ç¯€**: CH08 Hugging Face å‡½å¼åº«å¯¦æˆ°\n",
    "**ç‰ˆæœ¬**: v1.0\n",
    "**æ›´æ–°æ—¥æœŸ**: 2025-10-17\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š æœ¬ç¯€å­¸ç¿’ç›®æ¨™\n",
    "\n",
    "1. ç†è§£æŠ½å–å¼ vs ç”Ÿæˆå¼æ‘˜è¦çš„å·®ç•°\n",
    "2. ä½¿ç”¨ BART/T5/Pegasus ç”Ÿæˆæ‘˜è¦\n",
    "3. æŒæ¡æ‘˜è¦åƒæ•¸èª¿æ•´æŠ€å·§\n",
    "4. å¯¦ä½œå¤šæ–‡æª”æ‘˜è¦\n",
    "5. è©•ä¼°æ‘˜è¦è³ªé‡ (ROUGE æŒ‡æ¨™)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. æ–‡æœ¬æ‘˜è¦åŸºç¤\n",
    "\n",
    "### 1.1 æ‘˜è¦é¡å‹\n",
    "\n",
    "**æŠ½å–å¼æ‘˜è¦ (Extractive)**:\n",
    "- å¾åŸæ–‡ä¸­æŒ‘é¸é‡è¦å¥å­\n",
    "- ä¿ç•™åŸæ–‡è¡¨é”\n",
    "- ä¸ç”¢ç”Ÿæ–°å…§å®¹\n",
    "\n",
    "**ç”Ÿæˆå¼æ‘˜è¦ (Abstractive)**:\n",
    "- ç†è§£åŸæ–‡å¾Œé‡æ–°ç”Ÿæˆ\n",
    "- å¯èƒ½ç”¢ç”Ÿæ–°è©å½™\n",
    "- æ›´æ¥è¿‘äººé¡æ‘˜è¦\n",
    "\n",
    "```\n",
    "åŸæ–‡:\n",
    "\"The Transformer architecture has revolutionized NLP. \n",
    "It introduced self-attention mechanisms that allow models \n",
    "to process sequences in parallel.\"\n",
    "\n",
    "æŠ½å–å¼: \"The Transformer architecture has revolutionized NLP.\"\n",
    "\n",
    "ç”Ÿæˆå¼: \"Transformers changed NLP with self-attention.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£å¥—ä»¶\n",
    "# !pip install transformers torch rouge-score -q\n",
    "\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"âœ… ç’°å¢ƒæº–å‚™å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. ä½¿ç”¨é è¨“ç·´æ¨¡å‹\n",
    "\n",
    "### 2.1 BART æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¼‰å…¥ BART æ‘˜è¦æ¨¡å‹\n",
    "summarizer_bart = pipeline(\n",
    "    \"summarization\",\n",
    "    model=\"facebook/bart-large-cnn\",\n",
    "    device=-1\n",
    ")\n",
    "\n",
    "# æ¸¬è©¦æ–‡æœ¬\n",
    "article = \"\"\"\n",
    "The Transformer architecture, introduced in the paper \"Attention Is All You Need\" \n",
    "by Vaswani et al. in 2017, has revolutionized natural language processing. \n",
    "Unlike previous architectures that relied on recurrent or convolutional layers, \n",
    "Transformers use self-attention mechanisms to process input sequences in parallel. \n",
    "This parallel processing capability makes Transformers significantly faster to train \n",
    "than RNNs. The architecture consists of an encoder and a decoder, each composed of \n",
    "multiple layers of self-attention and feed-forward networks. The self-attention \n",
    "mechanism allows the model to weigh the importance of different words in a sentence \n",
    "when encoding each word. This has proven to be extremely effective for a wide range \n",
    "of NLP tasks, from translation to text generation.\n",
    "\"\"\"\n",
    "\n",
    "# ç”Ÿæˆæ‘˜è¦\n",
    "summary = summarizer_bart(\n",
    "    article,\n",
    "    max_length=60,\n",
    "    min_length=30,\n",
    "    do_sample=False\n",
    ")\n",
    "\n",
    "print(f\"åŸæ–‡ ({len(article.split())} è©):\")\n",
    "print(article.strip())\n",
    "print(f\"\\næ‘˜è¦ ({len(summary[0]['summary_text'].split())} è©):\")\n",
    "print(summary[0]['summary_text'])\n",
    "print(f\"\\nå£“ç¸®æ¯”: {len(summary[0]['summary_text'].split())/len(article.split()):.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 T5 æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T5 (Text-to-Text Transfer Transformer)\n",
    "summarizer_t5 = pipeline(\n",
    "    \"summarization\",\n",
    "    model=\"t5-small\",\n",
    "    device=-1\n",
    ")\n",
    "\n",
    "# ä½¿ç”¨ç›¸åŒæ–‡æœ¬\n",
    "summary_t5 = summarizer_t5(\n",
    "    article,\n",
    "    max_length=60,\n",
    "    min_length=30\n",
    ")\n",
    "\n",
    "print(\"T5 æ‘˜è¦:\")\n",
    "print(summary_t5[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 æ¨¡å‹å°æ¯”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\"BART-large-CNN\", \"facebook/bart-large-cnn\"),\n",
    "    (\"T5-small\", \"t5-small\"),\n",
    "    (\"Pegasus-CNN\", \"google/pegasus-cnn_dailymail\")\n",
    "]\n",
    "\n",
    "print(\"ä¸åŒæ¨¡å‹æ‘˜è¦å°æ¯”:\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for name, model_name in models:\n",
    "    try:\n",
    "        summarizer = pipeline(\"summarization\", model=model_name, device=-1)\n",
    "        result = summarizer(article, max_length=50, min_length=25)\n",
    "        \n",
    "        print(f\"\\n{name}:\")\n",
    "        print(result[0]['summary_text'])\n",
    "    except Exception as e:\n",
    "        print(f\"\\n{name}: è¼‰å…¥å¤±æ•— ({str(e)[:50]}...)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. åƒæ•¸èª¿æ•´\n",
    "\n",
    "### 3.1 é•·åº¦æ§åˆ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¸¬è©¦ä¸åŒé•·åº¦è¨­å®š\n",
    "length_configs = [\n",
    "    {\"max_length\": 30, \"min_length\": 20, \"name\": \"çŸ­æ‘˜è¦\"},\n",
    "    {\"max_length\": 60, \"min_length\": 40, \"name\": \"ä¸­æ‘˜è¦\"},\n",
    "    {\"max_length\": 100, \"min_length\": 70, \"name\": \"é•·æ‘˜è¦\"}\n",
    "]\n",
    "\n",
    "print(\"ä¸åŒé•·åº¦æ‘˜è¦å°æ¯”:\\n\")\n",
    "\n",
    "for config in length_configs:\n",
    "    summary = summarizer_bart(\n",
    "        article,\n",
    "        max_length=config['max_length'],\n",
    "        min_length=config['min_length'],\n",
    "        do_sample=False\n",
    "    )\n",
    "    \n",
    "    text = summary[0]['summary_text']\n",
    "    print(f\"{config['name']} ({len(text.split())} è©):\")\n",
    "    print(text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 æ¡æ¨£ç­–ç•¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beam Search vs Sampling\n",
    "configs = [\n",
    "    {\"do_sample\": False, \"num_beams\": 4, \"name\": \"Beam Search (4)\"},\n",
    "    {\"do_sample\": True, \"top_k\": 50, \"top_p\": 0.95, \"name\": \"Top-K & Top-P Sampling\"},\n",
    "    {\"do_sample\": True, \"temperature\": 0.8, \"name\": \"Temperature Sampling\"}\n",
    "]\n",
    "\n",
    "print(\"ä¸åŒæ¡æ¨£ç­–ç•¥å°æ¯”:\\n\")\n",
    "\n",
    "for config in configs:\n",
    "    name = config.pop('name')\n",
    "    \n",
    "    summary = summarizer_bart(\n",
    "        article,\n",
    "        max_length=50,\n",
    "        min_length=30,\n",
    "        **config\n",
    "    )\n",
    "    \n",
    "    print(f\"{name}:\")\n",
    "    print(summary[0]['summary_text'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. å¯¦æˆ°æ‡‰ç”¨\n",
    "\n",
    "### 4.1 æ–°èæ‘˜è¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_article = \"\"\"\n",
    "Apple Inc. announced record-breaking quarterly earnings today, with revenue \n",
    "reaching $120 billion, surpassing analyst expectations. The company's CEO \n",
    "Tim Cook attributed the success to strong iPhone sales and growth in the \n",
    "services sector. Apple's stock price rose 5% in after-hours trading following \n",
    "the announcement. The company also revealed plans to invest $10 billion in \n",
    "new product development over the next year, focusing on augmented reality \n",
    "and artificial intelligence technologies. Analysts predict continued growth \n",
    "for Apple in the coming quarters, citing strong consumer demand and a robust \n",
    "product pipeline.\n",
    "\"\"\"\n",
    "\n",
    "summary = summarizer_bart(\n",
    "    news_article,\n",
    "    max_length=50,\n",
    "    min_length=25,\n",
    "    do_sample=False\n",
    ")\n",
    "\n",
    "print(\"ğŸ“° æ–°èæ‘˜è¦ç”Ÿæˆ\\n\")\n",
    "print(\"åŸæ–‡:\")\n",
    "print(news_article.strip())\n",
    "print(f\"\\næ‘˜è¦:\")\n",
    "print(summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 æ‰¹æ¬¡è™•ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¤šç¯‡æ–‡ç« æ‰¹æ¬¡æ‘˜è¦\n",
    "articles = [\n",
    "    \"Tesla announced a new electric vehicle model today...\",\n",
    "    \"Scientists discovered a new exoplanet in the habitable zone...\",\n",
    "    \"The stock market reached new highs amid positive economic data...\"\n",
    "]\n",
    "\n",
    "# æ‰¹æ¬¡è™•ç†\n",
    "summaries = summarizer_bart(\n",
    "    articles,\n",
    "    max_length=30,\n",
    "    min_length=15,\n",
    "    batch_size=3\n",
    ")\n",
    "\n",
    "print(\"æ‰¹æ¬¡æ‘˜è¦çµæœ:\\n\")\n",
    "for i, (article, summary) in enumerate(zip(articles, summaries), 1):\n",
    "    print(f\"{i}. åŸæ–‡: {article}\")\n",
    "    print(f\"   æ‘˜è¦: {summary['summary_text']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 å¤šæ–‡æª”æ‘˜è¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¤šå€‹ç›¸é—œæ–‡æª”çš„çµ±ä¸€æ‘˜è¦\n",
    "docs = [\n",
    "    \"Apple released the new iPhone 15 with advanced AI features.\",\n",
    "    \"The iPhone 15 includes a new A17 chip and improved camera system.\",\n",
    "    \"Apple's new phone has been well-received by tech reviewers.\"\n",
    "]\n",
    "\n",
    "# åˆä½µæ–‡æª”\n",
    "combined_text = \" \".join(docs)\n",
    "\n",
    "# ç”Ÿæˆæ‘˜è¦\n",
    "summary = summarizer_bart(\n",
    "    combined_text,\n",
    "    max_length=40,\n",
    "    min_length=20\n",
    ")\n",
    "\n",
    "print(\"å¤šæ–‡æª”æ‘˜è¦:\\n\")\n",
    "print(\"æ–‡æª” 1:\", docs[0])\n",
    "print(\"æ–‡æª” 2:\", docs[1])\n",
    "print(\"æ–‡æª” 3:\", docs[2])\n",
    "print(f\"\\nçµ±ä¸€æ‘˜è¦: {summary[0]['summary_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. æ‘˜è¦è³ªé‡è©•ä¼°\n",
    "\n",
    "### 5.1 ROUGE æŒ‡æ¨™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "# åƒè€ƒæ‘˜è¦ (äººå·¥æ¨™è¨»)\n",
    "reference = \"Transformers revolutionized NLP with self-attention mechanisms for parallel processing.\"\n",
    "\n",
    "# ç”Ÿæˆæ‘˜è¦\n",
    "generated = summarizer_bart(article, max_length=30, min_length=15)[0]['summary_text']\n",
    "\n",
    "# è¨ˆç®— ROUGE\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "scores = scorer.score(reference, generated)\n",
    "\n",
    "print(\"ROUGE è©•ä¼°çµæœ:\\n\")\n",
    "print(f\"åƒè€ƒæ‘˜è¦: {reference}\")\n",
    "print(f\"ç”Ÿæˆæ‘˜è¦: {generated}\\n\")\n",
    "\n",
    "for metric, score in scores.items():\n",
    "    print(f\"{metric}:\")\n",
    "    print(f\"  Precision: {score.precision:.4f}\")\n",
    "    print(f\"  Recall:    {score.recall:.4f}\")\n",
    "    print(f\"  F1:        {score.fmeasure:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ROUGE æŒ‡æ¨™èªªæ˜**:\n",
    "- **ROUGE-1**: Unigram (å–®è©) é‡ç–Š\n",
    "- **ROUGE-2**: Bigram (é›™è©) é‡ç–Š\n",
    "- **ROUGE-L**: æœ€é•·å…¬å…±å­åºåˆ— (LCS)\n",
    "\n",
    "### 5.2 é•·åº¦åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ†æä¸åŒé•·åº¦çš„æ‘˜è¦è³ªé‡\n",
    "import pandas as pd\n",
    "\n",
    "max_lengths = [20, 30, 40, 50, 60]\n",
    "results = []\n",
    "\n",
    "for max_len in max_lengths:\n",
    "    summary = summarizer_bart(\n",
    "        article, \n",
    "        max_length=max_len, \n",
    "        min_length=max_len-10\n",
    "    )[0]['summary_text']\n",
    "    \n",
    "    scores = scorer.score(reference, summary)\n",
    "    \n",
    "    results.append({\n",
    "        'Max Length': max_len,\n",
    "        'Actual Length': len(summary.split()),\n",
    "        'ROUGE-1': scores['rouge1'].fmeasure,\n",
    "        'ROUGE-2': scores['rouge2'].fmeasure,\n",
    "        'ROUGE-L': scores['rougeL'].fmeasure\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(\"é•·åº¦ vs ROUGE åˆ†æ•¸:\\n\")\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# ç¹ªåœ–\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df['Max Length'], df['ROUGE-1'], marker='o', label='ROUGE-1')\n",
    "plt.plot(df['Max Length'], df['ROUGE-2'], marker='s', label='ROUGE-2')\n",
    "plt.plot(df['Max Length'], df['ROUGE-L'], marker='^', label='ROUGE-L')\n",
    "plt.xlabel('Max Summary Length', fontsize=12)\n",
    "plt.ylabel('ROUGE F1 Score', fontsize=12)\n",
    "plt.title('Summary Length vs ROUGE Scores', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. é€²éšæŠ€å·§\n",
    "\n",
    "### 6.1 æŠ½å–å¼æ‘˜è¦ (TextRank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç°¡æ˜“ TextRank å¯¦ä½œ\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import networkx as nx\n",
    "import nltk\n",
    "\n",
    "# nltk.download('punkt')\n",
    "\n",
    "def extractive_summarize(text, num_sentences=3):\n",
    "    # åˆ†å¥\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    \n",
    "    if len(sentences) <= num_sentences:\n",
    "        return text\n",
    "    \n",
    "    # TF-IDF å‘é‡åŒ–\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(sentences)\n",
    "    \n",
    "    # è¨ˆç®—ç›¸ä¼¼åº¦\n",
    "    similarity_matrix = cosine_similarity(tfidf_matrix)\n",
    "    \n",
    "    # PageRank\n",
    "    nx_graph = nx.from_numpy_array(similarity_matrix)\n",
    "    scores = nx.pagerank(nx_graph)\n",
    "    \n",
    "    # é¸æ“‡ top-k å¥å­\n",
    "    ranked = sorted(((scores[i], s) for i, s in enumerate(sentences)), reverse=True)\n",
    "    top_sentences = [s for _, s in ranked[:num_sentences]]\n",
    "    \n",
    "    # æŒ‰åŸé †åºæ’åˆ—\n",
    "    summary = [s for s in sentences if s in top_sentences]\n",
    "    \n",
    "    return ' '.join(summary)\n",
    "\n",
    "# æ¸¬è©¦\n",
    "extractive = extractive_summarize(article, num_sentences=2)\n",
    "abstractive = summarizer_bart(article, max_length=50, min_length=30)[0]['summary_text']\n",
    "\n",
    "print(\"æŠ½å–å¼ vs ç”Ÿæˆå¼å°æ¯”:\\n\")\n",
    "print(\"æŠ½å–å¼æ‘˜è¦:\")\n",
    "print(extractive)\n",
    "print(f\"\\nç”Ÿæˆå¼æ‘˜è¦:\")\n",
    "print(abstractive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 è‡ªè¨‚æ‘˜è¦é¢¨æ ¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨ Prompt æ§åˆ¶æ‘˜è¦é¢¨æ ¼ (éœ€è¦æ”¯æ´çš„æ¨¡å‹)\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_name = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# T5 éœ€è¦åŠ å‰ç¶´\n",
    "input_text = \"summarize: \" + article\n",
    "\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "outputs = model.generate(\n",
    "    inputs.input_ids,\n",
    "    max_length=50,\n",
    "    min_length=25,\n",
    "    num_beams=4,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(\"T5 ç”Ÿæˆæ‘˜è¦:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. èª²å¾Œç·´ç¿’\n",
    "\n",
    "### ç·´ç¿’ 1: æœƒè­°ç´€éŒ„æ‘˜è¦\n",
    "\n",
    "å°‡æœƒè­°è¨˜éŒ„è½‰æ›ç‚ºç°¡æ½”çš„è¡Œå‹•é …ç›®æ‘˜è¦ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: å¯¦ä½œæœƒè­°ç´€éŒ„æ‘˜è¦\n",
    "meeting_transcript = \"\"\"\n",
    "[é•·ç¯‡æœƒè­°è¨˜éŒ„]\n",
    "\"\"\"\n",
    "\n",
    "# æå–:\n",
    "# 1. ä¸»è¦æ±ºç­–\n",
    "# 2. è¡Œå‹•é …ç›®\n",
    "# 3. è²¬ä»»äºº"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç·´ç¿’ 2: å¤šæ–‡æª”ä¸»é¡Œæ‘˜è¦\n",
    "\n",
    "å¾å¤šç¯‡ç›¸é—œæ–°èä¸­æå–å…±åŒä¸»é¡Œæ‘˜è¦ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: å¯¦ä½œå¤šæ–‡æª”ä¸»é¡Œæ‘˜è¦\n",
    "# æç¤º:\n",
    "# 1. è­˜åˆ¥å…±åŒä¸»é¡Œ\n",
    "# 2. åˆä½µç›¸é—œä¿¡æ¯\n",
    "# 3. ç”Ÿæˆçµ±ä¸€æ‘˜è¦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. æœ¬ç¯€ç¸½çµ\n",
    "\n",
    "### âœ… é—œéµè¦é»\n",
    "\n",
    "1. **æ‘˜è¦é¡å‹**: æŠ½å–å¼ (é¸å¥) vs ç”Ÿæˆå¼ (é‡å¯«)\n",
    "2. **æ¨¡å‹é¸æ“‡**: BART (æ–°è), T5 (é€šç”¨), Pegasus (æ‘˜è¦å°ˆç”¨)\n",
    "3. **åƒæ•¸èª¿æ•´**: max_length, min_length, num_beams, do_sample\n",
    "4. **è©•ä¼°æŒ‡æ¨™**: ROUGE-1/2/L (èˆ‡åƒè€ƒæ‘˜è¦æ¯”è¼ƒ)\n",
    "\n",
    "### ğŸ“Š æ¨¡å‹æ•ˆèƒ½å°æ¯”\n",
    "\n",
    "| æ¨¡å‹ | åƒæ•¸é‡ | ROUGE-L | é€Ÿåº¦ | é©ç”¨å ´æ™¯ |\n",
    "|------|--------|---------|------|----------|\n",
    "| BART-large | 406M | ~44 | ä¸­ | æ–°èã€é•·æ–‡ |\n",
    "| T5-base | 220M | ~42 | å¿« | é€šç”¨æ–‡æœ¬ |\n",
    "| Pegasus | 568M | ~47 | æ…¢ | å°ˆæ¥­æ‘˜è¦ |\n",
    "\n",
    "### ğŸ“š å»¶ä¼¸é–±è®€\n",
    "\n",
    "- [BART è«–æ–‡](https://arxiv.org/abs/1910.13461)\n",
    "- [T5 è«–æ–‡](https://arxiv.org/abs/1910.10683)\n",
    "- [ROUGE è©•ä¼°æŒ‡æ¨™](https://aclanthology.org/W04-1013/)\n",
    "\n",
    "### ğŸš€ ä¸‹ä¸€ç¯€é å‘Š\n",
    "\n",
    "**CH08-07: æ–‡æœ¬ç”Ÿæˆ (Text Generation)**\n",
    "- GPT-2/GPT-3 æ–‡æœ¬ç”Ÿæˆ\n",
    "- ç”Ÿæˆç­–ç•¥ (Top-K, Top-P, Beam Search)\n",
    "- æ§åˆ¶ç”Ÿæˆå…§å®¹\n",
    "\n",
    "---\n",
    "\n",
    "**èª²ç¨‹**: iSpan Python NLP Cookbooks v2\n",
    "**è¬›å¸«**: Claude AI\n",
    "**æœ€å¾Œæ›´æ–°**: 2025-10-17"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
