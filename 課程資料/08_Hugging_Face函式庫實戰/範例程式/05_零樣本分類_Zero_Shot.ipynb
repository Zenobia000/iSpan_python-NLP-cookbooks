{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CH08-05: é›¶æ¨£æœ¬åˆ†é¡ (Zero-Shot Classification)\n",
    "\n",
    "**èª²ç¨‹**: iSpan Python NLP Cookbooks v2\n",
    "**ç« ç¯€**: CH08 Hugging Face å‡½å¼åº«å¯¦æˆ°\n",
    "**ç‰ˆæœ¬**: v1.0\n",
    "**æ›´æ–°æ—¥æœŸ**: 2025-10-17\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š æœ¬ç¯€å­¸ç¿’ç›®æ¨™\n",
    "\n",
    "1. ç†è§£é›¶æ¨£æœ¬å­¸ç¿’ (Zero-Shot Learning) çš„åŸç†\n",
    "2. æŒæ¡ Hugging Face é›¶æ¨£æœ¬åˆ†é¡ Pipeline\n",
    "3. æ‡‰ç”¨æ–¼å¤šæ¨™ç±¤åˆ†é¡ä»»å‹™\n",
    "4. å¯¦ä½œè‡ªè¨‚åˆ†é¡æ¨™ç±¤\n",
    "5. èˆ‡å‚³çµ±ç›£ç£å­¸ç¿’æ–¹æ³•å°æ¯”\n",
    "\n",
    "---\n",
    "\n",
    "## 1. é›¶æ¨£æœ¬å­¸ç¿’åŸç†\n",
    "\n",
    "### 1.1 ä»€éº¼æ˜¯é›¶æ¨£æœ¬åˆ†é¡?\n",
    "\n",
    "**å®šç¾©**: æ¨¡å‹ç„¡éœ€é‡å°ç‰¹å®šé¡åˆ¥è¨“ç·´,å³å¯å°æ–°é¡åˆ¥é€²è¡Œåˆ†é¡\n",
    "\n",
    "**æ ¸å¿ƒæ€æƒ³**:\n",
    "```\n",
    "å‚³çµ±åˆ†é¡: \n",
    "  è¨“ç·´æ•¸æ“š â†’ æ¨¡å‹ â†’ é æ¸¬å›ºå®šé¡åˆ¥\n",
    "\n",
    "é›¶æ¨£æœ¬åˆ†é¡:\n",
    "  é è¨“ç·´æ¨¡å‹ + è‡ªç„¶èªè¨€é¡åˆ¥æè¿° â†’ é æ¸¬ä»»æ„é¡åˆ¥\n",
    "```\n",
    "\n",
    "**ç¯„ä¾‹**:\n",
    "```\n",
    "æ–‡æœ¬: \"Apple released the new iPhone today.\"\n",
    "å€™é¸æ¨™ç±¤: [\"technology\", \"sports\", \"politics\"]\n",
    "\n",
    "æ¨¡å‹åˆ¤æ–·:\n",
    "- technology: 0.85\n",
    "- sports: 0.10\n",
    "- politics: 0.05\n",
    "```\n",
    "\n",
    "### 1.2 å„ªå‹¢èˆ‡ä¾·é™\n",
    "\n",
    "**å„ªå‹¢**:\n",
    "- âœ… ç„¡éœ€æ¨™è¨»æ•¸æ“š\n",
    "- âœ… å¿«é€Ÿé©æ‡‰æ–°é¡åˆ¥\n",
    "- âœ… éˆæ´»èª¿æ•´åˆ†é¡æ¨™ç±¤\n",
    "\n",
    "**ä¾·é™**:\n",
    "- âŒ æº–ç¢ºç‡ä½æ–¼å¾®èª¿æ¨¡å‹\n",
    "- âŒ ä¾è³´æ¨™ç±¤èªç¾©æè¿°\n",
    "- âŒ æ¨ç†é€Ÿåº¦è¼ƒæ…¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£å¿…è¦å¥—ä»¶\n",
    "# !pip install transformers torch -q\n",
    "\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"âœ… ç’°å¢ƒæº–å‚™å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. åŸºç¤ä½¿ç”¨\n",
    "\n",
    "### 2.1 å‰µå»ºé›¶æ¨£æœ¬åˆ†é¡å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¼‰å…¥é›¶æ¨£æœ¬åˆ†é¡ Pipeline\n",
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"facebook/bart-large-mnli\",\n",
    "    device=-1  # CPU\n",
    ")\n",
    "\n",
    "# æ¸¬è©¦æ–‡æœ¬\n",
    "text = \"Apple CEO Tim Cook announced the new iPhone at the event in California.\"\n",
    "\n",
    "# å€™é¸æ¨™ç±¤\n",
    "candidate_labels = [\"technology\", \"sports\", \"politics\", \"entertainment\", \"business\"]\n",
    "\n",
    "# é æ¸¬\n",
    "result = classifier(text, candidate_labels)\n",
    "\n",
    "print(f\"æ–‡æœ¬: {text}\\n\")\n",
    "print(\"åˆ†é¡çµæœ:\")\n",
    "for label, score in zip(result['labels'], result['scores']):\n",
    "    print(f\"  {label:15s}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 å¯è¦–åŒ–çµæœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¹ªè£½æ©Ÿç‡åˆ†å¸ƒ\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(result['labels'], result['scores'], color='skyblue')\n",
    "plt.xlabel('Probability', fontsize=12)\n",
    "plt.title('Zero-Shot Classification Results', fontsize=14)\n",
    "plt.xlim(0, 1)\n",
    "for i, score in enumerate(result['scores']):\n",
    "    plt.text(score + 0.02, i, f\"{score:.3f}\", va='center')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. å¤šæ¨™ç±¤åˆ†é¡\n",
    "\n",
    "### 3.1 Multi-Label vs Multi-Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This movie is a thrilling action-packed adventure with great special effects.\"\n",
    "\n",
    "labels = [\"action\", \"comedy\", \"thriller\", \"romance\", \"sci-fi\"]\n",
    "\n",
    "# Multi-Class (å–®æ¨™ç±¤,äº’æ–¥)\n",
    "result_single = classifier(\n",
    "    text, labels,\n",
    "    multi_label=False\n",
    ")\n",
    "\n",
    "# Multi-Label (å¤šæ¨™ç±¤,å¯å…±å­˜)\n",
    "result_multi = classifier(\n",
    "    text, labels,\n",
    "    multi_label=True\n",
    ")\n",
    "\n",
    "# å°æ¯”çµæœ\n",
    "df_comparison = pd.DataFrame({\n",
    "    'Label': labels,\n",
    "    'Multi-Class': [result_single['scores'][result_single['labels'].index(l)] for l in labels],\n",
    "    'Multi-Label': [result_multi['scores'][result_multi['labels'].index(l)] for l in labels]\n",
    "})\n",
    "\n",
    "print(\"Multi-Class vs Multi-Label å°æ¯”:\")\n",
    "print(df_comparison.to_string(index=False))\n",
    "\n",
    "# å¯è¦–åŒ–\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].barh(labels, df_comparison['Multi-Class'], color='coral')\n",
    "axes[0].set_title('Multi-Class (äº’æ–¥)', fontsize=14)\n",
    "axes[0].set_xlabel('Probability')\n",
    "\n",
    "axes[1].barh(labels, df_comparison['Multi-Label'], color='lightgreen')\n",
    "axes[1].set_title('Multi-Label (å¯å…±å­˜)', fontsize=14)\n",
    "axes[1].set_xlabel('Probability')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 è¨­å®šé–¾å€¼éæ¿¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¨­å®šé–¾å€¼,åªä¿ç•™é«˜ä¿¡å¿ƒåº¦æ¨™ç±¤\n",
    "threshold = 0.5\n",
    "\n",
    "filtered_labels = [\n",
    "    (label, score) \n",
    "    for label, score in zip(result_multi['labels'], result_multi['scores'])\n",
    "    if score > threshold\n",
    "]\n",
    "\n",
    "print(f\"æ–‡æœ¬: {text}\\n\")\n",
    "print(f\"é–¾å€¼: {threshold}\")\n",
    "print(\"\\néæ¿¾å¾Œçš„æ¨™ç±¤:\")\n",
    "for label, score in filtered_labels:\n",
    "    print(f\"  - {label}: {score:.4f}\")\n",
    "\n",
    "if not filtered_labels:\n",
    "    print(\"  (ç„¡æ¨™ç±¤è¶…éé–¾å€¼)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. å¯¦æˆ°æ‡‰ç”¨\n",
    "\n",
    "### 4.1 æ–°èåˆ†é¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ–°èæ–‡æœ¬\n",
    "news_articles = [\n",
    "    \"Tesla stock surges after record quarterly earnings report.\",\n",
    "    \"Scientists discover new exoplanet that could support life.\",\n",
    "    \"The Lakers won the championship in a thrilling final game.\",\n",
    "    \"New health study reveals benefits of Mediterranean diet.\",\n",
    "    \"President announces new climate change policy.\"\n",
    "]\n",
    "\n",
    "# æ–°èé¡åˆ¥\n",
    "news_categories = [\n",
    "    \"business\", \"science\", \"sports\", \"health\", \"politics\"\n",
    "]\n",
    "\n",
    "# æ‰¹æ¬¡åˆ†é¡\n",
    "print(\"æ–°èè‡ªå‹•åˆ†é¡çµæœ:\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, article in enumerate(news_articles, 1):\n",
    "    result = classifier(article, news_categories, multi_label=False)\n",
    "    top_label = result['labels'][0]\n",
    "    top_score = result['scores'][0]\n",
    "    \n",
    "    print(f\"{i}. {article}\")\n",
    "    print(f\"   åˆ†é¡: {top_label.upper()} (ä¿¡å¿ƒåº¦: {top_score:.2%})\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 æƒ…æ„Ÿç´°ç²’åº¦åˆ†é¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æƒ…æ„Ÿç´°åˆ†\n",
    "text = \"I'm absolutely thrilled and excited about this amazing opportunity!\"\n",
    "\n",
    "emotions = [\n",
    "    \"joy\", \"sadness\", \"anger\", \"fear\", \n",
    "    \"surprise\", \"disgust\", \"excitement\"\n",
    "]\n",
    "\n",
    "result = classifier(text, emotions, multi_label=True)\n",
    "\n",
    "# ç¹ªè£½é›·é”åœ–\n",
    "import math\n",
    "\n",
    "angles = np.linspace(0, 2 * np.pi, len(emotions), endpoint=False).tolist()\n",
    "scores = [result['scores'][result['labels'].index(e)] for e in emotions]\n",
    "\n",
    "# é–‰åˆåœ–å½¢\n",
    "angles += angles[:1]\n",
    "scores += scores[:1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(projection='polar'))\n",
    "ax.plot(angles, scores, 'o-', linewidth=2, color='blue')\n",
    "ax.fill(angles, scores, alpha=0.25, color='blue')\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(emotions)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title('Emotion Distribution (Zero-Shot)', fontsize=16, pad=20)\n",
    "ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"æ–‡æœ¬: {text}\\n\")\n",
    "print(\"æƒ…æ„Ÿåˆ†æ•¸:\")\n",
    "for emotion, score in zip(result['labels'], result['scores']):\n",
    "    print(f\"  {emotion:12s}: {'â–ˆ' * int(score * 20)} {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 ä¸»é¡Œæ¨™è¨»ç³»çµ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# éƒ¨è½æ ¼æ–‡ç« è‡ªå‹•æ¨™è¨»\n",
    "article = \"\"\"\n",
    "In this tutorial, we will learn how to build a machine learning model \n",
    "using Python and scikit-learn. We'll cover data preprocessing, \n",
    "model training, and evaluation techniques. This guide is perfect \n",
    "for beginners who want to get started with artificial intelligence.\n",
    "\"\"\"\n",
    "\n",
    "# å¯èƒ½çš„æ¨™ç±¤\n",
    "possible_tags = [\n",
    "    \"machine learning\", \"programming\", \"data science\",\n",
    "    \"artificial intelligence\", \"tutorial\", \"python\",\n",
    "    \"beginner guide\", \"web development\", \"database\"\n",
    "]\n",
    "\n",
    "# å¤šæ¨™ç±¤åˆ†é¡\n",
    "result = classifier(article, possible_tags, multi_label=True)\n",
    "\n",
    "# é¸æ“‡å‰ 5 å€‹ç›¸é—œæ¨™ç±¤\n",
    "top_tags = list(zip(result['labels'], result['scores']))[:5]\n",
    "\n",
    "print(\"æ–‡ç« å…§å®¹:\")\n",
    "print(article.strip())\n",
    "print(\"\\nå»ºè­°æ¨™ç±¤:\")\n",
    "for tag, score in top_tags:\n",
    "    print(f\"  #{tag.replace(' ', '_'):25s} ({score:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. èˆ‡å‚³çµ±æ–¹æ³•å°æ¯”\n",
    "\n",
    "### 5.1 æº–å‚™å°æ¯”æ•¸æ“š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¸¬è©¦æ•¸æ“šé›†\n",
    "test_data = [\n",
    "    (\"Apple stock rises after earnings\", \"business\"),\n",
    "    (\"Lakers win NBA championship\", \"sports\"),\n",
    "    (\"New vaccine shows promising results\", \"health\"),\n",
    "    (\"Election results announced today\", \"politics\"),\n",
    "    (\"New movie breaks box office records\", \"entertainment\")\n",
    "]\n",
    "\n",
    "texts = [t[0] for t in test_data]\n",
    "true_labels = [t[1] for t in test_data]\n",
    "all_labels = [\"business\", \"sports\", \"health\", \"politics\", \"entertainment\"]\n",
    "\n",
    "# é›¶æ¨£æœ¬é æ¸¬\n",
    "zero_shot_preds = []\n",
    "for text in texts:\n",
    "    result = classifier(text, all_labels)\n",
    "    zero_shot_preds.append(result['labels'][0])\n",
    "\n",
    "# è¨ˆç®—æº–ç¢ºç‡\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "accuracy = accuracy_score(true_labels, zero_shot_preds)\n",
    "\n",
    "print(\"é›¶æ¨£æœ¬åˆ†é¡çµæœ:\")\n",
    "print(\"=\"*60)\n",
    "for i, (text, true, pred) in enumerate(zip(texts, true_labels, zero_shot_preds), 1):\n",
    "    match = \"âœ“\" if true == pred else \"âœ—\"\n",
    "    print(f\"{i}. {match} True: {true:15s} | Pred: {pred:15s}\")\n",
    "    print(f\"   Text: {text}\\n\")\n",
    "\n",
    "print(f\"æº–ç¢ºç‡: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 å„ªå‹¢å ´æ™¯åˆ†æ\n",
    "\n",
    "**é›¶æ¨£æœ¬é©ç”¨å ´æ™¯**:\n",
    "1. âœ… å¿«é€ŸåŸå‹é–‹ç™¼\n",
    "2. âœ… å‹•æ…‹é¡åˆ¥éœ€æ±‚ (å¦‚ç”¨æˆ¶è‡ªå®šç¾©æ¨™ç±¤)\n",
    "3. âœ… å†·å•Ÿå‹•å•é¡Œ (ç„¡æ¨™è¨»æ•¸æ“š)\n",
    "4. âœ… æ¢ç´¢æ€§åˆ†æ\n",
    "\n",
    "**å‚³çµ±ç›£ç£å­¸ç¿’é©ç”¨å ´æ™¯**:\n",
    "1. âœ… å›ºå®šé¡åˆ¥\n",
    "2. âœ… æœ‰å……è¶³æ¨™è¨»æ•¸æ“š\n",
    "3. âœ… éœ€è¦é«˜æº–ç¢ºç‡\n",
    "4. âœ… ç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. é€²éšæŠ€å·§\n",
    "\n",
    "### 6.1 å‡è¨­æ¨¡æ¿å„ªåŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é›¶æ¨£æœ¬åˆ†é¡ä½¿ç”¨çš„éš±å¼å‡è¨­æ¨¡æ¿\n",
    "# é»˜èª: \"This example is about {label}.\"\n",
    "\n",
    "# è‡ªè¨‚å‡è¨­æ¨¡æ¿ (éœ€è¦æ›´åº•å±¤ API)\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "model_name = \"facebook/bart-large-mnli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "def custom_zero_shot(text, labels, hypothesis_template=\"This text is about {}.\"):\n",
    "    \"\"\"\n",
    "    è‡ªè¨‚å‡è¨­æ¨¡æ¿çš„é›¶æ¨£æœ¬åˆ†é¡\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for label in labels:\n",
    "        # æ§‹å»ºå‡è¨­\n",
    "        hypothesis = hypothesis_template.format(label)\n",
    "        \n",
    "        # NLI æ¨ç†\n",
    "        inputs = tokenizer(text, hypothesis, return_tensors=\"pt\", truncation=True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            # MNLI: [contradiction, neutral, entailment]\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            entailment_score = probs[0][2].item()  # å– entailment åˆ†æ•¸\n",
    "        \n",
    "        results.append((label, entailment_score))\n",
    "    \n",
    "    # æ’åº\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return results\n",
    "\n",
    "# æ¸¬è©¦ä¸åŒæ¨¡æ¿\n",
    "text = \"I love programming in Python!\"\n",
    "labels = [\"technology\", \"cooking\", \"sports\"]\n",
    "\n",
    "print(\"ä¸åŒå‡è¨­æ¨¡æ¿å°æ¯”:\\n\")\n",
    "\n",
    "templates = [\n",
    "    \"This example is {}.\",\n",
    "    \"This text is about {}.\",\n",
    "    \"The topic of this text is {}.\",\n",
    "]\n",
    "\n",
    "for template in templates:\n",
    "    results = custom_zero_shot(text, labels, template)\n",
    "    print(f\"æ¨¡æ¿: '{template}'\")\n",
    "    for label, score in results:\n",
    "        print(f\"  {label:12s}: {score:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. èª²å¾Œç·´ç¿’\n",
    "\n",
    "### ç·´ç¿’ 1: æ§‹å»ºæƒ…ç·’åˆ†é¡å™¨\n",
    "\n",
    "ä½¿ç”¨é›¶æ¨£æœ¬åˆ†é¡æ§‹å»º 6 ç¨®æƒ…ç·’çš„åˆ†é¡å™¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: å¯¦ä½œ 6 ç¨®æƒ…ç·’åˆ†é¡\n",
    "# æƒ…ç·’: joy, sadness, anger, fear, surprise, disgust\n",
    "# æ¸¬è©¦å¤šå€‹æ–‡æœ¬ç¯„ä¾‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç·´ç¿’ 2: å‹•æ…‹æ¨™ç±¤ç³»çµ±\n",
    "\n",
    "å¯¦ä½œä¸€å€‹å…è¨±ç”¨æˆ¶è‡ªå®šç¾©æ¨™ç±¤çš„åˆ†é¡ç³»çµ±ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: å¯¦ä½œäº’å‹•å¼æ¨™ç±¤ç³»çµ±\n",
    "# æç¤º:\n",
    "# 1. æ¥å—ç”¨æˆ¶è¼¸å…¥çš„æ–‡æœ¬\n",
    "# 2. æ¥å—ç”¨æˆ¶è‡ªå®šç¾©çš„æ¨™ç±¤åˆ—è¡¨\n",
    "# 3. è¿”å›åˆ†é¡çµæœ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. æœ¬ç¯€ç¸½çµ\n",
    "\n",
    "### âœ… é—œéµè¦é»\n",
    "\n",
    "1. **é›¶æ¨£æœ¬åŸç†**: åŸºæ–¼ NLI (è‡ªç„¶èªè¨€æ¨ç†) æ¨¡å‹\n",
    "2. **Multi-Label**: è¨­å®š `multi_label=True` æ”¯æ´å¤šæ¨™ç±¤\n",
    "3. **å‡è¨­æ¨¡æ¿**: å½±éŸ¿åˆ†é¡æ•ˆæœçš„é—œéµå› ç´ \n",
    "4. **æ‡‰ç”¨å ´æ™¯**: å¿«é€ŸåŸå‹ã€å‹•æ…‹é¡åˆ¥ã€å†·å•Ÿå‹•\n",
    "\n",
    "### ğŸ“Š æ•ˆèƒ½å°æ¯”\n",
    "\n",
    "| æ–¹æ³• | æº–ç¢ºç‡ | è¨“ç·´æ™‚é–“ | æ¨™è¨»æˆæœ¬ | éˆæ´»æ€§ |\n",
    "|------|--------|---------|---------|--------|\n",
    "| é›¶æ¨£æœ¬ | 70-85% | 0 | $0 | æ¥µé«˜ |\n",
    "| å¾®èª¿ | 90-95% | ~1h | $$$ | ä½ |\n",
    "| å¾é›¶è¨“ç·´ | 85-92% | ~10h | $$$$ | ä½ |\n",
    "\n",
    "### ğŸ“š å»¶ä¼¸é–±è®€\n",
    "\n",
    "- [Zero-Shot Learning è«–æ–‡](https://arxiv.org/abs/1909.00161)\n",
    "- [BART-MNLI æ¨¡å‹](https://huggingface.co/facebook/bart-large-mnli)\n",
    "- [NLI ä»»å‹™ä»‹ç´¹](https://nlp.stanford.edu/projects/snli/)\n",
    "\n",
    "### ğŸš€ ä¸‹ä¸€ç¯€é å‘Š\n",
    "\n",
    "**CH08-06: æ–‡æœ¬æ‘˜è¦ (Summarization)**\n",
    "- æŠ½å–å¼ vs ç”Ÿæˆå¼æ‘˜è¦\n",
    "- ä½¿ç”¨ BART/T5 ç”Ÿæˆæ‘˜è¦\n",
    "- æ‘˜è¦è³ªé‡è©•ä¼°\n",
    "\n",
    "---\n",
    "\n",
    "**èª²ç¨‹**: iSpan Python NLP Cookbooks v2\n",
    "**è¬›å¸«**: Claude AI\n",
    "**æœ€å¾Œæ›´æ–°**: 2025-10-17"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
