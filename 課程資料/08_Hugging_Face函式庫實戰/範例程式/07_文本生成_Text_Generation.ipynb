{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CH08-07: 文本生成 (Text Generation)\n",
    "\n",
    "**課程**: iSpan Python NLP Cookbooks v2\n",
    "**章節**: CH08 Hugging Face 函式庫實戰\n",
    "**版本**: v1.0\n",
    "**更新日期**: 2025-10-17\n",
    "\n",
    "---\n",
    "\n",
    "## 📚 本節學習目標\n",
    "\n",
    "1. 理解自回歸文本生成原理\n",
    "2. 掌握 GPT-2 文本生成技巧\n",
    "3. 學習生成策略 (Greedy, Beam Search, Sampling)\n",
    "4. 控制生成質量與多樣性\n",
    "5. 應用於實際場景 (故事續寫、對話生成)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. 自回歸生成原理\n",
    "\n",
    "### 1.1 生成過程\n",
    "\n",
    "```\n",
    "自回歸生成 (Autoregressive Generation):\n",
    "\n",
    "給定提示詞 (Prompt): \"Once upon a time\"\n",
    "\n",
    "Step 1: P(w4 | \"Once upon a time\") → \"there\"\n",
    "Step 2: P(w5 | \"Once upon a time there\") → \"was\"\n",
    "Step 3: P(w6 | \"Once upon a time there was\") → \"a\"\n",
    "...\n",
    "\n",
    "重複直到:\n",
    "- 生成 <EOS> token\n",
    "- 達到最大長度\n",
    "```\n",
    "\n",
    "### 1.2 生成策略對比\n",
    "\n",
    "| 策略 | 說明 | 優點 | 缺點 |\n",
    "|------|------|------|------|\n",
    "| **Greedy** | 每步選最高機率詞 | 快速、確定 | 重複、無創意 |\n",
    "| **Beam Search** | 保留 k 個候選序列 | 高質量 | 較慢、仍可能重複 |\n",
    "| **Top-K** | 從前 k 個詞中採樣 | 多樣性 | 可能不連貫 |\n",
    "| **Top-P (Nucleus)** | 累積機率達 p 的詞中採樣 | 平衡質量與多樣性 | 需調整 p |\n",
    "| **Temperature** | 調整機率分布平滑度 | 控制創意度 | 過高會混亂 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安裝套件\n",
    "# !pip install transformers torch -q\n",
    "\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"✅ 環境準備完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. 基礎文本生成\n",
    "\n",
    "### 2.1 使用 GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入 GPT-2 生成器\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"gpt2\",\n",
    "    device=-1\n",
    ")\n",
    "\n",
    "# 提示詞\n",
    "prompt = \"Artificial intelligence is\"\n",
    "\n",
    "# 生成文本\n",
    "results = generator(\n",
    "    prompt,\n",
    "    max_length=50,\n",
    "    num_return_sequences=3\n",
    ")\n",
    "\n",
    "print(f\"Prompt: \\\"{prompt}\\\"\\n\")\n",
    "print(\"生成結果:\\n\")\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"{i}. {result['generated_text']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 生成參數詳解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 參數完整示範\n",
    "result = generator(\n",
    "    \"In the future, technology will\",\n",
    "    max_length=80,              # 最大生成長度\n",
    "    min_length=30,              # 最小生成長度\n",
    "    num_return_sequences=1,     # 返回數量\n",
    "    temperature=0.8,            # 溫度 (0.0-2.0)\n",
    "    top_k=50,                   # Top-K 採樣\n",
    "    top_p=0.95,                 # Top-P (Nucleus) 採樣\n",
    "    repetition_penalty=1.2,     # 重複懲罰\n",
    "    do_sample=True,             # 啟用採樣\n",
    "    num_beams=1,                # Beam Search (1=不使用)\n",
    "    early_stopping=False        # 早停\n",
    ")\n",
    "\n",
    "print(\"生成結果:\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. 生成策略實驗\n",
    "\n",
    "### 3.1 Temperature 影響"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 測試不同 temperature\n",
    "prompt = \"The future of AI is\"\n",
    "temperatures = [0.3, 0.7, 1.0, 1.5]\n",
    "\n",
    "print(\"Temperature 對生成的影響:\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for temp in temperatures:\n",
    "    result = generator(\n",
    "        prompt,\n",
    "        max_length=40,\n",
    "        temperature=temp,\n",
    "        do_sample=True,\n",
    "        num_return_sequences=1\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nTemperature = {temp}:\")\n",
    "    print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Top-K vs Top-P 對比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Machine learning is\"\n",
    "\n",
    "configs = [\n",
    "    {\"do_sample\": False, \"name\": \"Greedy\"},\n",
    "    {\"do_sample\": True, \"top_k\": 10, \"name\": \"Top-K (k=10)\"},\n",
    "    {\"do_sample\": True, \"top_k\": 50, \"name\": \"Top-K (k=50)\"},\n",
    "    {\"do_sample\": True, \"top_p\": 0.9, \"name\": \"Top-P (p=0.9)\"},\n",
    "    {\"do_sample\": True, \"top_k\": 50, \"top_p\": 0.95, \"name\": \"Top-K + Top-P\"}\n",
    "]\n",
    "\n",
    "print(\"生成策略對比:\\n\")\n",
    "\n",
    "for config in configs:\n",
    "    name = config.pop('name')\n",
    "    \n",
    "    result = generator(\n",
    "        prompt,\n",
    "        max_length=40,\n",
    "        num_return_sequences=1,\n",
    "        **config\n",
    "    )\n",
    "    \n",
    "    print(f\"{name}:\")\n",
    "    print(result[0]['generated_text'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Beam Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beam Search 生成\n",
    "result = generator(\n",
    "    \"The most important invention in history is\",\n",
    "    max_length=50,\n",
    "    num_beams=5,              # Beam 數量\n",
    "    num_return_sequences=3,   # 返回前 3 個序列\n",
    "    early_stopping=True,\n",
    "    do_sample=False\n",
    ")\n",
    "\n",
    "print(\"Beam Search 結果 (num_beams=5):\\n\")\n",
    "for i, r in enumerate(result, 1):\n",
    "    print(f\"{i}. {r['generated_text']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. 實戰應用\n",
    "\n",
    "### 4.1 故事續寫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 故事開頭\n",
    "story_start = \"\"\"In a small village nestled in the mountains, \n",
    "there lived a young girl who discovered she had magical powers.\"\"\"\n",
    "\n",
    "# 生成續寫\n",
    "continuation = generator(\n",
    "    story_start,\n",
    "    max_length=150,\n",
    "    temperature=0.9,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.2,\n",
    "    do_sample=True,\n",
    "    num_return_sequences=2\n",
    ")\n",
    "\n",
    "print(\"故事續寫:\\n\")\n",
    "for i, story in enumerate(continuation, 1):\n",
    "    print(f\"版本 {i}:\")\n",
    "    print(story['generated_text'])\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 代碼生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用專門的代碼模型 (如果可用)\n",
    "code_prompt = \"\"\"def fibonacci(n):\n",
    "    # Calculate fibonacci sequence\n",
    "\"\"\"\n",
    "\n",
    "result = generator(\n",
    "    code_prompt,\n",
    "    max_length=100,\n",
    "    temperature=0.2,  # 低溫度保持確定性\n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "print(\"代碼生成:\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 對話生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 對話式生成\n",
    "conversation = \"\"\"User: What is machine learning?\n",
    "Assistant:\"\"\"\n",
    "\n",
    "response = generator(\n",
    "    conversation,\n",
    "    max_length=100,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "print(\"對話生成:\")\n",
    "print(response[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. 控制生成內容\n",
    "\n",
    "### 5.1 避免重複"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"The key to success is\"\n",
    "\n",
    "# 不使用重複懲罰\n",
    "result_no_penalty = generator(\n",
    "    prompt,\n",
    "    max_length=60,\n",
    "    repetition_penalty=1.0,\n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "# 使用重複懲罰\n",
    "result_with_penalty = generator(\n",
    "    prompt,\n",
    "    max_length=60,\n",
    "    repetition_penalty=1.5,  # 強烈懲罰重複\n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "print(\"不使用重複懲罰:\")\n",
    "print(result_no_penalty[0]['generated_text'])\n",
    "print(\"\\n使用重複懲罰 (1.5):\")\n",
    "print(result_with_penalty[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 長度控制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成不同長度\n",
    "lengths = [30, 60, 100]\n",
    "\n",
    "print(\"不同長度生成對比:\\n\")\n",
    "\n",
    "for length in lengths:\n",
    "    result = generator(\n",
    "        \"Deep learning models are\",\n",
    "        max_length=length,\n",
    "        temperature=0.8,\n",
    "        do_sample=True\n",
    "    )\n",
    "    \n",
    "    text = result[0]['generated_text']\n",
    "    print(f\"max_length={length} ({len(text.split())} 詞):\")\n",
    "    print(text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. 進階: 條件生成\n",
    "\n",
    "### 6.1 基於關鍵詞生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用關鍵詞引導生成\n",
    "keywords = [\"python\", \"data science\", \"tutorial\"]\n",
    "\n",
    "prompt = f\"Write a blog post about {', '.join(keywords)}:\\n\\n\"\n",
    "\n",
    "result = generator(\n",
    "    prompt,\n",
    "    max_length=120,\n",
    "    temperature=0.8,\n",
    "    top_p=0.95,\n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "print(\"關鍵詞:\", keywords)\n",
    "print(\"\\n生成文章:\")\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 風格遷移"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不同風格的生成\n",
    "base_content = \"Machine learning is a powerful technology.\"\n",
    "\n",
    "styles = [\n",
    "    \"Rewrite in simple words for beginners:\",\n",
    "    \"Rewrite in academic style:\",\n",
    "    \"Rewrite as a marketing pitch:\"\n",
    "]\n",
    "\n",
    "print(\"風格遷移生成:\\n\")\n",
    "\n",
    "for style in styles:\n",
    "    prompt = f\"{style} {base_content}\"\n",
    "    result = generator(\n",
    "        prompt,\n",
    "        max_length=80,\n",
    "        temperature=0.7,\n",
    "        do_sample=True\n",
    "    )\n",
    "    \n",
    "    print(f\"{style}\")\n",
    "    print(result[0]['generated_text'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. 生成質量評估\n",
    "\n",
    "### 7.1 困惑度 (Perplexity)"
   ]
  },
  {
   "cell_type