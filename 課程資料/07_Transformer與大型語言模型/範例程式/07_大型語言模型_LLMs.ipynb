{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# CH07-07: å¤§å‹èªè¨€æ¨¡å‹ (Large Language Models)\n",
    "\n",
    "**èª²ç¨‹æ™‚é•·**: 90 åˆ†é˜  \n",
    "**é›£åº¦**: â­â­â­â­  \n",
    "**å‰ç½®çŸ¥è­˜**: CH07-01 è‡³ CH07-06  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š æœ¬ç¯€å­¸ç¿’ç›®æ¨™\n",
    "\n",
    "1. âœ… ç†è§£ LLM çš„å®šç¾©èˆ‡è¦æ¨¡å®šå¾‹ (Scaling Laws)\n",
    "2. âœ… æŒæ¡ Instruction Tuning èˆ‡ RLHF åŸç†\n",
    "3. âœ… å­¸æœƒ Prompt Engineering æ ¸å¿ƒæŠ€å·§\n",
    "4. âœ… ç†è§£ In-Context Learning çš„å·¥ä½œæ©Ÿåˆ¶\n",
    "5. âœ… èªè­˜ LLM çš„èƒ½åŠ›é‚Šç•Œèˆ‡å€«ç†è­°é¡Œ\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“– ç›®éŒ„\n",
    "\n",
    "1. [ä»€éº¼æ˜¯å¤§å‹èªè¨€æ¨¡å‹](#1-what-is-llm)\n",
    "2. [è¦æ¨¡å®šå¾‹èˆ‡æ¹§ç¾èƒ½åŠ›](#2-scaling-laws)\n",
    "3. [å¾é è¨“ç·´åˆ°å°é½Š](#3-alignment)\n",
    "4. [Prompt Engineering å¯¦æˆ°](#4-prompt-engineering)\n",
    "5. [In-Context Learning åŸç†](#5-in-context-learning)\n",
    "6. [LLM çš„å±€é™æ€§èˆ‡æœªä¾†](#6-limitations)\n",
    "7. [ç¸½çµ](#7-summary)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-1",
   "metadata": {},
   "source": [
    "## 1. ä»€éº¼æ˜¯å¤§å‹èªè¨€æ¨¡å‹ {#1-what-is-llm}\n",
    "\n",
    "### 1.1 å®šç¾©\n",
    "\n",
    "**Large Language Model (LLM)**:\n",
    "> æ“æœ‰æ•¸åå„„è‡³æ•¸å…†åƒæ•¸çš„ Transformer æ¨¡å‹ï¼Œåœ¨å¤§è¦æ¨¡æ–‡æœ¬èªæ–™ä¸Šé è¨“ç·´ï¼Œå±•ç¾å‡ºå¼·å¤§çš„èªè¨€ç†è§£èˆ‡ç”Ÿæˆèƒ½åŠ›ã€‚\n",
    "\n",
    "**é—œéµç‰¹å¾µ**:\n",
    "- **è¦æ¨¡**: åƒæ•¸é‡é€šå¸¸ > 1B (10å„„)\n",
    "- **æ¶æ§‹**: ä¸»è¦åŸºæ–¼ Decoder-Only Transformer\n",
    "- **è¨“ç·´æ•¸æ“š**: æ•¸ç™¾ GB è‡³ TB ç´šæ–‡æœ¬\n",
    "- **èƒ½åŠ›**: Few-shot learning, In-context learning, Chain-of-thought reasoning\n",
    "\n",
    "### 1.2 LLM æ™‚é–“è»¸\n",
    "\n",
    "```\n",
    "2018 â”€ GPT (117M)          â””â”€ è­‰æ˜é è¨“ç·´æœ‰æ•ˆæ€§\n",
    "       BERT (340M)\n",
    "\n",
    "2019 â”€ GPT-2 (1.5B)        â””â”€ é¦–å€‹ 10å„„+ åƒæ•¸æ¨¡å‹\n",
    "       T5 (11B)\n",
    "\n",
    "2020 â”€ GPT-3 (175B)        â””â”€ Few-shot learning çªç ´\n",
    "\n",
    "2021 â”€ Codex (12B)         â””â”€ å°ˆç²¾ç¨‹å¼ç¢¼\n",
    "       DALL-E (12B)\n",
    "\n",
    "2022 â”€ ChatGPT             â””â”€ RLHF + Instruction Tuning\n",
    "       InstructGPT\n",
    "\n",
    "2023 â”€ GPT-4 (~1.8T?)      â””â”€ Multimodal LLM\n",
    "       LLaMA (7B-65B)      â””â”€ é–‹æºé«˜æ•ˆ LLM\n",
    "       Mistral (7B)        â””â”€ MoE æ¶æ§‹\n",
    "\n",
    "2024 â”€ Gemini 1.5 Pro      â””â”€ è¶…é•·ä¸Šä¸‹æ–‡ (1M tokens)\n",
    "       Claude 3            â””â”€ å„ªç§€æ¨ç†èƒ½åŠ›\n",
    "```\n",
    "\n",
    "### 1.3 åƒæ•¸è¦æ¨¡å°æ¯”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¼‰å…¥å¿…è¦å¥—ä»¶\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'Arial Unicode MS']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"âœ… å¥—ä»¶è¼‰å…¥å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-params-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¦–è¦ºåŒ–æ¨¡å‹åƒæ•¸è¦æ¨¡æ¼”é€²\n",
    "\n",
    "models_data = {\n",
    "    'Model': [\n",
    "        'BERT-Large', 'GPT', 'GPT-2', 'T5-11B', 'GPT-3', \n",
    "        'LLaMA-65B', 'PaLM', 'GPT-4 (ä¼°è¨ˆ)'\n",
    "    ],\n",
    "    'Parameters (B)': [0.34, 0.117, 1.5, 11, 175, 65, 540, 1800],\n",
    "    'Year': [2018, 2018, 2019, 2019, 2020, 2023, 2022, 2023],\n",
    "    'Type': ['Encoder', 'Decoder', 'Decoder', 'Enc-Dec', 'Decoder', \n",
    "             'Decoder', 'Decoder', 'Decoder']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(models_data)\n",
    "\n",
    "# ç¹ªåœ–\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# å·¦åœ–: å°æ•¸å°ºåº¦çš„åƒæ•¸å¢é•·\n",
    "colors = {'Encoder': 'skyblue', 'Decoder': 'lightcoral', 'Enc-Dec': 'lightgreen'}\n",
    "for model_type in df['Type'].unique():\n",
    "    subset = df[df['Type'] == model_type]\n",
    "    axes[0].scatter(\n",
    "        subset['Year'], \n",
    "        subset['Parameters (B)'], \n",
    "        s=200, \n",
    "        alpha=0.7,\n",
    "        label=model_type,\n",
    "        color=colors[model_type]\n",
    "    )\n",
    "    \n",
    "    for _, row in subset.iterrows():\n",
    "        axes[0].text(\n",
    "            row['Year'], \n",
    "            row['Parameters (B)'] * 1.3, \n",
    "            row['Model'], \n",
    "            ha='center', \n",
    "            fontsize=9\n",
    "        )\n",
    "\n",
    "axes[0].set_yscale('log')\n",
    "axes[0].set_xlabel('ç™¼å¸ƒå¹´ä»½', fontsize=12)\n",
    "axes[0].set_ylabel('åƒæ•¸é‡ (Billions, å°æ•¸å°ºåº¦)', fontsize=12)\n",
    "axes[0].set_title('LLM åƒæ•¸è¦æ¨¡æ¼”é€² (2018-2023)', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# å³åœ–: åƒæ•¸é‡æ¢å½¢åœ–\n",
    "df_sorted = df.sort_values('Parameters (B)')\n",
    "bar_colors = [colors[t] for t in df_sorted['Type']]\n",
    "\n",
    "axes[1].barh(df_sorted['Model'], df_sorted['Parameters (B)'], color=bar_colors, alpha=0.7)\n",
    "axes[1].set_xlabel('åƒæ•¸é‡ (Billions)', fontsize=12)\n",
    "axes[1].set_title('æ¨¡å‹åƒæ•¸é‡å°æ¯”', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xscale('log')\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "for i, (model, params) in enumerate(zip(df_sorted['Model'], df_sorted['Parameters (B)'])):\n",
    "    axes[1].text(params * 1.2, i, f'{params}B', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\né—œéµè§€å¯Ÿ:\")\n",
    "print(f\"â€¢ 2018-2023 å¹´é–“ï¼Œæœ€å¤§æ¨¡å‹åƒæ•¸å¢é•·äº† {1800/0.117:.0f}x å€\")\n",
    "print(\"â€¢ Decoder-Only æ¶æ§‹ä¸»å° LLM ç™¼å±•\")\n",
    "print(\"â€¢ GPT-4 åƒæ•¸é‡ç´„ç‚º GPT-3 çš„ 10 å€\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-2",
   "metadata": {},
   "source": [
    "## 2. è¦æ¨¡å®šå¾‹èˆ‡æ¹§ç¾èƒ½åŠ› {#2-scaling-laws}\n",
    "\n",
    "### 2.1 Scaling Laws (è¦æ¨¡å®šå¾‹)\n",
    "\n",
    "**æ ¸å¿ƒç™¼ç¾** (Kaplan et al., 2020):\n",
    "> èªè¨€æ¨¡å‹çš„æ•ˆèƒ½èˆ‡ä¸‰å€‹å› ç´ å‘ˆç¾å†ªå¾‹é—œä¿‚ (Power Law):\n",
    "> 1. æ¨¡å‹åƒæ•¸é‡ (N)\n",
    "> 2. è¨“ç·´æ•¸æ“šé‡ (D)\n",
    "> 3. è¨ˆç®—é‡ (C)\n",
    "\n",
    "**æ•¸å­¸å½¢å¼**:\n",
    "$$\n",
    "\\text{Loss}(N) \\propto N^{-\\alpha}\n",
    "$$\n",
    "\n",
    "**å¯¦éš›æ„ç¾©**:\n",
    "- 10x åƒæ•¸ â†’ é¡¯è‘—çš„æ•ˆèƒ½æå‡\n",
    "- ä½†æ•ˆèƒ½æå‡é€Ÿåº¦éæ¸› (é‚Šéš›æ•ˆæ‡‰)\n",
    "\n",
    "### 2.2 æ¹§ç¾èƒ½åŠ› (Emergent Abilities)\n",
    "\n",
    "**å®šç¾©**:\n",
    "> ç•¶æ¨¡å‹è¦æ¨¡è¶…éæŸå€‹è‡¨ç•Œé»æ™‚ï¼Œçªç„¶å±•ç¾å‡ºå°æ¨¡å‹ä¸å…·å‚™çš„èƒ½åŠ›ã€‚\n",
    "\n",
    "**å…¸å‹æ¹§ç¾èƒ½åŠ›**:\n",
    "\n",
    "1. **ç®—è¡“æ¨ç†**\n",
    "   - < 10B: å¹¾ä¹ç„¡æ³•è§£æ±º\n",
    "   - 10B-100B: é–‹å§‹å‡ºç¾èƒ½åŠ›\n",
    "   - > 100B: æ¥è¿‘äººé¡æ°´å¹³\n",
    "\n",
    "2. **å¤šæ­¥æ¨ç† (Chain-of-Thought)**\n",
    "   ```\n",
    "   å•é¡Œ: \"Roger æœ‰ 5 é¡†ç¶²çƒã€‚ä»–åˆè²·äº† 2 ç½ç¶²çƒï¼Œæ¯ç½ 3 é¡†ã€‚ä»–ç¾åœ¨æœ‰å¹¾é¡†ç¶²çƒ?\"\n",
    "   \n",
    "   å°æ¨¡å‹ (<10B): \"7 é¡†\" âŒ\n",
    "   \n",
    "   å¤§æ¨¡å‹ (>100B):\n",
    "   \"è®“æˆ‘å€‘ä¸€æ­¥æ­¥æ€è€ƒ:\n",
    "   1. Roger åŸæœ¬æœ‰ 5 é¡†ç¶²çƒ\n",
    "   2. ä»–è²·äº† 2 ç½ï¼Œæ¯ç½ 3 é¡†ï¼Œæ‰€ä»¥è²·äº† 2 Ã— 3 = 6 é¡†\n",
    "   3. ç¸½å…±æœ‰ 5 + 6 = 11 é¡†ç¶²çƒ\" âœ…\n",
    "   ```\n",
    "\n",
    "3. **Few-Shot Learning**\n",
    "   - å¾å°‘é‡ç¯„ä¾‹ä¸­å­¸ç¿’æ–°ä»»å‹™\n",
    "   - ç„¡éœ€æ¢¯åº¦æ›´æ–°\n",
    "\n",
    "4. **Code Generation**\n",
    "   - å¾è‡ªç„¶èªè¨€ç”Ÿæˆå¯åŸ·è¡Œç¨‹å¼ç¢¼\n",
    "\n",
    "### 2.3 è¦–è¦ºåŒ–æ¹§ç¾èƒ½åŠ›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emergent-abilities-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¨¡æ“¬æ¹§ç¾èƒ½åŠ›æ›²ç·š\n",
    "\n",
    "def sigmoid_emergence(x, threshold, steepness):\n",
    "    \"\"\"æ¨¡æ“¬æ¹§ç¾èƒ½åŠ›çš„ sigmoid æ›²ç·š\"\"\"\n",
    "    return 1 / (1 + np.exp(-steepness * (x - threshold)))\n",
    "\n",
    "# åƒæ•¸è¦æ¨¡ (å°æ•¸å°ºåº¦)\n",
    "params = np.logspace(8, 12, 100)  # 100M to 1T\n",
    "\n",
    "# ä¸åŒèƒ½åŠ›çš„æ¹§ç¾é»\n",
    "abilities = {\n",
    "    'åŸºç¤èªè¨€èƒ½åŠ›': (9.5, 2),\n",
    "    'Few-Shot Learning': (10.5, 3),\n",
    "    'ç®—è¡“æ¨ç†': (11.0, 4),\n",
    "    'Chain-of-Thought': (11.5, 5),\n",
    "    'è¤‡é›œæ¨ç†': (11.8, 6)\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "for ability, (threshold, steepness) in abilities.items():\n",
    "    performance = sigmoid_emergence(np.log10(params), threshold, steepness)\n",
    "    ax.plot(params, performance * 100, label=ability, linewidth=2.5)\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('æ¨¡å‹åƒæ•¸é‡', fontsize=13)\n",
    "ax.set_ylabel('ä»»å‹™è¡¨ç¾ (%)', fontsize=13)\n",
    "ax.set_title('LLM æ¹§ç¾èƒ½åŠ›: ä¸åŒè¦æ¨¡ä¸‹çš„è¡¨ç¾', fontsize=15, fontweight='bold')\n",
    "ax.legend(fontsize=11, loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# æ¨™è¨˜é‡è¦é‡Œç¨‹ç¢‘\n",
    "milestones = [\n",
    "    (1e9, 'GPT-2\\n1.5B'),\n",
    "    (1e11, 'GPT-3\\n175B'),\n",
    "    (5e11, 'PaLM\\n540B')\n",
    "]\n",
    "\n",
    "for param, label in milestones:\n",
    "    ax.axvline(param, color='gray', linestyle='--', alpha=0.5)\n",
    "    ax.text(param, 95, label, ha='center', fontsize=9, \n",
    "            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "ax.set_xticks([1e8, 1e9, 1e10, 1e11, 1e12])\n",
    "ax.set_xticklabels(['100M', '1B', '10B', '100B', '1T'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\næ¹§ç¾èƒ½åŠ›çš„ç‰¹é»:\")\n",
    "print(\"â€¢ éç·šæ€§: èƒ½åŠ›çªç„¶çˆ†ç™¼ï¼Œè€Œéå¹³æ»‘å¢é•·\")\n",
    "print(\"â€¢ é–¾å€¼æ•ˆæ‡‰: å­˜åœ¨æ˜ç¢ºçš„è‡¨ç•Œè¦æ¨¡\")\n",
    "print(\"â€¢ ä¸å¯é æ¸¬: é›£ä»¥é å…ˆçŸ¥é“ä½•æ™‚æœƒæ¹§ç¾æ–°èƒ½åŠ›\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3",
   "metadata": {},
   "source": [
    "## 3. å¾é è¨“ç·´åˆ°å°é½Š {#3-alignment}\n",
    "\n",
    "### 3.1 LLM è¨“ç·´çš„ä¸‰å€‹éšæ®µ\n",
    "\n",
    "```\n",
    "éšæ®µ 1: é è¨“ç·´ (Pre-training)\n",
    "        â†“\n",
    "   å­¸åˆ°èªè¨€çµæ§‹èˆ‡çŸ¥è­˜\n",
    "        â†“\n",
    "éšæ®µ 2: æŒ‡ä»¤å¾®èª¿ (Instruction Tuning)\n",
    "        â†“\n",
    "   å­¸æœƒéµå¾ªæŒ‡ä»¤\n",
    "        â†“\n",
    "éšæ®µ 3: äººé¡åé¥‹å¼·åŒ–å­¸ç¿’ (RLHF)\n",
    "        â†“\n",
    "   å°é½Šäººé¡åƒ¹å€¼è§€\n",
    "```\n",
    "\n",
    "### 3.2 éšæ®µ 1: é è¨“ç·´ (Pre-training)\n",
    "\n",
    "**ç›®æ¨™**: å­¸ç¿’èªè¨€çš„çµ±è¨ˆçµæ§‹èˆ‡ä¸–ç•ŒçŸ¥è­˜\n",
    "\n",
    "**è¨“ç·´ä»»å‹™**: Causal Language Modeling\n",
    "```python\n",
    "Input:  \"The capital of France is\"\n",
    "Target: \"Paris\"\n",
    "\n",
    "Loss = -log P(\"Paris\" | \"The capital of France is\")\n",
    "```\n",
    "\n",
    "**è¨“ç·´æ•¸æ“š**:\n",
    "- Common Crawl (ç¶²é )\n",
    "- Books (æ›¸ç±)\n",
    "- Wikipedia (ç™¾ç§‘)\n",
    "- GitHub (ç¨‹å¼ç¢¼)\n",
    "- Reddit, StackOverflow (è«–å£‡)\n",
    "\n",
    "**GPT-3 æ•¸æ“šçµ„æˆ**:\n",
    "- Common Crawl: 60%\n",
    "- WebText2: 22%\n",
    "- Books: 16%\n",
    "- Wikipedia: 3%\n",
    "\n",
    "**æŒ‘æˆ°**:\n",
    "- è¨ˆç®—æˆæœ¬æ¥µé«˜ (æ•¸ç™¾è¬ç¾å…ƒ)\n",
    "- éœ€è¦æ•¸åƒå€‹ GPU/TPU\n",
    "- è¨“ç·´æ™‚é–“: æ•¸é€±è‡³æ•¸æœˆ\n",
    "\n",
    "### 3.3 éšæ®µ 2: æŒ‡ä»¤å¾®èª¿ (Instruction Tuning)\n",
    "\n",
    "**ç›®æ¨™**: è®“æ¨¡å‹ç†è§£ä¸¦éµå¾ªäººé¡æŒ‡ä»¤\n",
    "\n",
    "**è³‡æ–™æ ¼å¼**:\n",
    "```python\n",
    "# ç¯„ä¾‹ 1: å•ç­”\n",
    "Instruction: \"What is the capital of France?\"\n",
    "Response: \"The capital of France is Paris.\"\n",
    "\n",
    "# ç¯„ä¾‹ 2: ç¿»è­¯\n",
    "Instruction: \"Translate to French: Hello, how are you?\"\n",
    "Response: \"Bonjour, comment allez-vous?\"\n",
    "\n",
    "# ç¯„ä¾‹ 3: ç¨‹å¼ç¢¼\n",
    "Instruction: \"Write a Python function to calculate factorial\"\n",
    "Response: \"def factorial(n):\\n    if n == 0: return 1\\n    return n * factorial(n-1)\"\n",
    "```\n",
    "\n",
    "**è³‡æ–™é›†**:\n",
    "- **FLAN** (Google): 1800+ ä»»å‹™\n",
    "- **T0** (BigScience): å¤šæ¨£åŒ– prompts\n",
    "- **Self-Instruct** (Stanford): ä½¿ç”¨ GPT-3 ç”ŸæˆæŒ‡ä»¤æ•¸æ“š\n",
    "\n",
    "**æ•ˆæœ**:\n",
    "- é¡¯è‘—æå‡éµå¾ªæŒ‡ä»¤çš„èƒ½åŠ›\n",
    "- æ”¹å–„ zero-shot è¡¨ç¾\n",
    "- æ¸›å°‘æœ‰å®³è¼¸å‡º\n",
    "\n",
    "### 3.4 éšæ®µ 3: RLHF (Reinforcement Learning from Human Feedback)\n",
    "\n",
    "**æ ¸å¿ƒæ€æƒ³**: ç”¨äººé¡åå¥½è¨“ç·´çå‹µæ¨¡å‹ï¼Œå†ç”¨ RL å„ªåŒ– LLM\n",
    "\n",
    "**æµç¨‹**:\n",
    "\n",
    "```\n",
    "Step 1: æ”¶é›†äººé¡åå¥½æ•¸æ“š\n",
    "   Prompt: \"å¯«ä¸€é¦–é—œæ–¼æ˜¥å¤©çš„è©©\"\n",
    "   Response A: [è©©æ­Œ A]\n",
    "   Response B: [è©©æ­Œ B]\n",
    "   äººé¡æ¨™è¨»: A > B  (A æ›´å¥½)\n",
    "\n",
    "Step 2: è¨“ç·´çå‹µæ¨¡å‹ (Reward Model)\n",
    "   è¼¸å…¥: (Prompt, Response)\n",
    "   è¼¸å‡º: Reward Score (é æ¸¬äººé¡æ»¿æ„åº¦)\n",
    "\n",
    "Step 3: ç”¨ PPO æ¼”ç®—æ³•å„ªåŒ– LLM\n",
    "   ç›®æ¨™: æœ€å¤§åŒ–çå‹µæ¨¡å‹çš„åˆ†æ•¸\n",
    "   ç´„æŸ: ä¸è¦åé›¢åŸå§‹æ¨¡å‹å¤ªé  (KL divergence penalty)\n",
    "```\n",
    "\n",
    "**æ•¸å­¸å½¢å¼**:\n",
    "$$\n",
    "\\text{Objective} = \\mathbb{E}_{x \\sim D, y \\sim \\pi_\\theta}[r(x, y)] - \\beta \\cdot D_{KL}(\\pi_\\theta || \\pi_{\\text{ref}})\n",
    "$$\n",
    "\n",
    "å…¶ä¸­:\n",
    "- $r(x, y)$: çå‹µæ¨¡å‹åˆ†æ•¸\n",
    "- $\\pi_\\theta$: ç•¶å‰ç­–ç•¥ (LLM)\n",
    "- $\\pi_{\\text{ref}}$: åƒè€ƒç­–ç•¥ (åŸå§‹æ¨¡å‹)\n",
    "- $\\beta$: KL æ‡²ç½°ä¿‚æ•¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rlhf-process-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¦–è¦ºåŒ– RLHF æµç¨‹\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "# å®šç¾©æµç¨‹åœ–ç¯€é»\n",
    "steps = [\n",
    "    (0.5, 0.9, \"é è¨“ç·´ LLM\", 'lightblue'),\n",
    "    (0.5, 0.75, \"Instruction Tuning\", 'lightgreen'),\n",
    "    (0.2, 0.55, \"æ”¶é›†åå¥½æ•¸æ“š\\n(A vs B)\", 'lightyellow'),\n",
    "    (0.5, 0.55, \"è¨“ç·´çå‹µæ¨¡å‹\\n(Reward Model)\", 'lightcoral'),\n",
    "    (0.8, 0.55, \"ç”Ÿæˆå¤šå€‹å›æ‡‰\", 'lavender'),\n",
    "    (0.5, 0.35, \"PPO å¼·åŒ–å­¸ç¿’å„ªåŒ–\", 'lightgreen'),\n",
    "    (0.5, 0.15, \"å°é½Šå¾Œçš„ LLM\\n(ChatGPT)\", 'gold')\n",
    "]\n",
    "\n",
    "for x, y, label, color in steps:\n",
    "    ax.add_patch(plt.Rectangle(\n",
    "        (x-0.12, y-0.05), 0.24, 0.08, \n",
    "        facecolor=color, edgecolor='black', linewidth=2\n",
    "    ))\n",
    "    ax.text(x, y, label, ha='center', va='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "# ç¹ªè£½ç®­é ­\n",
    "arrows = [\n",
    "    ((0.5, 0.82), (0.5, 0.75)),\n",
    "    ((0.5, 0.70), (0.2, 0.60)),\n",
    "    ((0.5, 0.70), (0.5, 0.60)),\n",
    "    ((0.5, 0.70), (0.8, 0.60)),\n",
    "    ((0.2, 0.50), (0.5, 0.40)),\n",
    "    ((0.5, 0.50), (0.5, 0.40)),\n",
    "    ((0.8, 0.50), (0.5, 0.40)),\n",
    "    ((0.5, 0.30), (0.5, 0.20))\n",
    "]\n",
    "\n",
    "for start, end in arrows:\n",
    "    ax.annotate('', xy=end, xytext=start,\n",
    "               arrowprops=dict(arrowstyle='->', lw=2, color='darkblue'))\n",
    "\n",
    "# æ·»åŠ èªªæ˜æ–‡å­—\n",
    "annotations = [\n",
    "    (0.15, 0.60, \"äººé¡è©•åˆ†å“¡\\næ¯”è¼ƒå›æ‡‰\", 9),\n",
    "    (0.65, 0.60, \"LLM ç”Ÿæˆ\\nå€™é¸å›æ‡‰\", 9),\n",
    "    (0.75, 0.35, \"æœ€å¤§åŒ–\\nçå‹µåˆ†æ•¸\", 9, 'green'),\n",
    "    (0.25, 0.35, \"å­¸ç¿’\\näººé¡åå¥½\", 9, 'red')\n",
    "]\n",
    "\n",
    "for x, y, text, size, *color in annotations:\n",
    "    c = color[0] if color else 'black'\n",
    "    ax.text(x, y, text, ha='center', fontsize=size, style='italic', color=c,\n",
    "           bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.axis('off')\n",
    "ax.set_title('RLHF å®Œæ•´æµç¨‹: å¾é è¨“ç·´åˆ°å°é½Š', fontsize=16, fontweight='bold', pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nRLHF çš„é‡è¦æ€§:\")\n",
    "print(\"â€¢ ä½¿ LLM æ›´å®‰å…¨ã€æ›´æœ‰ç”¨ã€æ›´èª å¯¦\")\n",
    "print(\"â€¢ æ¸›å°‘æœ‰å®³ã€åè¦‹ã€éŒ¯èª¤çš„è¼¸å‡º\")\n",
    "print(\"â€¢ ChatGPT çš„æˆåŠŸé—œéµä¹‹ä¸€\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-4",
   "metadata": {},
   "source": [
    "## 4. Prompt Engineering å¯¦æˆ° {#4-prompt-engineering}\n",
    "\n",
    "### 4.1 ä»€éº¼æ˜¯ Prompt Engineering?\n",
    "\n",
    "**å®šç¾©**:\n",
    "> è¨­è¨ˆå’Œå„ªåŒ–è¼¸å…¥æ–‡æœ¬ (prompt)ï¼Œä»¥å¼•å° LLM ç”¢ç”ŸæœŸæœ›çš„è¼¸å‡ºã€‚\n",
    "\n",
    "**ç‚ºä»€éº¼é‡è¦?**\n",
    "- LLM å° prompt æªè¾­æ¥µåº¦æ•æ„Ÿ\n",
    "- å¥½çš„ prompt å¯ä»¥å¤§å¹…æå‡è¡¨ç¾\n",
    "- ç„¡éœ€å¾®èª¿ï¼Œæˆæœ¬ä½å»‰\n",
    "\n",
    "### 4.2 æ ¸å¿ƒæŠ€å·§\n",
    "\n",
    "#### æŠ€å·§ 1: Zero-Shot Prompting\n",
    "\n",
    "**åŸºç¤ç‰ˆ**:\n",
    "```\n",
    "Prompt: \"Classify the sentiment: I love this product!\"\n",
    "Output: \"Positive\"\n",
    "```\n",
    "\n",
    "**æ”¹é€²ç‰ˆ** (æ›´æ˜ç¢ºçš„æŒ‡ä»¤):\n",
    "```\n",
    "Prompt: \"Classify the sentiment of the following text as Positive, Negative, or Neutral.\\n\\nText: I love this product!\\nSentiment:\"\n",
    "Output: \"Positive\"\n",
    "```\n",
    "\n",
    "#### æŠ€å·§ 2: Few-Shot Prompting\n",
    "\n",
    "æä¾›ç¯„ä¾‹ä¾†å¼•å°æ¨¡å‹:\n",
    "\n",
    "```\n",
    "Classify sentiment as Positive, Negative, or Neutral.\n",
    "\n",
    "Text: \"This movie was amazing!\"\n",
    "Sentiment: Positive\n",
    "\n",
    "Text: \"I hated this book.\"\n",
    "Sentiment: Negative\n",
    "\n",
    "Text: \"The weather is okay.\"\n",
    "Sentiment: Neutral\n",
    "\n",
    "Text: \"Best purchase ever!\"\n",
    "Sentiment:\n",
    "```\n",
    "\n",
    "#### æŠ€å·§ 3: Chain-of-Thought (CoT) Prompting\n",
    "\n",
    "**æ¨™æº– Prompt** (è¡¨ç¾å·®):\n",
    "```\n",
    "Q: Roger æœ‰ 5 é¡†ç¶²çƒã€‚ä»–åˆè²·äº† 2 ç½ï¼Œæ¯ç½ 3 é¡†ã€‚ä»–ç¾åœ¨æœ‰å¹¾é¡†?\n",
    "A: 7\n",
    "```\n",
    "\n",
    "**CoT Prompt** (è¡¨ç¾å¥½):\n",
    "```\n",
    "Q: Roger æœ‰ 5 é¡†ç¶²çƒã€‚ä»–åˆè²·äº† 2 ç½ï¼Œæ¯ç½ 3 é¡†ã€‚ä»–ç¾åœ¨æœ‰å¹¾é¡†?\n",
    "A: Let's think step by step.\n",
    "1. Roger åŸæœ¬æœ‰ 5 é¡†ç¶²çƒ\n",
    "2. ä»–è²·äº† 2 ç½ï¼Œæ¯ç½ 3 é¡†ï¼Œæ‰€ä»¥æ˜¯ 2 Ã— 3 = 6 é¡†\n",
    "3. ç¸½å…± 5 + 6 = 11 é¡†\n",
    "ç­”æ¡ˆæ˜¯ 11 é¡†ã€‚\n",
    "```\n",
    "\n",
    "**ç¥å¥‡çš„ä¸€å¥è©±**: `\"Let's think step by step.\"`\n",
    "\n",
    "#### æŠ€å·§ 4: Self-Consistency\n",
    "\n",
    "ç”Ÿæˆå¤šå€‹æ¨ç†è·¯å¾‘ï¼Œå–å¤šæ•¸æ±º:\n",
    "\n",
    "```\n",
    "åŒä¸€å•é¡Œç”Ÿæˆ 5 æ¬¡ (temperature > 0):\n",
    "è·¯å¾‘ 1: ... ç­”æ¡ˆæ˜¯ 11\n",
    "è·¯å¾‘ 2: ... ç­”æ¡ˆæ˜¯ 11\n",
    "è·¯å¾‘ 3: ... ç­”æ¡ˆæ˜¯ 7  (éŒ¯èª¤)\n",
    "è·¯å¾‘ 4: ... ç­”æ¡ˆæ˜¯ 11\n",
    "è·¯å¾‘ 5: ... ç­”æ¡ˆæ˜¯ 11\n",
    "\n",
    "æœ€çµ‚ç­”æ¡ˆ: 11 (å¤šæ•¸æ±º)\n",
    "```\n",
    "\n",
    "#### æŠ€å·§ 5: Role Prompting\n",
    "\n",
    "```\n",
    "å·®: \"å¯«ä¸€ç¯‡é—œæ–¼æ°£å€™è®Šé·çš„æ–‡ç« \"\n",
    "\n",
    "å¥½: \"ä½ æ˜¯ä¸€ä½å°ˆç²¾æ°£å€™ç§‘å­¸çš„è³‡æ·±æ•™æˆã€‚è«‹ç”¨æ·ºé¡¯æ˜“æ‡‚çš„æ–¹å¼ï¼Œå‘é«˜ä¸­ç”Ÿè§£é‡‹æ°£å€™è®Šé·çš„åŸå› èˆ‡å½±éŸ¿ã€‚\"\n",
    "```\n",
    "\n",
    "### 4.3 Prompt è¨­è¨ˆåŸå‰‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-principles",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å±•ç¤º Prompt Engineering çš„æœ€ä½³å¯¦è¸\n",
    "\n",
    "principles = {\n",
    "    'åŸå‰‡': [\n",
    "        '1. æ˜ç¢ºæ€§',\n",
    "        '2. å…·é«”æ€§',\n",
    "        '3. ç¯„ä¾‹å°å‘',\n",
    "        '4. çµæ§‹åŒ–è¼¸å‡º',\n",
    "        '5. è¿­ä»£å„ªåŒ–'\n",
    "    ],\n",
    "    'å·®çš„ Prompt': [\n",
    "        '\"åˆ†é¡é€™å€‹\"',\n",
    "        '\"å¯«é»æ±è¥¿\"',\n",
    "        'æ²’æœ‰ç¯„ä¾‹',\n",
    "        '\"å‘Šè¨´æˆ‘çµæœ\"',\n",
    "        'ä¸€æ¬¡å°±æƒ³å®Œç¾'\n",
    "    ],\n",
    "    'å¥½çš„ Prompt': [\n",
    "        '\"å°‡ä»¥ä¸‹æ–‡æœ¬åˆ†é¡ç‚º Positive/Negative\"',\n",
    "        '\"ç”¨ 3 æ®µè½ä»‹ç´¹ Transformerï¼Œæ¯æ®µ 100 å­—\"',\n",
    "        'æä¾› 2-3 å€‹ç¯„ä¾‹',\n",
    "        '\"ä»¥ JSON æ ¼å¼è¼¸å‡º: {\\\"sentiment\\\": ...}\"',\n",
    "        'æ¸¬è©¦å¤šå€‹ç‰ˆæœ¬ï¼Œé¸æœ€ä½³'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_principles = pd.DataFrame(principles)\n",
    "\n",
    "# ä½¿ç”¨ HTML é¡¯ç¤ºè¡¨æ ¼\n",
    "print(\"=\" * 80)\n",
    "print(\"Prompt Engineering è¨­è¨ˆåŸå‰‡\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "for _, row in df_principles.iterrows():\n",
    "    print(f\"{row['åŸå‰‡']:20s}\")\n",
    "    print(f\"  âŒ å·®: {row['å·®çš„ Prompt']}\")\n",
    "    print(f\"  âœ… å¥½: {row['å¥½çš„ Prompt']}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"\\næ ¸å¿ƒå»ºè­°:\")\n",
    "print(\"â€¢ æŠŠ LLM ç•¶ä½œä¸€å€‹è°æ˜ä½†å­—é¢æ„ç¾©çš„åŠ©æ‰‹\")\n",
    "print(\"â€¢ æä¾›ä¸Šä¸‹æ–‡ã€ç¯„ä¾‹ã€æ ¼å¼è¦æ±‚\")\n",
    "print(\"â€¢ è¿­ä»£æ¸¬è©¦ï¼Œè¨˜éŒ„æœ‰æ•ˆçš„ prompts\")\n",
    "print(\"â€¢ ä½¿ç”¨ temperature=0 ä¿è­‰ç©©å®šè¼¸å‡º\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-5",
   "metadata": {},
   "source": [
    "## 5. In-Context Learning åŸç† {#5-in-context-learning}\n",
    "\n",
    "### 5.1 ä»€éº¼æ˜¯ In-Context Learning?\n",
    "\n",
    "**å®šç¾©**:\n",
    "> LLM èƒ½å¤ åœ¨æ¨è«–æ™‚å¾ prompt ä¸­çš„ç¯„ä¾‹å­¸ç¿’ï¼ŒåŸ·è¡Œæ–°ä»»å‹™ï¼Œç„¡éœ€æ›´æ–°åƒæ•¸ã€‚\n",
    "\n",
    "**ç¥å¥‡ä¹‹è™•**:\n",
    "- ä¸éœ€è¦æ¢¯åº¦ä¸‹é™\n",
    "- ä¸éœ€è¦å¾®èª¿\n",
    "- åªéœ€è¦åœ¨ prompt ä¸­æä¾›ç¯„ä¾‹\n",
    "\n",
    "**ç¯„ä¾‹**:\n",
    "```python\n",
    "# æ¨¡å‹å¾æœªè¦‹éé€™å€‹ä»»å‹™ï¼Œä½†èƒ½ç«‹å³å­¸æœƒ\n",
    "Prompt = \"\"\"\n",
    "å°‡å¥å­è½‰æ›ç‚ºéå»å¼:\n",
    "\n",
    "I walk to school â†’ I walked to school\n",
    "She eats an apple â†’ She ate an apple\n",
    "They play soccer â†’ They played soccer\n",
    "He runs fast â†’\n",
    "\"\"\"\n",
    "\n",
    "Output: \"He ran fast\"\n",
    "```\n",
    "\n",
    "### 5.2 å·¥ä½œæ©Ÿåˆ¶å‡èªª\n",
    "\n",
    "**å‡èªª 1: éš±å¼å¾®èª¿**\n",
    "- LLM å…§éƒ¨åŸ·è¡Œäº†é¡ä¼¼æ¢¯åº¦ä¸‹é™çš„éç¨‹\n",
    "- å‰å‘å‚³æ’­ä¸­èª¿æ•´å…§éƒ¨è¡¨ç¤º\n",
    "\n",
    "**å‡èªª 2: æ¨¡å¼åŒ¹é…**\n",
    "- è¨“ç·´æ™‚è¦‹éé¡ä¼¼çš„ few-shot æ¨¡å¼\n",
    "- è­˜åˆ¥ä¸¦è¤‡è£½è©²æ¨¡å¼\n",
    "\n",
    "**å‡èªª 3: è²è‘‰æ–¯æ¨æ–·**\n",
    "- LLM ç¶­è­·å¤šå€‹å‡èªª\n",
    "- æ ¹æ“šç¯„ä¾‹æ›´æ–°å‡èªªçš„å¾Œé©—æ©Ÿç‡\n",
    "\n",
    "**æœ€æ–°ç ”ç©¶**:\n",
    "- Transformer å¯ä»¥å¯¦ç¾æ¢¯åº¦ä¸‹é™ (Von Oswald et al., 2023)\n",
    "- In-context learning â‰ˆ éš±å¼åƒæ•¸æ›´æ–°\n",
    "\n",
    "### 5.3 å½±éŸ¿ In-Context Learning çš„å› ç´ \n",
    "\n",
    "**1. ç¯„ä¾‹æ•¸é‡**:\n",
    "- 0-shot < 1-shot < few-shot (é€šå¸¸ 3-5 å€‹æœ€ä½³)\n",
    "- ä½†è¶…éæŸå€‹æ•¸é‡å¾Œé‚Šéš›æ•ˆç›Šéæ¸›\n",
    "\n",
    "**2. ç¯„ä¾‹å“è³ª**:\n",
    "- å¤šæ¨£æ€§ > ç›¸ä¼¼æ€§\n",
    "- ä»£è¡¨æ€§ç¯„ä¾‹ > æ¥µç«¯æ¡ˆä¾‹\n",
    "\n",
    "**3. ç¯„ä¾‹é †åº**:\n",
    "- é‡è¦! é †åºæœƒå½±éŸ¿çµæœ\n",
    "- å»ºè­°: éš¨æ©ŸåŒ–æ¸¬è©¦å¤šç¨®é †åº\n",
    "\n",
    "**4. æ¨¡å‹è¦æ¨¡**:\n",
    "- < 10B: In-context learning èƒ½åŠ›å¼±\n",
    "- > 100B: é¡¯è‘—æå‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "icl-performance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¨¡æ“¬ In-Context Learning æ•ˆèƒ½èˆ‡ç¯„ä¾‹æ•¸é‡çš„é—œä¿‚\n",
    "\n",
    "def icl_performance(num_examples, model_size):\n",
    "    \"\"\"æ¨¡æ“¬ ICL è¡¨ç¾éš¨ç¯„ä¾‹æ•¸å¢é•·\"\"\"\n",
    "    # ä½¿ç”¨å°æ•¸å‡½æ•¸æ¨¡æ“¬é‚Šéš›éæ¸›\n",
    "    base_performance = 30 * (model_size / 100)  # æ¨¡å‹è¦æ¨¡åŸºæº–\n",
    "    improvement = 30 * np.log1p(num_examples) * (model_size / 100)\n",
    "    noise = np.random.normal(0, 2)\n",
    "    return min(95, base_performance + improvement + noise)\n",
    "\n",
    "num_examples_range = range(0, 11)\n",
    "model_sizes = [10, 100, 500]  # 10B, 100B, 500B\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "for size in model_sizes:\n",
    "    performances = [icl_performance(n, size) for n in num_examples_range]\n",
    "    ax.plot(num_examples_range, performances, marker='o', linewidth=2.5, \n",
    "            label=f'{size}B åƒæ•¸', markersize=8)\n",
    "\n",
    "ax.set_xlabel('ç¯„ä¾‹æ•¸é‡ (Few-Shot)', fontsize=13)\n",
    "ax.set_ylabel('ä»»å‹™æº–ç¢ºç‡ (%)', fontsize=13)\n",
    "ax.set_title('In-Context Learning: ç¯„ä¾‹æ•¸é‡ vs è¡¨ç¾', fontsize=15, fontweight='bold')\n",
    "ax.legend(fontsize=12)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xticks(range(0, 11))\n",
    "\n",
    "# æ¨™è¨»é—œéµå€åŸŸ\n",
    "ax.axvspan(-0.5, 0.5, alpha=0.1, color='red', label='Zero-Shot')\n",
    "ax.axvspan(0.5, 1.5, alpha=0.1, color='orange', label='One-Shot')\n",
    "ax.axvspan(1.5, 10.5, alpha=0.1, color='green', label='Few-Shot')\n",
    "\n",
    "ax.text(0, 25, 'Zero-Shot', ha='center', fontsize=10, style='italic')\n",
    "ax.text(1, 25, 'One-Shot', ha='center', fontsize=10, style='italic')\n",
    "ax.text(5, 25, 'Few-Shot', ha='center', fontsize=10, style='italic')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\né—œéµè§€å¯Ÿ:\")\n",
    "print(\"â€¢ å¤§æ¨¡å‹å¾ 0 å€‹ç¯„ä¾‹å°±æœ‰ä¸éŒ¯è¡¨ç¾\")\n",
    "print(\"â€¢ 3-5 å€‹ç¯„ä¾‹é€šå¸¸æ˜¯æœ€ä½³å¹³è¡¡é»\")\n",
    "print(\"â€¢ å°æ¨¡å‹ (<10B) å¹¾ä¹ç„¡ in-context learning èƒ½åŠ›\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-6",
   "metadata": {},
   "source": [
    "## 6. LLM çš„å±€é™æ€§èˆ‡æœªä¾† {#6-limitations}\n",
    "\n",
    "### 6.1 æ ¸å¿ƒå±€é™\n",
    "\n",
    "#### 1. å¹»è¦º (Hallucination)\n",
    "\n",
    "**å®šç¾©**: ç”Ÿæˆè½èµ·ä¾†åˆç†ä½†å¯¦éš›éŒ¯èª¤çš„å…§å®¹\n",
    "\n",
    "**ç¯„ä¾‹**:\n",
    "```\n",
    "Q: \"èª°ç™¼æ˜äº†é›»ç‡ˆæ³¡?\"\n",
    "A: \"æ¹¯ç‘ªæ–¯Â·æ„›è¿ªç”Ÿæ–¼ 1879 å¹´ç™¼æ˜äº†é›»ç‡ˆæ³¡ã€‚\" âœ… æ­£ç¢º\n",
    "\n",
    "Q: \"æ„›è¿ªç”Ÿåœ¨å“ªæ‰€å¤§å­¸ç²å¾—åšå£«å­¸ä½?\"\n",
    "A: \"æ„›è¿ªç”Ÿåœ¨è€¶é­¯å¤§å­¸ç²å¾—ç‰©ç†å­¸åšå£«å­¸ä½ã€‚\" âŒ ç·¨é€  (ä»–æ²’æœ‰å¤§å­¸å­¸ä½)\n",
    "```\n",
    "\n",
    "**åŸå› **:\n",
    "- è¨“ç·´ç›®æ¨™æ˜¯é æ¸¬ä¸‹ä¸€å€‹è©ï¼Œè€Œéä¿è­‰çœŸå¯¦æ€§\n",
    "- çŸ¥è­˜æˆªæ­¢æ—¥æœŸå¾Œçš„è³‡è¨Šç„¡æ³•ç²å¾—\n",
    "- è¨“ç·´æ•¸æ“šå¯èƒ½åŒ…å«éŒ¯èª¤è³‡è¨Š\n",
    "\n",
    "**ç·©è§£æ–¹æ³•**:\n",
    "- æª¢ç´¢å¢å¼·ç”Ÿæˆ (RAG)\n",
    "- å¼•ç”¨ä¾†æº\n",
    "- äººå·¥å¯©æ ¸é—œéµè¼¸å‡º\n",
    "\n",
    "#### 2. ä¸Šä¸‹æ–‡é•·åº¦é™åˆ¶\n",
    "\n",
    "| æ¨¡å‹ | ä¸Šä¸‹æ–‡é•·åº¦ | å¯è™•ç†æ–‡æœ¬é‡ |\n",
    "|------|-----------|-------------|\n",
    "| GPT-3 | 2,048 tokens | ~1,500 è‹±æ–‡å–®å­— |\n",
    "| GPT-3.5 | 4,096 tokens | ~3,000 è‹±æ–‡å–®å­— |\n",
    "| GPT-4 | 8,192 / 32,768 | ~6,000 / 24,000 å–®å­— |\n",
    "| Claude 3 | 200,000 tokens | ~150,000 å–®å­— |\n",
    "| Gemini 1.5 | 1,000,000 tokens | ~750,000 å–®å­— |\n",
    "\n",
    "**æŒ‘æˆ°**:\n",
    "- ç„¡æ³•è™•ç†è¶…é•·æ–‡æª”\n",
    "- è¨ˆç®—è¤‡é›œåº¦ O(nÂ²)\n",
    "\n",
    "#### 3. æ¨ç†èƒ½åŠ›é™åˆ¶\n",
    "\n",
    "**æ“…é•·**:\n",
    "- æ¨¡å¼è­˜åˆ¥\n",
    "- ç°¡å–®æ¨ç†\n",
    "- å¸¸è­˜æ‡‰ç”¨\n",
    "\n",
    "**ä¸æ“…é•·**:\n",
    "- è¤‡é›œæ•¸å­¸è­‰æ˜\n",
    "- å¤šæ­¥é‚è¼¯æ¨ç†\n",
    "- éœ€è¦ç²¾ç¢ºè¨ˆç®—çš„ä»»å‹™\n",
    "\n",
    "**ç¯„ä¾‹ (å¤±æ•—æ¡ˆä¾‹)**:\n",
    "```\n",
    "Q: \"è¨ˆç®— 4,567 Ã— 8,923\"\n",
    "A: \"40,759,241\"  âŒ (æ­£ç¢ºç­”æ¡ˆ: 40,755,241)\n",
    "```\n",
    "\n",
    "#### 4. è¨“ç·´æˆæœ¬èˆ‡ç’°å¢ƒå½±éŸ¿\n",
    "\n",
    "**GPT-3 è¨“ç·´æˆæœ¬ä¼°è¨ˆ**:\n",
    "- é›»åŠ›: ~1,287 MWh\n",
    "- ç¢³æ’æ”¾: ~552 å™¸ COâ‚‚\n",
    "- é‡‘éŒ¢: $4.6M USD\n",
    "\n",
    "#### 5. åè¦‹èˆ‡å®‰å…¨æ€§\n",
    "\n",
    "**å•é¡Œä¾†æº**:\n",
    "- è¨“ç·´æ•¸æ“šåŒ…å«ç¤¾æœƒåè¦‹\n",
    "- å¯èƒ½ç”Ÿæˆæœ‰å®³å…§å®¹\n",
    "- éš±ç§æ´©éœ²é¢¨éšª\n",
    "\n",
    "**æ‡‰å°æªæ–½**:\n",
    "- RLHF å°é½Š\n",
    "- å…§å®¹éæ¿¾\n",
    "- æŒçºŒç›£æ§èˆ‡æ”¹é€²\n",
    "\n",
    "### 6.2 æœªä¾†è¶¨å‹¢\n",
    "\n",
    "**1. å¤šæ¨¡æ…‹ LLM**\n",
    "- GPT-4, Gemini: æ–‡æœ¬ + åœ–åƒ\n",
    "- æœªä¾†: éŸ³è¨Š + è¦–é » + 3D\n",
    "\n",
    "**2. æ•ˆç‡æå‡**\n",
    "- Mixture of Experts (MoE)\n",
    "- é‡åŒ– (Quantization)\n",
    "- ç¨€ç–æ¿€æ´»\n",
    "\n",
    "**3. æ›´é•·ä¸Šä¸‹æ–‡**\n",
    "- çªç ´ 1M tokens\n",
    "- é«˜æ•ˆæ³¨æ„åŠ›æ©Ÿåˆ¶\n",
    "\n",
    "**4. å·¥å…·ä½¿ç”¨ (Tool Use)**\n",
    "- å‘¼å«å¤–éƒ¨ API\n",
    "- åŸ·è¡Œç¨‹å¼ç¢¼\n",
    "- æª¢ç´¢å³æ™‚è³‡è¨Š\n",
    "\n",
    "**5. å¤šæ™ºèƒ½é«”ç³»çµ±**\n",
    "- å¤šå€‹ LLM å”ä½œ\n",
    "- å°ˆç²¾ä¸åŒé ˜åŸŸ\n",
    "- è‡ªæˆ‘ä¿®æ­£èˆ‡è¾¯è«–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-trends-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¦–è¦ºåŒ– LLM ç™¼å±•è¶¨å‹¢\n",
    "\n",
    "trends = {\n",
    "    'è¶¨å‹¢': [\n",
    "        'æ¨¡å‹è¦æ¨¡',\n",
    "        'ä¸Šä¸‹æ–‡é•·åº¦',\n",
    "        'å¤šæ¨¡æ…‹èƒ½åŠ›',\n",
    "        'æ¨ç†èƒ½åŠ›',\n",
    "        'æ•ˆç‡ (æˆæœ¬)',\n",
    "        'å®‰å…¨æ€§å°é½Š'\n",
    "    ],\n",
    "    '2023': [85, 60, 50, 55, 40, 65],\n",
    "    '2024 (é æ¸¬)': [90, 80, 75, 70, 60, 80],\n",
    "    '2025 (é æ¸¬)': [92, 90, 85, 80, 75, 90]\n",
    "}\n",
    "\n",
    "df_trends = pd.DataFrame(trends)\n",
    "df_trends = df_trends.set_index('è¶¨å‹¢')\n",
    "\n",
    "# ç¹ªè£½é›·é”åœ–\n",
    "categories = df_trends.index.tolist()\n",
    "N = len(categories)\n",
    "\n",
    "angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
    "angles += angles[:1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
    "\n",
    "for year in df_trends.columns:\n",
    "    values = df_trends[year].tolist()\n",
    "    values += values[:1]\n",
    "    ax.plot(angles, values, 'o-', linewidth=2, label=year, markersize=8)\n",
    "    ax.fill(angles, values, alpha=0.15)\n",
    "\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(categories, fontsize=11)\n",
    "ax.set_ylim(0, 100)\n",
    "ax.set_yticks([20, 40, 60, 80, 100])\n",
    "ax.set_yticklabels(['20', '40', '60', '80', '100'], fontsize=9)\n",
    "ax.set_title('LLM èƒ½åŠ›ç™¼å±•è¶¨å‹¢ (é›·é”åœ–)', fontsize=15, fontweight='bold', pad=30)\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=11)\n",
    "ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nè¶¨å‹¢è§£è®€:\")\n",
    "print(\"â€¢ ä¸Šä¸‹æ–‡é•·åº¦: å¿«é€Ÿå¢é•· (1M+ tokens æˆç‚ºå¯èƒ½)\")\n",
    "print(\"â€¢ å¤šæ¨¡æ…‹: å¾å–®ç´”æ–‡æœ¬æ“´å±•åˆ°åœ–åƒã€éŸ³è¨Šã€è¦–é »\")\n",
    "print(\"â€¢ æ•ˆç‡: é€é MoE, é‡åŒ–ç­‰æŠ€è¡“å¤§å¹…é™ä½æˆæœ¬\")\n",
    "print(\"â€¢ å®‰å…¨æ€§: æ›´å¼·çš„å°é½Šèˆ‡éæ¿¾æ©Ÿåˆ¶\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-7",
   "metadata": {},
   "source": [
    "## 7. ç¸½çµ {#7-summary}\n",
    "\n",
    "### 7.1 é—œéµè¦é»å›é¡§\n",
    "\n",
    "âœ… **LLM çš„æ ¸å¿ƒ**:\n",
    "- å®šç¾©: > 1B åƒæ•¸çš„ Transformer æ¨¡å‹\n",
    "- æ¶æ§‹: ä¸»è¦ç‚º Decoder-Only\n",
    "- èƒ½åŠ›: Few-shot learning, Chain-of-thought, In-context learning\n",
    "\n",
    "âœ… **è¦æ¨¡å®šå¾‹**:\n",
    "- æ•ˆèƒ½ âˆ åƒæ•¸é‡^(-Î±)\n",
    "- æ¹§ç¾èƒ½åŠ›åœ¨ç‰¹å®šè¦æ¨¡çªç„¶å‡ºç¾\n",
    "- ä½†é‚Šéš›æ•ˆæ‡‰éæ¸›\n",
    "\n",
    "âœ… **è¨“ç·´ä¸‰éšæ®µ**:\n",
    "1. é è¨“ç·´: å­¸ç¿’èªè¨€èˆ‡çŸ¥è­˜\n",
    "2. Instruction Tuning: å­¸æœƒéµå¾ªæŒ‡ä»¤\n",
    "3. RLHF: å°é½Šäººé¡åƒ¹å€¼è§€\n",
    "\n",
    "âœ… **Prompt Engineering**:\n",
    "- æ˜ç¢ºã€å…·é«”ã€çµæ§‹åŒ–\n",
    "- Few-shot > One-shot > Zero-shot\n",
    "- Chain-of-Thought æå‡æ¨ç†\n",
    "- è¿­ä»£å„ªåŒ–æ˜¯é—œéµ\n",
    "\n",
    "âœ… **In-Context Learning**:\n",
    "- ç„¡éœ€æ¢¯åº¦æ›´æ–°çš„å­¸ç¿’\n",
    "- 3-5 å€‹ç¯„ä¾‹æœ€ä½³\n",
    "- éœ€è¦ > 10B åƒæ•¸æ‰æœ‰æ•ˆ\n",
    "\n",
    "âœ… **å±€é™æ€§**:\n",
    "- å¹»è¦º (ç·¨é€ äº‹å¯¦)\n",
    "- ä¸Šä¸‹æ–‡é•·åº¦é™åˆ¶\n",
    "- æ¨ç†èƒ½åŠ›æœ‰é™\n",
    "- è¨“ç·´æˆæœ¬é«˜\n",
    "- åè¦‹èˆ‡å®‰å…¨å•é¡Œ\n",
    "\n",
    "### 7.2 å¯¦ç”¨å»ºè­°\n",
    "\n",
    "**ä½¿ç”¨ LLM çš„æœ€ä½³å¯¦è¸**:\n",
    "\n",
    "1. **é¸æ“‡åˆé©æ¨¡å‹**:\n",
    "   - ç°¡å–®ä»»å‹™: GPT-3.5, Claude Instant\n",
    "   - è¤‡é›œä»»å‹™: GPT-4, Claude 3\n",
    "   - é ç®—æœ‰é™: é–‹æº LLaMA, Mistral\n",
    "\n",
    "2. **è¨­è¨ˆæœ‰æ•ˆ Prompt**:\n",
    "   - å¾ç°¡å–®é–‹å§‹ï¼Œé€æ­¥å„ªåŒ–\n",
    "   - è¨˜éŒ„æœ‰æ•ˆçš„ prompts\n",
    "   - ä½¿ç”¨ prompt æ¨¡æ¿åº«\n",
    "\n",
    "3. **è™•ç†è¼¸å‡º**:\n",
    "   - é©—è­‰é—œéµäº‹å¯¦\n",
    "   - ä½¿ç”¨å¤šæ¬¡ç”Ÿæˆ + æŠ•ç¥¨\n",
    "   - çµåˆæª¢ç´¢ç³»çµ± (RAG)\n",
    "\n",
    "4. **æˆæœ¬æ§åˆ¶**:\n",
    "   - å¿«å–å¸¸ç”¨çµæœ\n",
    "   - ä½¿ç”¨è¼ƒå°æ¨¡å‹è™•ç†ç°¡å–®ä»»å‹™\n",
    "   - å„ªåŒ– prompt é•·åº¦\n",
    "\n",
    "### 7.3 å»¶ä¼¸é–±è®€\n",
    "\n",
    "**è«–æ–‡**:\n",
    "1. [Language Models are Few-Shot Learners (GPT-3)](https://arxiv.org/abs/2005.14165)\n",
    "2. [Training language models to follow instructions (InstructGPT)](https://arxiv.org/abs/2203.02155)\n",
    "3. [Chain-of-Thought Prompting](https://arxiv.org/abs/2201.11903)\n",
    "4. [Scaling Laws for Neural Language Models](https://arxiv.org/abs/2001.08361)\n",
    "\n",
    "**è³‡æº**:\n",
    "- [OpenAI Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering)\n",
    "- [Anthropic Claude Documentation](https://docs.anthropic.com/)\n",
    "- [Awesome LLM (GitHub)](https://github.com/Hannibal046/Awesome-LLM)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ ä¸‹ä¸€ç¯€é å‘Š\n",
    "\n",
    "**CH07-08: LLM å¯¦éš›æ‡‰ç”¨æ¡ˆä¾‹**\n",
    "- RAG (æª¢ç´¢å¢å¼·ç”Ÿæˆ) å¯¦ä½œ\n",
    "- LangChain æ¡†æ¶ä½¿ç”¨\n",
    "- Agent ç³»çµ±è¨­è¨ˆ\n",
    "- ä½¿ç”¨ Hugging Face API å‘¼å«é–‹æº LLM\n",
    "- ç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²è€ƒé‡\n",
    "\n",
    "---\n",
    "\n",
    "**èª²ç¨‹å®Œæˆæ™‚é–“**: `____å¹´____æœˆ____æ—¥`  \n",
    "**å­¸ç¿’å¿ƒå¾—**: ___________________________________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
