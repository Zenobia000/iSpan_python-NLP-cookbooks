{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CH01-02: 必要套件安裝\n",
    "\n",
    "**課程目標:**\n",
    "- 掌握 NLP 核心套件的安裝與配置\n",
    "- 理解不同套件的適用場景\n",
    "- 學會解決套件衝突問題\n",
    "- 了解中英文 NLP 工具的差異\n",
    "\n",
    "**學習時間:** 約 75 分鐘\n",
    "\n",
    "**前置知識:**\n",
    "- Poetry 基礎操作\n",
    "- Python 套件管理概念\n",
    "- 命令列基本操作\n",
    "\n",
    "---\n",
    "\n",
    "## 📚 目錄\n",
    "\n",
    "1. [NLP 套件生態系統概覽](#1)\n",
    "2. [中文 NLP 工具安裝](#2)\n",
    "3. [英文 NLP 工具安裝](#3)\n",
    "4. [深度學習框架選擇](#4)\n",
    "5. [Transformers 生態安裝](#5)\n",
    "6. [套件相容性檢查](#6)\n",
    "7. [模型與數據下載](#7)\n",
    "8. [實戰練習](#8)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 環境設定與套件導入\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from importlib.metadata import version, PackageNotFoundError\n",
    "from pathlib import Path\n",
    "\n",
    "# 設定中文顯示\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'SimHei', 'Arial Unicode MS']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 設定顯示風格\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"✅ 環境設定完成\")\n",
    "print(f\"Python 版本: {sys.version.split()[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1. NLP 套件生態系統概覽\n",
    "\n",
    "### 1.1 NLP 工具分類\n",
    "\n",
    "NLP 套件可從**語言**、**技術典範**、**應用場景**三個維度分類:\n",
    "\n",
    "#### 按語言分類:\n",
    "- **中文專用:** jieba, pkuseg, LTP\n",
    "- **英文專用:** NLTK, TextBlob\n",
    "- **多語言:** spaCy, Stanza\n",
    "\n",
    "#### 按技術典範分類:\n",
    "- **傳統方法 (規則/統計):** NLTK, jieba\n",
    "- **深度學習:** Transformers, fairseq\n",
    "\n",
    "#### 按應用場景分類:\n",
    "- **研究教學:** NLTK\n",
    "- **生產環境:** spaCy, Transformers\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP 套件生態系統視覺化\n",
    "packages_data = {\n",
    "    '套件': ['jieba', 'NLTK', 'spaCy', 'Transformers', 'Stanza', 'Gensim'],\n",
    "    '適用語言': ['中文', '英文', '多語言', '多語言', '60+ 語言', '多語言'],\n",
    "    '主要功能': ['分詞', '分詞/POS/詞幹化', 'Pipeline 處理', '預訓練模型', '分詞/POS/NER', 'Word2Vec/Doc2Vec'],\n",
    "    '技術典範': ['統計 (HMM)', '規則+統計', '神經網路', 'Transformer', '神經網路', '詞向量'],\n",
    "    '學習曲線': ['低', '中', '中', '高', '中', '中'],\n",
    "    '效能': ['快', '中', '快', '慢 (需 GPU)', '中', '中']\n",
    "}\n",
    "\n",
    "df_packages = pd.DataFrame(packages_data)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "\n",
    "table = ax.table(cellText=df_packages.values, colLabels=df_packages.columns,\n",
    "                cellLoc='center', loc='center')\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "table.scale(1, 2.5)\n",
    "\n",
    "# 設定表頭樣式\n",
    "for i in range(len(df_packages.columns)):\n",
    "    table[(0, i)].set_facecolor('#4ECDC4')\n",
    "    table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "\n",
    "# 設定交替行顏色\n",
    "for i in range(1, len(df_packages) + 1):\n",
    "    for j in range(len(df_packages.columns)):\n",
    "        if i % 2 == 0:\n",
    "            table[(i, j)].set_facecolor('#F7F7F7')\n",
    "\n",
    "plt.title('NLP 套件生態系統對比', fontsize=18, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n📊 選擇指南:\")\n",
    "print(\"  - 中文分詞: jieba (快速、輕量)\")\n",
    "print(\"  - 英文教學: NLTK (功能完整)\")\n",
    "print(\"  - 生產環境: spaCy (效能優先)\")\n",
    "print(\"  - SOTA 模型: Transformers (準確率最高)\")\n",
    "print(\"  - 多語言: Stanza (支援 60+ 語言)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 套件安裝策略\n",
    "\n",
    "#### 分層安裝策略 (推薦):\n",
    "\n",
    "```bash\n",
    "# 第 1 層: 基礎工具\n",
    "poetry add numpy pandas scikit-learn matplotlib\n",
    "\n",
    "# 第 2 層: 中文/英文 NLP\n",
    "poetry add jieba nltk spacy\n",
    "\n",
    "# 第 3 層: 深度學習框架 (二選一)\n",
    "poetry add torch  # 或 tensorflow\n",
    "\n",
    "# 第 4 層: 深度學習 NLP\n",
    "poetry add transformers datasets tokenizers\n",
    "```\n",
    "\n",
    "**優點:**\n",
    "- 分層安裝,問題易定位\n",
    "- 避免一次安裝過多套件導致衝突\n",
    "- 便於理解依賴關係\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "## 2. 中文 NLP 工具安裝\n",
    "\n",
    "### 2.1 jieba (結巴分詞)\n",
    "\n",
    "**jieba** 是最流行的 Python 中文分詞工具,基於 HMM (隱馬可夫模型) 與 Viterbi 算法。\n",
    "\n",
    "#### 安裝與配置:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安裝 jieba (在終端執行)\n",
    "install_cmd = \"poetry add jieba\"\n",
    "print(f\"📦 安裝指令: {install_cmd}\\n\")\n",
    "\n",
    "# 檢查是否已安裝\n",
    "try:\n",
    "    import jieba\n",
    "    jieba_version = version('jieba')\n",
    "    print(f\"✅ jieba 已安裝,版本: {jieba_version}\")\n",
    "    \n",
    "    # 基本測試\n",
    "    test_text = \"我愛自然語言處理\"\n",
    "    words = list(jieba.cut(test_text))\n",
    "    print(f\"\\n分詞測試: '{test_text}' → {words}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(f\"❌ jieba 未安裝,請執行: {install_cmd}\")\n",
    "except PackageNotFoundError:\n",
    "    print(f\"⚠️ jieba 已導入但版本資訊不可用\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### jieba 三種分詞模式:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jieba 分詞模式對比\n",
    "try:\n",
    "    import jieba\n",
    "    \n",
    "    test_sentence = \"我來到北京清華大學\"\n",
    "    \n",
    "    modes = [\n",
    "        ('精確模式', list(jieba.cut(test_sentence, cut_all=False))),\n",
    "        ('全模式', list(jieba.cut(test_sentence, cut_all=True))),\n",
    "        ('搜尋引擎模式', list(jieba.cut_for_search(test_sentence)))\n",
    "    ]\n",
    "    \n",
    "    print(f\"測試句子: '{test_sentence}'\\n\")\n",
    "    \n",
    "    for mode_name, result in modes:\n",
    "        print(f\"{mode_name:12s}: {result}\")\n",
    "    \n",
    "    # 視覺化對比\n",
    "    mode_names = [m[0] for m in modes]\n",
    "    token_counts = [len(m[1]) for m in modes]\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    bars = plt.bar(mode_names, token_counts, color=['#4ECDC4', '#FF6B6B', '#FFE66D'])\n",
    "    plt.ylabel('詞數量', fontsize=12)\n",
    "    plt.title('jieba 三種分詞模式對比', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 在柱狀圖上標註數值\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{int(height)}',\n",
    "                ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n💡 模式選擇:\")\n",
    "    print(\"  - 精確模式: 適合文本分析 (預設)\")\n",
    "    print(\"  - 全模式: 窮盡所有可能,詞數最多\")\n",
    "    print(\"  - 搜尋引擎模式: 適合建立索引\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"請先安裝 jieba: poetry add jieba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 自定義詞典\n",
    "\n",
    "jieba 支援自定義詞典,可添加領域專有名詞:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定義詞典示例\n",
    "try:\n",
    "    import jieba\n",
    "    \n",
    "    # 測試文本 (包含專有名詞)\n",
    "    text = \"我在學習 Transformer 模型和 BERT 算法\"\n",
    "    \n",
    "    print(\"測試文本:\", text)\n",
    "    print(\"\\n【未加載自定義詞典】\")\n",
    "    result_before = list(jieba.cut(text))\n",
    "    print(f\"分詞結果: {result_before}\")\n",
    "    \n",
    "    # 添加自定義詞\n",
    "    custom_words = [\n",
    "        ('Transformer', 10, 'n'),  # (詞, 詞頻, 詞性)\n",
    "        ('BERT', 10, 'n'),\n",
    "        ('自然語言處理', 15, 'n')\n",
    "    ]\n",
    "    \n",
    "    for word, freq, pos in custom_words:\n",
    "        jieba.add_word(word, freq, pos)\n",
    "    \n",
    "    print(\"\\n【加載自定義詞典後】\")\n",
    "    result_after = list(jieba.cut(text))\n",
    "    print(f\"分詞結果: {result_after}\")\n",
    "    \n",
    "    # 對比視覺化\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # 未加載詞典\n",
    "    axes[0].bar(range(len(result_before)), [1]*len(result_before), color='#FF6B6B')\n",
    "    axes[0].set_xticks(range(len(result_before)))\n",
    "    axes[0].set_xticklabels(result_before, rotation=45, ha='right')\n",
    "    axes[0].set_title('未加載自定義詞典', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_ylabel('詞位置')\n",
    "    \n",
    "    # 加載詞典後\n",
    "    axes[1].bar(range(len(result_after)), [1]*len(result_after), color='#4ECDC4')\n",
    "    axes[1].set_xticks(range(len(result_after)))\n",
    "    axes[1].set_xticklabels(result_after, rotation=45, ha='right')\n",
    "    axes[1].set_title('加載自定義詞典後', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_ylabel('詞位置')\n",
    "    \n",
    "    plt.suptitle('自定義詞典效果對比', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n💡 自定義詞典格式 (custom_dict.txt):\")\n",
    "    print(\"  Transformer 10 n\")\n",
    "    print(\"  BERT 10 n\")\n",
    "    print(\"  自然語言處理 15 n\")\n",
    "    print(\"\\n載入方式: jieba.load_userdict('custom_dict.txt')\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"請先安裝 jieba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "## 3. 英文 NLP 工具安裝\n",
    "\n",
    "### 3.1 NLTK (Natural Language Toolkit)\n",
    "\n",
    "**NLTK** 是經典的英文 NLP 工具包,適合教學與研究。\n",
    "\n",
    "#### 安裝與數據下載:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安裝 NLTK\n",
    "install_cmd = \"poetry add nltk\"\n",
    "print(f\"📦 安裝指令: {install_cmd}\\n\")\n",
    "\n",
    "# 檢查並測試 NLTK\n",
    "try:\n",
    "    import nltk\n",
    "    nltk_version = version('nltk')\n",
    "    print(f\"✅ NLTK 已安裝,版本: {nltk_version}\")\n",
    "    \n",
    "    # 必要數據包列表\n",
    "    required_data = [\n",
    "        ('punkt', '分詞模型'),\n",
    "        ('stopwords', '停用詞表'),\n",
    "        ('averaged_perceptron_tagger', 'POS 標註器'),\n",
    "        ('wordnet', 'WordNet 詞彙資料庫'),\n",
    "        ('omw-1.4', '多語言 WordNet')\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n📚 必要數據包:\")\n",
    "    for package, description in required_data:\n",
    "        print(f\"  - {package:30s}: {description}\")\n",
    "    \n",
    "    print(\"\\n下載指令:\")\n",
    "    print(\"  nltk.download('punkt')\")\n",
    "    print(\"  nltk.download('stopwords')\")\n",
    "    print(\"  nltk.download('averaged_perceptron_tagger')\")\n",
    "    print(\"  nltk.download('wordnet')\")\n",
    "    print(\"  nltk.download('omw-1.4')\")\n",
    "    print(\"\\n或一次性下載: nltk.download('popular')\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(f\"❌ NLTK 未安裝,請執行: {install_cmd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK 基本功能測試\n",
    "try:\n",
    "    import nltk\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    from nltk.corpus import stopwords\n",
    "    \n",
    "    # 測試文本\n",
    "    text = \"Natural language processing is amazing! It enables computers to understand human language.\"\n",
    "    \n",
    "    print(f\"測試文本: {text}\\n\")\n",
    "    \n",
    "    # 分詞\n",
    "    try:\n",
    "        tokens = word_tokenize(text)\n",
    "        print(f\"✅ 分詞結果: {tokens}\")\n",
    "        print(f\"   詞數: {len(tokens)}\")\n",
    "    except LookupError:\n",
    "        print(\"❌ 分詞失敗,請下載: nltk.download('punkt')\")\n",
    "        tokens = []\n",
    "    \n",
    "    # 停用詞過濾\n",
    "    try:\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        filtered = [w for w in tokens if w.lower() not in stop_words]\n",
    "        print(f\"\\n✅ 過濾停用詞後: {filtered}\")\n",
    "        print(f\"   詞數: {len(filtered)}\")\n",
    "        \n",
    "        # 視覺化對比\n",
    "        data = {\n",
    "            '處理階段': ['原始分詞', '過濾停用詞'],\n",
    "            '詞數': [len(tokens), len(filtered)]\n",
    "        }\n",
    "        \n",
    "        plt.figure(figsize=(10, 5))\n",
    "        bars = plt.bar(data['處理階段'], data['詞數'], color=['#FF6B6B', '#4ECDC4'])\n",
    "        plt.ylabel('詞數量', fontsize=12)\n",
    "        plt.title('NLTK 停用詞過濾效果', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{int(height)}',\n",
    "                    ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except LookupError:\n",
    "        print(\"❌ 停用詞處理失敗,請下載: nltk.download('stopwords')\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"請先安裝 NLTK: poetry add nltk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 spaCy (工業級 NLP)\n",
    "\n",
    "**spaCy** 是面向生產環境的 NLP 工具,效能優於 NLTK。\n",
    "\n",
    "#### 安裝與語言模型下載:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安裝 spaCy\n",
    "install_steps = [\n",
    "    ('1. 安裝 spaCy 套件', 'poetry add spacy'),\n",
    "    ('2. 下載英文小型模型', 'python -m spacy download en_core_web_sm'),\n",
    "    ('3. 下載英文中型模型 (含詞向量)', 'python -m spacy download en_core_web_md'),\n",
    "    ('4. 下載中文模型', 'python -m spacy download zh_core_web_sm'),\n",
    "]\n",
    "\n",
    "print(\"📦 spaCy 安裝步驟:\\n\")\n",
    "for step, cmd in install_steps:\n",
    "    print(f\"{step}\")\n",
    "    print(f\"   {cmd}\\n\")\n",
    "\n",
    "# 檢查 spaCy 安裝狀態\n",
    "try:\n",
    "    import spacy\n",
    "    spacy_version = version('spacy')\n",
    "    print(f\"✅ spaCy 已安裝,版本: {spacy_version}\")\n",
    "    \n",
    "    # 檢查可用模型\n",
    "    print(\"\\n🔍 檢查已安裝的語言模型:\")\n",
    "    models = ['en_core_web_sm', 'en_core_web_md', 'zh_core_web_sm']\n",
    "    \n",
    "    for model in models:\n",
    "        try:\n",
    "            nlp = spacy.load(model)\n",
    "            print(f\"  ✅ {model} - 已安裝\")\n",
    "        except OSError:\n",
    "            print(f\"  ❌ {model} - 未安裝\")\n",
    "            print(f\"     下載: python -m spacy download {model}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"❌ spaCy 未安裝,請執行: poetry add spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spaCy 功能展示\n",
    "try:\n",
    "    import spacy\n",
    "    \n",
    "    # 載入模型\n",
    "    try:\n",
    "        nlp = spacy.load('en_core_web_sm')\n",
    "        \n",
    "        # 處理文本\n",
    "        text = \"Apple is looking at buying U.K. startup for $1 billion\"\n",
    "        doc = nlp(text)\n",
    "        \n",
    "        print(f\"測試文本: {text}\\n\")\n",
    "        \n",
    "        # 實體識別 (NER)\n",
    "        print(\"【命名實體識別 (NER)】\")\n",
    "        for ent in doc.ents:\n",
    "            print(f\"  {ent.text:15s} → {ent.label_:10s} ({spacy.explain(ent.label_)})\")\n",
    "        \n",
    "        # 詞性標註 (POS)\n",
    "        print(\"\\n【詞性標註 (POS)】\")\n",
    "        for token in doc:\n",
    "            print(f\"  {token.text:10s} → {token.pos_:6s} {token.dep_:10s}\")\n",
    "        \n",
    "        # 視覺化 NER 結果\n",
    "        entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "        if entities:\n",
    "            ent_texts, ent_labels = zip(*entities)\n",
    "            \n",
    "            plt.figure(figsize=(12, 5))\n",
    "            colors = {'ORG': '#FF6B6B', 'GPE': '#4ECDC4', 'MONEY': '#FFE66D'}\n",
    "            bar_colors = [colors.get(label, '#95E1D3') for label in ent_labels]\n",
    "            \n",
    "            plt.bar(range(len(ent_texts)), [1]*len(ent_texts), color=bar_colors)\n",
    "            plt.xticks(range(len(ent_texts)), ent_texts, rotation=45, ha='right')\n",
    "            plt.ylabel('實體')\n",
    "            plt.title('spaCy 命名實體識別結果', fontsize=14, fontweight='bold')\n",
    "            \n",
    "            # 圖例\n",
    "            from matplotlib.patches import Patch\n",
    "            legend_elements = [Patch(facecolor=colors[label], label=label) for label in set(ent_labels)]\n",
    "            plt.legend(handles=legend_elements, loc='upper right')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "    except OSError:\n",
    "        print(\"❌ 英文模型未安裝\")\n",
    "        print(\"請執行: python -m spacy download en_core_web_sm\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"請先安裝 spaCy: poetry add spacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "## 4. 深度學習框架選擇\n",
    "\n",
    "### 4.1 PyTorch vs TensorFlow\n",
    "\n",
    "深度學習 NLP 需要選擇底層框架,主流選項為 **PyTorch** 和 **TensorFlow**。\n",
    "\n",
    "#### 對比分析:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch vs TensorFlow 對比\n",
    "comparison = {\n",
    "    '維度': ['學習曲線', '社群支援', 'NLP 生態', '生產部署', '研究友善度', 'GPU 支援', '模型可用性'],\n",
    "    'PyTorch': ['中等', '⭐⭐⭐⭐⭐', 'Transformers 首選', '需額外工具', '⭐⭐⭐⭐⭐', '優秀', 'Hugging Face'],\n",
    "    'TensorFlow': ['較陡', '⭐⭐⭐⭐', 'TF Hub', 'TF Serving 完善', '⭐⭐⭐', '優秀', 'TF Hub']\n",
    "}\n",
    "\n",
    "df_compare = pd.DataFrame(comparison)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "\n",
    "table = ax.table(cellText=df_compare.values, colLabels=df_compare.columns,\n",
    "                cellLoc='center', loc='center',\n",
    "                colWidths=[0.25, 0.35, 0.35])\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "table.scale(1, 2.5)\n",
    "\n",
    "# 設定表頭\n",
    "for i in range(len(df_compare.columns)):\n",
    "    table[(0, i)].set_facecolor('#FF6B6B')\n",
    "    table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "\n",
    "# 高亮 PyTorch 列\n",
    "for i in range(1, len(df_compare) + 1):\n",
    "    table[(i, 1)].set_facecolor('#FFE6E6')\n",
    "\n",
    "plt.title('PyTorch vs TensorFlow 對比', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n🎯 選擇建議:\")\n",
    "print(\"\\nPyTorch - 適合:\")\n",
    "print(\"  ✅ NLP 研究與實驗\")\n",
    "print(\"  ✅ 使用 Hugging Face Transformers\")\n",
    "print(\"  ✅ 需要動態計算圖\")\n",
    "print(\"  ✅ 學術論文復現\")\n",
    "\n",
    "print(\"\\nTensorFlow - 適合:\")\n",
    "print(\"  ✅ 大規模生產部署\")\n",
    "print(\"  ✅ 移動端/嵌入式設備 (TF Lite)\")\n",
    "print(\"  ✅ 企業級應用\")\n",
    "print(\"  ✅ 需要完整部署方案 (TF Serving)\")\n",
    "\n",
    "print(\"\\n💡 本課程推薦: PyTorch\")\n",
    "print(\"   原因: Transformers 生態、社群活躍、學習資源豐富\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 安裝深度學習框架\n",
    "\n",
    "#### PyTorch 安裝:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch 安裝指令\n",
    "pytorch_install = {\n",
    "    '環境': ['CPU 版本', 'GPU 版本 (CUDA 11.8)', 'GPU 版本 (CUDA 12.1)', 'macOS (M1/M2)'],\n",
    "    '安裝指令': [\n",
    "        'poetry add torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu',\n",
    "        'poetry add torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118',\n",
    "        'poetry add torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121',\n",
    "        'poetry add torch torchvision torchaudio'\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"🔥 PyTorch 安裝指令:\\n\")\n",
    "for env, cmd in zip(pytorch_install['環境'], pytorch_install['安裝指令']):\n",
    "    print(f\"{env}:\")\n",
    "    print(f\"  {cmd}\\n\")\n",
    "\n",
    "print(\"⚠️ 注意事項:\")\n",
    "print(\"  1. 先確認 CUDA 版本: nvidia-smi\")\n",
    "print(\"  2. 選擇對應的 PyTorch 版本\")\n",
    "print(\"  3. CPU 版本體積較小,但無法使用 GPU 加速\")\n",
    "\n",
    "# 檢查 PyTorch 安裝\n",
    "try:\n",
    "    import torch\n",
    "    torch_version = version('torch')\n",
    "    print(f\"\\n✅ PyTorch 已安裝,版本: {torch_version}\")\n",
    "    print(f\"   CUDA 可用: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"   CUDA 版本: {torch.version.cuda}\")\n",
    "        print(f\"   GPU 數量: {torch.cuda.device_count()}\")\n",
    "        print(f\"   GPU 名稱: {torch.cuda.get_device_name(0)}\")\n",
    "except ImportError:\n",
    "    print(\"\\n❌ PyTorch 未安裝\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorFlow 安裝 (可選):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow 安裝指令\n",
    "print(\"🔷 TensorFlow 安裝指令:\\n\")\n",
    "print(\"CPU 版本:\")\n",
    "print(\"  poetry add tensorflow\\n\")\n",
    "print(\"GPU 版本:\")\n",
    "print(\"  poetry add tensorflow[and-cuda]\\n\")\n",
    "\n",
    "# 檢查 TensorFlow 安裝\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    tf_version = version('tensorflow')\n",
    "    print(f\"✅ TensorFlow 已安裝,版本: {tf_version}\")\n",
    "    \n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    print(f\"   GPU 數量: {len(gpus)}\")\n",
    "    for gpu in gpus:\n",
    "        print(f\"   - {gpu}\")\n",
    "except ImportError:\n",
    "    print(\"❌ TensorFlow 未安裝 (可選)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "## 5. Transformers 生態安裝\n",
    "\n",
    "### 5.1 Hugging Face Transformers\n",
    "\n",
    "**Transformers** 是目前最流行的預訓練模型庫,支援 BERT、GPT、T5 等數千個模型。\n",
    "\n",
    "#### 核心套件:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformers 生態套件\n",
    "transformers_packages = {\n",
    "    '套件': ['transformers', 'datasets', 'tokenizers', 'accelerate', 'evaluate'],\n",
    "    '功能': [\n",
    "        '預訓練模型庫 (BERT/GPT/T5)',\n",
    "        '數據集載入與處理',\n",
    "        '快速 Tokenizer (Rust 實作)',\n",
    "        '多 GPU/混合精度訓練',\n",
    "        '模型評估指標'\n",
    "    ],\n",
    "    '必要性': ['必須', '推薦', '推薦', '進階', '進階'],\n",
    "    '安裝指令': [\n",
    "        'poetry add transformers',\n",
    "        'poetry add datasets',\n",
    "        'poetry add tokenizers',\n",
    "        'poetry add accelerate',\n",
    "        'poetry add evaluate'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_transformers = pd.DataFrame(transformers_packages)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 5))\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "\n",
    "table = ax.table(cellText=df_transformers.values, colLabels=df_transformers.columns,\n",
    "                cellLoc='left', loc='center')\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "table.scale(1, 2.5)\n",
    "\n",
    "# 設定表頭\n",
    "for i in range(len(df_transformers.columns)):\n",
    "    table[(0, i)].set_facecolor('#4ECDC4')\n",
    "    table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "\n",
    "# 高亮必須套件\n",
    "table[(1, 2)].set_facecolor('#FFEB3B')  # transformers\n",
    "\n",
    "plt.title('Transformers 生態套件', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n📦 安裝順序建議:\")\n",
    "print(\"  1. poetry add transformers\")\n",
    "print(\"  2. poetry add datasets tokenizers\")\n",
    "print(\"  3. poetry add accelerate evaluate (進階功能)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 檢查 Transformers 安裝\n",
    "transformers_check = [\n",
    "    ('transformers', '預訓練模型'),\n",
    "    ('datasets', '數據集'),\n",
    "    ('tokenizers', 'Tokenizer')\n",
    "]\n",
    "\n",
    "print(\"🔍 檢查 Transformers 生態套件安裝狀態:\\n\")\n",
    "\n",
    "for package, desc in transformers_check:\n",
    "    try:\n",
    "        pkg_version = version(package)\n",
    "        print(f\"  ✅ {package:15s} {pkg_version:10s} - {desc}\")\n",
    "    except PackageNotFoundError:\n",
    "        print(f\"  ❌ {package:15s} {'未安裝':10s} - {desc}\")\n",
    "        print(f\"     安裝: poetry add {package}\")\n",
    "\n",
    "# 測試 Transformers\n",
    "try:\n",
    "    from transformers import AutoTokenizer, AutoModel\n",
    "    print(\"\\n✅ Transformers 核心模組可正常導入\")\n",
    "    print(\"\\n💡 使用範例:\")\n",
    "    print(\"  from transformers import AutoTokenizer, AutoModel\")\n",
    "    print(\"  tokenizer = AutoTokenizer.from_pretrained('bert-base-chinese')\")\n",
    "    print(\"  model = AutoModel.from_pretrained('bert-base-chinese')\")\n",
    "except ImportError:\n",
    "    print(\"\\n❌ Transformers 未安裝或導入失敗\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 模型快取設定\n",
    "\n",
    "Transformers 模型檔案通常較大 (數百 MB),需要合理設定快取目錄:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformers 快取設定\n",
    "import os\n",
    "\n",
    "print(\"📁 Transformers 快取目錄設定:\\n\")\n",
    "\n",
    "# 預設快取位置\n",
    "default_cache = os.path.expanduser('~/.cache/huggingface/hub/')\n",
    "print(f\"預設快取位置: {default_cache}\")\n",
    "\n",
    "print(\"\\n自定義快取目錄 (三種方法):\\n\")\n",
    "\n",
    "print(\"方法 1: 環境變數 (全域設定)\")\n",
    "print(\"  export TRANSFORMERS_CACHE=/path/to/cache  # Linux/macOS\")\n",
    "print(\"  set TRANSFORMERS_CACHE=D:\\\\models         # Windows\\n\")\n",
    "\n",
    "print(\"方法 2: Python 代碼設定\")\n",
    "print(\"  import os\")\n",
    "print(\"  os.environ['TRANSFORMERS_CACHE'] = '/path/to/cache'\\n\")\n",
    "\n",
    "print(\"方法 3: 下載時指定\")\n",
    "print(\"  model = AutoModel.from_pretrained('bert-base-chinese',\")\n",
    "print(\"                                     cache_dir='/path/to/cache')\")\n",
    "\n",
    "# 視覺化快取目錄結構\n",
    "cache_structure = \"\"\"\n",
    "~/.cache/huggingface/\n",
    "└── hub/\n",
    "    ├── models--bert-base-chinese/\n",
    "    │   ├── snapshots/\n",
    "    │   │   └── abc123.../\n",
    "    │   │       ├── config.json\n",
    "    │   │       ├── pytorch_model.bin (約 400MB)\n",
    "    │   │       └── tokenizer.json\n",
    "    │   └── refs/\n",
    "    │       └── main → abc123...\n",
    "    └── models--gpt2/\n",
    "        └── ...\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n📂 快取目錄結構:\")\n",
    "print(cache_structure)\n",
    "\n",
    "print(\"\\n💡 快取管理建議:\")\n",
    "print(\"  1. 定期清理不用的模型 (可手動刪除)\")\n",
    "print(\"  2. 團隊共享可設定統一快取目錄\")\n",
    "print(\"  3. CI/CD 環境建議使用快取加速\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a>\n",
    "## 6. 套件相容性檢查\n",
    "\n",
    "### 6.1 常見依賴衝突\n",
    "\n",
    "深度學習 NLP 專案常見的套件衝突問題:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 常見依賴衝突案例\n",
    "conflicts = {\n",
    "    '衝突類型': [\n",
    "        'NumPy 版本衝突',\n",
    "        'Protobuf 版本衝突',\n",
    "        'PyTorch vs TensorFlow',\n",
    "        'Tokenizers 版本不匹配'\n",
    "    ],\n",
    "    '症狀': [\n",
    "        'ImportError: numpy.core.multiarray failed',\n",
    "        'TypeError: Descriptors cannot not be created directly',\n",
    "        '記憶體衝突,無法同時載入',\n",
    "        'AttributeError: module has no attribute'\n",
    "    ],\n",
    "    '解決方案': [\n",
    "        'poetry add \"numpy>=1.24,<2.0\"',\n",
    "        'poetry add \"protobuf>=3.20,<4.0\"',\n",
    "        '選擇一個框架,避免同時安裝',\n",
    "        'poetry update tokenizers transformers'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_conflicts = pd.DataFrame(conflicts)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 5))\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "\n",
    "table = ax.table(cellText=df_conflicts.values, colLabels=df_conflicts.columns,\n",
    "                cellLoc='left', loc='center')\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(9)\n",
    "table.scale(1, 3)\n",
    "\n",
    "# 設定表頭\n",
    "for i in range(len(df_conflicts.columns)):\n",
    "    table[(0, i)].set_facecolor('#FF6B6B')\n",
    "    table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "\n",
    "plt.title('常見依賴衝突與解決方案', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n🔧 預防衝突的最佳實踐:\")\n",
    "print(\"  1. 使用 Poetry 管理依賴 - 自動解決衝突\")\n",
    "print(\"  2. 定期更新 poetry.lock - poetry update\")\n",
    "print(\"  3. 檢查依賴樹 - poetry show --tree\")\n",
    "print(\"  4. 鎖定核心套件版本範圍 - 使用 ^ 或 ~ 約束\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 環境驗證腳本\n",
    "\n",
    "創建自動化腳本檢查所有套件:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 完整環境驗證腳本\n",
    "def check_nlp_environment():\n",
    "    \"\"\"檢查 NLP 開發環境所有套件\"\"\"\n",
    "    \n",
    "    packages = [\n",
    "        # 基礎工具\n",
    "        ('numpy', '1.24.0'),\n",
    "        ('pandas', '2.0.0'),\n",
    "        ('scikit-learn', '1.3.0'),\n",
    "        # 中文 NLP\n",
    "        ('jieba', None),\n",
    "        # 英文 NLP\n",
    "        ('nltk', '3.8.0'),\n",
    "        ('spacy', '3.7.0'),\n",
    "        # 深度學習\n",
    "        ('torch', '2.0.0'),\n",
    "        ('transformers', '4.30.0'),\n",
    "        ('datasets', None),\n",
    "        ('tokenizers', None),\n",
    "    ]\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"  NLP 環境套件檢查報告\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for package, min_version in packages:\n",
    "        try:\n",
    "            pkg_version = version(package)\n",
    "            status = \"✅\"\n",
    "            \n",
    "            if min_version and pkg_version < min_version:\n",
    "                status = \"⚠️\"\n",
    "                note = f\"建議 >= {min_version}\"\n",
    "            else:\n",
    "                note = \"OK\"\n",
    "            \n",
    "            results.append({\n",
    "                '套件': package,\n",
    "                '版本': pkg_version,\n",
    "                '狀態': status,\n",
    "                '備註': note\n",
    "            })\n",
    "            \n",
    "        except PackageNotFoundError:\n",
    "            results.append({\n",
    "                '套件': package,\n",
    "                '版本': '未安裝',\n",
    "                '狀態': '❌',\n",
    "                '備註': f'執行: poetry add {package}'\n",
    "            })\n",
    "    \n",
    "    # 輸出結果\n",
    "    for r in results:\n",
    "        print(f\"  {r['狀態']} {r['套件']:20s} {r['版本']:15s} {r['備註']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    \n",
    "    # 統計\n",
    "    installed = sum(1 for r in results if r['狀態'] == '✅')\n",
    "    total = len(results)\n",
    "    \n",
    "    print(f\"  套件安裝狀態: {installed}/{total} 已安裝\")\n",
    "    \n",
    "    if installed == total:\n",
    "        print(\"\\n  ✅ 環境檢查通過,可以開始 NLP 開發!\")\n",
    "    else:\n",
    "        print(\"\\n  ⚠️ 部分套件缺失或版本過低,請根據上方提示安裝\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 執行檢查\n",
    "results = check_nlp_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a>\n",
    "## 7. 模型與數據下載\n",
    "\n",
    "### 7.1 NLTK 數據下載\n",
    "\n",
    "NLTK 需要額外下載語料庫與模型:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK 數據下載腳本\n",
    "def download_nltk_data():\n",
    "    \"\"\"批次下載 NLTK 必要數據\"\"\"\n",
    "    try:\n",
    "        import nltk\n",
    "        \n",
    "        data_packages = [\n",
    "            'punkt',\n",
    "            'stopwords',\n",
    "            'averaged_perceptron_tagger',\n",
    "            'wordnet',\n",
    "            'omw-1.4'\n",
    "        ]\n",
    "        \n",
    "        print(\"📥 開始下載 NLTK 數據包...\\n\")\n",
    "        \n",
    "        for package in data_packages:\n",
    "            try:\n",
    "                # 檢查是否已下載\n",
    "                nltk.data.find(f'tokenizers/{package}' if package == 'punkt' else f'corpora/{package}')\n",
    "                print(f\"  ✅ {package:30s} - 已存在\")\n",
    "            except LookupError:\n",
    "                print(f\"  ⬇️  {package:30s} - 下載中...\")\n",
    "                nltk.download(package, quiet=True)\n",
    "                print(f\"  ✅ {package:30s} - 下載完成\")\n",
    "        \n",
    "        print(\"\\n✅ NLTK 數據包下載完成!\")\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"❌ NLTK 未安裝,請先執行: poetry add nltk\")\n",
    "\n",
    "# 執行下載 (取消註解以執行)\n",
    "# download_nltk_data()\n",
    "\n",
    "print(\"💡 使用說明:\")\n",
    "print(\"  - 取消上方註解執行自動下載\")\n",
    "print(\"  - 或手動執行: nltk.download('popular')\")\n",
    "print(\"  - 或使用 GUI: nltk.download()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 spaCy 語言模型\n",
    "\n",
    "spaCy 模型大小與功能對比:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spaCy 模型對比\n",
    "spacy_models = {\n",
    "    '模型': [\n",
    "        'en_core_web_sm',\n",
    "        'en_core_web_md',\n",
    "        'en_core_web_lg',\n",
    "        'zh_core_web_sm',\n",
    "        'zh_core_web_md'\n",
    "    ],\n",
    "    '語言': ['英文', '英文', '英文', '中文', '中文'],\n",
    "    '大小': ['12 MB', '40 MB', '560 MB', '40 MB', '80 MB'],\n",
    "    '詞向量': ['❌', '✅ (300 維)', '✅ (300 維)', '❌', '✅'],\n",
    "    '功能': [\n",
    "        'POS, NER, Parser',\n",
    "        'POS, NER, Parser, Vectors',\n",
    "        'POS, NER, Parser, Vectors',\n",
    "        'POS, NER, Parser',\n",
    "        'POS, NER, Parser, Vectors'\n",
    "    ],\n",
    "    '推薦場景': [\n",
    "        '快速開發/測試',\n",
    "        '一般應用',\n",
    "        '高準確率需求',\n",
    "        '中文基本處理',\n",
    "        '中文語義分析'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_spacy = pd.DataFrame(spacy_models)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "\n",
    "table = ax.table(cellText=df_spacy.values, colLabels=df_spacy.columns,\n",
    "                cellLoc='center', loc='center')\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "table.scale(1, 2.5)\n",
    "\n",
    "# 設定表頭\n",
    "for i in range(len(df_spacy.columns)):\n",
    "    table[(0, i)].set_facecolor('#4ECDC4')\n",
    "    table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "\n",
    "# 高亮推薦模型\n",
    "table[(2, 0)].set_facecolor('#FFEB3B')  # en_core_web_md\n",
    "table[(4, 0)].set_facecolor('#FFEB3B')  # zh_core_web_sm\n",
    "\n",
    "plt.title('spaCy 語言模型對比', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n📥 下載指令:\")\n",
    "print(\"  python -m spacy download en_core_web_md  # 推薦 (英文)\")\n",
    "print(\"  python -m spacy download zh_core_web_sm  # 推薦 (中文)\")\n",
    "\n",
    "print(\"\\n💡 選擇建議:\")\n",
    "print(\"  - 開發測試: 使用 sm (小型) 模型\")\n",
    "print(\"  - 生產環境: 使用 md (中型) 模型 (含詞向量)\")\n",
    "print(\"  - 高準確率: 使用 lg (大型) 模型 (需更多記憶體)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"8\"></a>\n",
    "## 8. 實戰練習\n",
    "\n",
    "### 練習 1: 完整環境搭建\n",
    "\n",
    "根據以下步驟,從零搭建完整 NLP 環境:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 練習 1: 完整環境搭建步驟\n",
    "exercise1 = \"\"\"\n",
    "📝 練習 1: 從零搭建 NLP 環境\n",
    "\n",
    "步驟 1: 創建專案\n",
    "  poetry new nlp-complete-env\n",
    "  cd nlp-complete-env\n",
    "  poetry config virtualenvs.in-project true\n",
    "\n",
    "步驟 2: 安裝基礎工具\n",
    "  poetry add numpy pandas scikit-learn matplotlib seaborn\n",
    "\n",
    "步驟 3: 安裝中文 NLP\n",
    "  poetry add jieba\n",
    "\n",
    "步驟 4: 安裝英文 NLP\n",
    "  poetry add nltk spacy\n",
    "  python -m spacy download en_core_web_md\n",
    "\n",
    "步驟 5: 安裝深度學習框架\n",
    "  poetry add torch torchvision torchaudio\n",
    "\n",
    "步驟 6: 安裝 Transformers 生態\n",
    "  poetry add transformers datasets tokenizers\n",
    "\n",
    "步驟 7: 下載 NLTK 數據\n",
    "  python -c \"import nltk; nltk.download('popular')\"\n",
    "\n",
    "步驟 8: 環境驗證\n",
    "  poetry run python -c \"import jieba, nltk, spacy, torch, transformers; print('✅ All OK')\"\n",
    "\n",
    "步驟 9: 檢查依賴樹\n",
    "  poetry show --tree\n",
    "\n",
    "步驟 10: 提交配置\n",
    "  git init\n",
    "  git add pyproject.toml poetry.lock\n",
    "  git commit -m \"feat: initial NLP environment setup\"\n",
    "\"\"\"\n",
    "\n",
    "print(exercise1)\n",
    "\n",
    "print(\"\\n🎯 預期結果:\")\n",
    "print(\"  - 所有套件正確安裝\")\n",
    "print(\"  - 依賴無衝突\")\n",
    "print(\"  - 語言模型已下載\")\n",
    "print(\"  - 可正常導入所有套件\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 練習 2: 套件功能測試\n",
    "\n",
    "測試所有已安裝套件的核心功能:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 練習 2: 綜合功能測試\n",
    "def test_all_packages():\n",
    "    \"\"\"測試所有 NLP 套件核心功能\"\"\"\n",
    "    \n",
    "    print(\"🧪 NLP 套件功能測試\\n\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # 測試 1: jieba\n",
    "    try:\n",
    "        import jieba\n",
    "        result = list(jieba.cut(\"我愛自然語言處理\"))\n",
    "        print(f\"✅ jieba 分詞: {result}\")\n",
    "    except:\n",
    "        print(\"❌ jieba 測試失敗\")\n",
    "    \n",
    "    # 測試 2: NLTK\n",
    "    try:\n",
    "        from nltk.tokenize import word_tokenize\n",
    "        result = word_tokenize(\"NLP is awesome\")\n",
    "        print(f\"✅ NLTK 分詞: {result}\")\n",
    "    except:\n",
    "        print(\"❌ NLTK 測試失敗 (可能缺少數據包)\")\n",
    "    \n",
    "    # 測試 3: spaCy\n",
    "    try:\n",
    "        import spacy\n",
    "        nlp = spacy.load('en_core_web_sm')\n",
    "        doc = nlp(\"Apple is a company\")\n",
    "        entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "        print(f\"✅ spaCy NER: {entities}\")\n",
    "    except:\n",
    "        print(\"❌ spaCy 測試失敗 (可能缺少模型)\")\n",
    "    \n",
    "    # 測試 4: PyTorch\n",
    "    try:\n",
    "        import torch\n",
    "        x = torch.tensor([1, 2, 3])\n",
    "        print(f\"✅ PyTorch: {x}, CUDA={torch.cuda.is_available()}\")\n",
    "    except:\n",
    "        print(\"❌ PyTorch 測試失敗\")\n",
    "    \n",
    "    # 測試 5: Transformers\n",
    "    try:\n",
    "        from transformers import AutoTokenizer\n",
    "        print(f\"✅ Transformers: 模組載入成功\")\n",
    "    except:\n",
    "        print(\"❌ Transformers 測試失敗\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"\\n測試完成!\")\n",
    "\n",
    "# 執行測試 (取消註解)\n",
    "# test_all_packages()\n",
    "\n",
    "print(\"💡 取消上方註解執行完整測試\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📚 本課總結\n",
    "\n",
    "### 核心要點回顧:\n",
    "\n",
    "1. **NLP 套件分類:**\n",
    "   - 中文專用: jieba (輕量、快速)\n",
    "   - 英文工具: NLTK (教學)、spaCy (生產)\n",
    "   - 深度學習: Transformers (SOTA 模型)\n",
    "\n",
    "2. **安裝策略:**\n",
    "   - 分層安裝 (基礎 → NLP → 深度學習)\n",
    "   - 使用 Poetry 管理依賴\n",
    "   - 定期檢查相容性\n",
    "\n",
    "3. **深度學習框架:**\n",
    "   - PyTorch: NLP 研究首選,Transformers 生態\n",
    "   - TensorFlow: 生產部署完善\n",
    "\n",
    "4. **模型管理:**\n",
    "   - NLTK: 需下載數據包 (punkt, stopwords 等)\n",
    "   - spaCy: 需下載語言模型 (en_core_web_md 等)\n",
    "   - Transformers: 自動快取模型 (~/.cache/huggingface)\n",
    "\n",
    "5. **相容性檢查:**\n",
    "   - 使用環境驗證腳本\n",
    "   - 定期執行 poetry update\n",
    "   - 檢查依賴樹 (poetry show --tree)\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 下節預告\n",
    "\n",
    "**CH01-03: 開發環境測試**\n",
    "\n",
    "我們將深入探討:\n",
    "- 完整環境檢測腳本\n",
    "- GPU 環境測試 (CUDA, cuDNN)\n",
    "- 模型載入驗證\n",
    "- 效能基準測試\n",
    "- 常見問題診斷與排除\n",
    "\n",
    "---\n",
    "\n",
    "## 📖 延伸閱讀\n",
    "\n",
    "1. **官方文檔:**\n",
    "   - [jieba GitHub](https://github.com/fxsjy/jieba)\n",
    "   - [NLTK 官方文檔](https://www.nltk.org/)\n",
    "   - [spaCy 官方文檔](https://spacy.io/)\n",
    "   - [Transformers 官方文檔](https://huggingface.co/docs/transformers/)\n",
    "\n",
    "2. **模型資源:**\n",
    "   - [Hugging Face Hub](https://huggingface.co/models)\n",
    "   - [spaCy 模型列表](https://spacy.io/models)\n",
    "   - [NLTK 數據下載](https://www.nltk.org/data.html)\n",
    "\n",
    "3. **進階主題:**\n",
    "   - [中文分詞算法詳解](https://github.com/hankcs/HanLP)\n",
    "   - [spaCy 進階教程](https://course.spacy.io/)\n",
    "   - [Transformers 課程](https://huggingface.co/course/)\n",
    "\n",
    "---\n",
    "\n",
    "### 🙋 問題討論\n",
    "\n",
    "有任何問題嗎?歡迎在討論區提問!\n",
    "\n",
    "---\n",
    "\n",
    "**課程資訊:**\n",
    "- **作者:** iSpan NLP Team\n",
    "- **版本:** v1.0\n",
    "- **最後更新:** 2025-10-17\n",
    "- **授權:** MIT License (僅供教學使用)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
