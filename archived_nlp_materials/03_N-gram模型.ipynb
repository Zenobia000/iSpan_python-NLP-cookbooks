{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4db1f3e7",
   "metadata": {},
   "source": [
    "# 簡單用法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00a5ad1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', '自然']\n",
      "['自然', '語言']\n",
      "['語言', '處理']\n",
      "['處理', '（']\n",
      "['（', 'NLP']\n",
      "['NLP', '）']\n",
      "['）', '是']\n",
      "['是', '一個']\n",
      "['一個', '令人']\n",
      "['令人', '興奮']\n",
      "['興奮', '的']\n",
      "['的', '領域']\n",
      "['領域', '，']\n",
      "['，', '它']\n",
      "['它', '專注']\n",
      "['專注', '於']\n",
      "['於', '使']\n",
      "['使', '計算機']\n",
      "['計算機', '能夠']\n",
      "['能夠', '理解']\n",
      "['理解', '和']\n",
      "['和', '生成']\n",
      "['生成', '人類']\n",
      "['人類', '語言']\n",
      "['語言', '。']\n",
      "['。', '\\n']\n",
      "['\\n', 'NLP']\n",
      "['NLP', '的']\n",
      "['的', '應用']\n",
      "['應用', '範圍']\n",
      "['範圍', '廣泛']\n",
      "['廣泛', '，']\n",
      "['，', '包括']\n",
      "['包括', '機器']\n",
      "['機器', '翻譯']\n",
      "['翻譯', '、']\n",
      "['、', '情感']\n",
      "['情感', '分析']\n",
      "['分析', '、']\n",
      "['、', '語音識別']\n",
      "['語音識別', '和']\n",
      "['和', '文本']\n",
      "['文本', '生成']\n",
      "['生成', '。']\n",
      "['。', '\\n']\n",
      "['\\n', 'Bi']\n",
      "['Bi', '-']\n",
      "['-', 'gram']\n",
      "['gram', '模型']\n",
      "['模型', '是']\n",
      "['是', 'NLP']\n",
      "['NLP', '中']\n",
      "['中', '的']\n",
      "['的', '一個']\n",
      "['一個', '基本概念']\n",
      "['基本概念', '，']\n",
      "['，', '它']\n",
      "['它', '處理']\n",
      "['處理', '相鄰']\n",
      "['相鄰', '的']\n",
      "['的', '單詞']\n",
      "['單詞', '對']\n",
      "['對', '，']\n",
      "['，', '有助']\n",
      "['有助', '於']\n",
      "['於', '理解']\n",
      "['理解', '語']\n",
      "['語', '言中']\n",
      "['言中', '的']\n",
      "['的', '上下文']\n",
      "['上下文', '關']\n",
      "['關', '係']\n",
      "['係', '。']\n",
      "['。', '\\n']\n",
      "['\\n', '通過']\n",
      "['通過', '使用']\n",
      "['使用', 'Python']\n",
      "['Python', '，']\n",
      "['，', '我們']\n",
      "['我們', '可以']\n",
      "['可以', '輕松']\n",
      "['輕松', '實現']\n",
      "['實現', '一個']\n",
      "['一個', '簡單']\n",
      "['簡單', '的']\n",
      "['的', 'bi']\n",
      "['bi', '-']\n",
      "['-', 'gram']\n",
      "['gram', '模型']\n",
      "['模型', '來']\n",
      "['來', '分析']\n",
      "['分析', '文本']\n",
      "['文本', '。']\n",
      "['。', '\\n']\n",
      "['\\n', '該']\n",
      "['該', '模型']\n",
      "['模型', '將']\n",
      "['將', '文本']\n",
      "['文本', '分解成']\n",
      "['分解成', '一系列']\n",
      "['一系列', '相鄰']\n",
      "['相鄰', '的']\n",
      "['的', '詞']\n",
      "['詞', '對']\n",
      "['對', '，']\n",
      "['，', '並計算']\n",
      "['並計算', '它們']\n",
      "['它們', '在']\n",
      "['在', '文本']\n",
      "['文本', '中']\n",
      "['中', '的']\n",
      "['的', '出現']\n",
      "['出現', '頻率']\n",
      "['頻率', '。']\n",
      "['。', '\\n']\n",
      "['\\n', '這種']\n",
      "['這種', '分析']\n",
      "['分析', '有助']\n",
      "['有助', '於']\n",
      "['於', '我們']\n",
      "['我們', '瞭解']\n",
      "['瞭解', '文本']\n",
      "['文本', '中']\n",
      "['中', '的']\n",
      "['的', '詞']\n",
      "['詞', '彙']\n",
      "['彙', '關聯性']\n",
      "['關聯性', '，']\n",
      "['，', '並']\n",
      "['並', '可以']\n",
      "['可以', '用']\n",
      "['用', '於']\n",
      "['於', '許多']\n",
      "['許多', 'NLP']\n",
      "['NLP', '任務中']\n",
      "['任務中', '，']\n",
      "['，', '如語']\n",
      "['如語', '言']\n",
      "['言', '模型']\n",
      "['模型', '和']\n",
      "['和', '文本']\n",
      "['文本', '生成']\n",
      "['生成', '。']\n",
      "['。', '\\n']\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "\n",
    "def generate_ngrams(words, n):\n",
    "    # 建立空的 n-grams 列表\n",
    "    ngrams = []\n",
    "\n",
    "    # 迭代詞彙列表中的每個詞\n",
    "    for i in range(len(words) - n + 1):\n",
    "        # 新增下一個 n-gram\n",
    "        ngrams.append(words[i:i+n])\n",
    "\n",
    "    return ngrams\n",
    "\n",
    "# 範例輸入\n",
    "text = \"\"\"\n",
    "自然語言處理（NLP）是一個令人興奮的領域，它專注於使計算機能夠理解和生成人類語言。\n",
    "NLP的應用範圍廣泛，包括機器翻譯、情感分析、語音識別和文本生成。\n",
    "Bi-gram模型是NLP中的一個基本概念，它處理相鄰的單詞對，有助於理解語言中的上下文關係。\n",
    "通過使用Python，我們可以輕松實現一個簡單的bi-gram模型來分析文本。\n",
    "該模型將文本分解成一系列相鄰的詞對，並計算它們在文本中的出現頻率。\n",
    "這種分析有助於我們瞭解文本中的詞彙關聯性，並可以用於許多NLP任務中，如語言模型和文本生成。\n",
    "\"\"\"\n",
    "\n",
    "# 使用 jieba 進行斷詞\n",
    "words = jieba.lcut(text)\n",
    "\n",
    "# 產生 bi-grams\n",
    "bigrams = generate_ngrams(words, 2)\n",
    "\n",
    "# 輸出結果\n",
    "for bigram in bigrams:\n",
    "    print(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a98c0fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " '自然',\n",
       " '語言',\n",
       " '處理',\n",
       " '（',\n",
       " 'NLP',\n",
       " '）',\n",
       " '是',\n",
       " '一個',\n",
       " '令人',\n",
       " '興奮',\n",
       " '的',\n",
       " '領域',\n",
       " '，',\n",
       " '它',\n",
       " '專注',\n",
       " '於',\n",
       " '使',\n",
       " '計算機',\n",
       " '能夠',\n",
       " '理解',\n",
       " '和',\n",
       " '生成',\n",
       " '人類',\n",
       " '語言',\n",
       " '。',\n",
       " '\\n',\n",
       " 'NLP',\n",
       " '的',\n",
       " '應用',\n",
       " '範圍',\n",
       " '廣泛',\n",
       " '，',\n",
       " '包括',\n",
       " '機器',\n",
       " '翻譯',\n",
       " '、',\n",
       " '情感',\n",
       " '分析',\n",
       " '、',\n",
       " '語音識別',\n",
       " '和',\n",
       " '文本',\n",
       " '生成',\n",
       " '。',\n",
       " '\\n',\n",
       " 'Bi',\n",
       " '-',\n",
       " 'gram',\n",
       " '模型',\n",
       " '是',\n",
       " 'NLP',\n",
       " '中',\n",
       " '的',\n",
       " '一個',\n",
       " '基本概念',\n",
       " '，',\n",
       " '它',\n",
       " '處理',\n",
       " '相鄰',\n",
       " '的',\n",
       " '單詞',\n",
       " '對',\n",
       " '，',\n",
       " '有助',\n",
       " '於',\n",
       " '理解',\n",
       " '語',\n",
       " '言中',\n",
       " '的',\n",
       " '上下文',\n",
       " '關',\n",
       " '係',\n",
       " '。',\n",
       " '\\n',\n",
       " '通過',\n",
       " '使用',\n",
       " 'Python',\n",
       " '，',\n",
       " '我們',\n",
       " '可以',\n",
       " '輕松',\n",
       " '實現',\n",
       " '一個',\n",
       " '簡單',\n",
       " '的',\n",
       " 'bi',\n",
       " '-',\n",
       " 'gram',\n",
       " '模型',\n",
       " '來',\n",
       " '分析',\n",
       " '文本',\n",
       " '。',\n",
       " '\\n',\n",
       " '該',\n",
       " '模型',\n",
       " '將',\n",
       " '文本',\n",
       " '分解成',\n",
       " '一系列',\n",
       " '相鄰',\n",
       " '的',\n",
       " '詞',\n",
       " '對',\n",
       " '，',\n",
       " '並計算',\n",
       " '它們',\n",
       " '在',\n",
       " '文本',\n",
       " '中',\n",
       " '的',\n",
       " '出現',\n",
       " '頻率',\n",
       " '。',\n",
       " '\\n',\n",
       " '這種',\n",
       " '分析',\n",
       " '有助',\n",
       " '於',\n",
       " '我們',\n",
       " '瞭解',\n",
       " '文本',\n",
       " '中',\n",
       " '的',\n",
       " '詞',\n",
       " '彙',\n",
       " '關聯性',\n",
       " '，',\n",
       " '並',\n",
       " '可以',\n",
       " '用',\n",
       " '於',\n",
       " '許多',\n",
       " 'NLP',\n",
       " '任務中',\n",
       " '，',\n",
       " '如語',\n",
       " '言',\n",
       " '模型',\n",
       " '和',\n",
       " '文本',\n",
       " '生成',\n",
       " '。',\n",
       " '\\n']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd6613bb",
   "metadata": {},
   "source": [
    "# 計算下一個字出現的機率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57b7b5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('蘋果', 0.5), ('橘子', 0.5)]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "# 假設我們已經有了一個已斷詞的文本列表\n",
    "tokens = ['我', '愛', '吃', '蘋果', '，', '我', '也', '愛', '吃', '橘子']\n",
    "\n",
    "# 建立一個預設為空列表的詞典\n",
    "ngram_dict = defaultdict(Counter)\n",
    "\n",
    "# 指定我們要使用的 N-gram 的 N 值\n",
    "N = 2\n",
    "\n",
    "# 遍歷所有的詞彙\n",
    "for i in range(len(tokens)-N):\n",
    "    # 得到 N-gram 和它的下一個詞彙\n",
    "    ngram = tuple(tokens[i:i + N])\n",
    "    next_token = tokens[i + N]\n",
    "    # 更新詞典\n",
    "    ngram_dict[ngram][next_token] += 1\n",
    "\n",
    "# 轉換次數為機率\n",
    "for ngram, next_tokens in ngram_dict.items():\n",
    "    total_count = sum(next_tokens.values())\n",
    "    for next_token, count in next_tokens.items():\n",
    "        ngram_dict[ngram][next_token] = count / total_count\n",
    "\n",
    "# 假設我們要預測 \"我愛\" 的下一個詞彙\n",
    "ngram = ('愛', '吃')\n",
    "\n",
    "# 從詞典中取得所有可能的下一個詞彙和它們的機率\n",
    "next_tokens_probs = ngram_dict[ngram]\n",
    "\n",
    "# 將它們按照機率排序，取前 k 個\n",
    "k = 2\n",
    "top_k_next_tokens = sorted(next_tokens_probs.items(), key=lambda x: x[1], reverse=True)[:k]\n",
    "\n",
    "print(top_k_next_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2b80947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('珍惜', 0.2857142857142857), ('認識', 0.14285714285714285), ('改變', 0.14285714285714285), ('關心', 0.14285714285714285), ('減少', 0.14285714285714285), ('教育', 0.14285714285714285)]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import re\n",
    "\n",
    "# 定義文章\n",
    "article = '''\n",
    "大自然是我們生活中不可或缺的一部分。\n",
    "我們應該珍惜自然的美麗，並保護我們的環境，以確保我們的子孫後代也能享受到它的恩惠。自然賜予我們空氣、水和食物，這些是我們生存所必需的。\n",
    "然而，我們應該認識到，我們的活動對自然造成了傷害。過度的工業化和城市化導致了大量的森林砍伐和生態破壞。\n",
    "我們應該改變這種情況，採取可持續的做法，以保護我們的生態系統。\n",
    "我們應該關心氣候變化，因為它對我們的星球產生了嚴重的影響。\n",
    "溫室氣體排放正在加速全球變暖，這對我們的環境和社會造成了極大的威脅。我們應該減少碳排放，轉向可再生能源，以減緩氣候變化的影響。\n",
    "最重要的是，我們應該教育我們的下一代，讓他們了解自然的價值，並鼓勵他們參與保護我們的環境。\n",
    "只有這樣，我們才能確保自然的美麗和資源將在未來得以保存，讓我們和我們的子孫後代都能夠享受它們。自然是我們的寶藏，我們應該珍惜和保護它。\n",
    "\n",
    "'''\n",
    "\n",
    "# 使用正則表達式刪除標點符號和空格，然後拆分成詞語列表\n",
    "# cleaned_text = re.sub(r'[^\\w\\s]', '', article)\n",
    "tokens = jieba.lcut(article)\n",
    "\n",
    "# 建立一個預設為空Counter的詞典\n",
    "ngram_dict = defaultdict(Counter)\n",
    "\n",
    "# 指定我們要使用的 N-gram 的 N 值\n",
    "N = 2\n",
    "\n",
    "# 遍歷所有的詞彙\n",
    "for i in range(len(tokens) - N):\n",
    "    # 得到 N-gram 和它的下一個詞彙\n",
    "    ngram = tuple(tokens[i:i + N])\n",
    "    next_token = tokens[i + N]\n",
    "    # 更新詞典\n",
    "    ngram_dict[ngram][next_token] += 1\n",
    "\n",
    "# 轉換次數為機率\n",
    "for ngram, next_tokens in ngram_dict.items():\n",
    "    total_count = sum(next_tokens.values())\n",
    "    for next_token, count in next_tokens.items():\n",
    "        ngram_dict[ngram][next_token] = count / total_count\n",
    "\n",
    "# 假設我們要預測 \"Bi-gram\" 的下一個詞彙\n",
    "ngram = ('我們', '應該')\n",
    "\n",
    "# 從詞典中取得所有可能的下一個詞彙和它們的機率\n",
    "next_tokens_probs = ngram_dict[ngram]\n",
    "\n",
    "# 將它們按照機率排序，取前 k 個\n",
    "k = 5\n",
    "top_k_next_tokens = sorted(next_tokens_probs.items(), key=lambda x: x[1], reverse=True)[:k]\n",
    "\n",
    "print(top_k_next_tokens)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
