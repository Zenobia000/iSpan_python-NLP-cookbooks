{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://siqi-zhu.medium.com/ldavis-a-deep-dive-into-the-popular-topic-modeling-tool-d0c61a03e969"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.lda_model\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "from collections import Counter\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "from opencc import OpenCC\n",
    "import pandas as pd\n",
    "import requests\n",
    "import jieba\n",
    "import re\n",
    "import os\n",
    "\n",
    "import pyLDAvis.lda_model\n",
    "import pyLDAvis\n",
    "\n",
    "cc = OpenCC('s2tw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4.0'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.2'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 266 entries, 0 to 265\n",
      "Data columns (total 10 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   開單時間    266 non-null    datetime64[ns]\n",
      " 1   機關      266 non-null    object        \n",
      " 2   回覆時間    266 non-null    datetime64[ns]\n",
      " 3   摘要      266 non-null    object        \n",
      " 4   細節      266 non-null    object        \n",
      " 5   回覆      266 non-null    object        \n",
      " 6   value   266 non-null    object        \n",
      " 7   問題單分類   266 non-null    object        \n",
      " 8   單號      266 non-null    object        \n",
      " 9   主機關代碼   266 non-null    int64         \n",
      "dtypes: datetime64[ns](2), int64(1), object(7)\n",
      "memory usage: 20.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"./system_problem.xlsx\")\n",
    "df.head()\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本地 csv 文件，可以是本地文件，也可以是遠程文件\n",
    "# source_csv_path = 'CRM_reviews.csv'\n",
    "# 文本 csv 文件裡面文本所處的列名,注意這裡一定要填對，要不然會報錯的！\n",
    "\n",
    "document_column_name = '摘要'\n",
    "# 輸出主題詞的文件路徑\n",
    "top_words_csv_path = 'poetry_topic_modeling.csv'\n",
    "# 輸出各文檔所屬主題的文件路徑\n",
    "predict_topic_csv_path = 'poetry-distribution.csv'\n",
    "# 可視化 html 文件路徑\n",
    "html_path = 'poetry-lda-visualization.html'\n",
    "# 選定主題數\n",
    "n_topics = 3\n",
    "# 要輸出的每个主題的前 n_top_words 主題詞數\n",
    "n_top_words = 1500\n",
    "# 去除無意義字符的正則表達式\n",
    "pattern = r'[\\\\s,.<>/?:;\\'\\\"[\\\\]{}()\\\\|~!\\t\"@#$%^&*\\\\-_=\\\\+，。\\n《》、？：；“”‘’｛｝【】（）…￥！—┄－]+'\n",
    "# 停頓詞定義\n",
    "# stop = r'我|你'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                         人事室主任郭燕燕要查看輪班相關資料，經查詢無資料，畫面如附件\n",
       "1                                        有關北嶺國小112年寒暑休設定\n",
       "2                                        秘書室新進人員無法選取該室職稱\n",
       "3             1/3及1/4曠職部分麻煩請處理，因該員原任職台東地院1/3辭職，1/12本院報到。\n",
       "4                  1/10請假，值班表設定帶頒給陳妘綺，申請完成但班表未變動，亦無法重新申請\n",
       "                             ...                        \n",
       "261    請協助開通秘書室行政助理(專案人員)邱韻娉差勤系統，(AD帳號:yunping-siraya...\n",
       "262                                  請協助開啟本校公務人員加班餘數試算功能\n",
       "263                   人員組織樹，技正有重複，而且會看到以前當科長的同仁差單，不知如何解決\n",
       "264    1/13上午08:53刷卡，因未顯示卡別，致系統出現刷卡不一致，重新轉成出勤資料亦無法處理，...\n",
       "265          請協助填寫\"是否連續在職\"、\"初任公職日\"等黃底之\"資料欄位英文名稱\"及\"資料表名稱\"\n",
       "Name: 摘要, Length: 266, dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"摘要\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取每個主題對應 topN 重要關鍵字\n",
    "def top_words_data_frame(model: LatentDirichletAllocation,\n",
    "                         tf_idf_vectorizer: TfidfVectorizer,\n",
    "                         n_top_words: int) -> pd.DataFrame:\n",
    "    '''\n",
    "    求出每个主题的前 n_top_words 个词\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : sklearn 的 LatentDirichletAllocation \n",
    "    tf_idf_vectorizer : sklearn 的 TfidfVectorizer\n",
    "    n_top_words :前 n_top_words 个主题词\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    DataFrame: 包含主题词分布情况\n",
    "    '''\n",
    "    rows = []\n",
    "    feature_names = tf_idf_vectorizer.get_feature_names_out()\n",
    "    for topic in model.components_:\n",
    "        top_words = [feature_names[i]\n",
    "                     for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "        rows.append(top_words)\n",
    "    columns = [f'word {i+1}' for i in range(n_top_words)]\n",
    "    df = pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義預測函式\n",
    "def predict_to_data_frame(model: LatentDirichletAllocation, X: np.ndarray) -> pd.DataFrame:\n",
    "    '''\n",
    "    求出文档主题概率分布情况\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : sklearn 的 LatentDirichletAllocation \n",
    "    X : 词向量矩阵\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    DataFrame: 包含主题词分布情况\n",
    "    '''\n",
    "    matrix = model.transform(X)\n",
    "    columns = [f'P(topic {i+1})' for i in range(len(model.components_))]\n",
    "    df = pd.DataFrame(matrix, columns=columns)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除重複、去除缺失、分词, 轉繁體\n",
    "df['abstrat'] = (\n",
    "    df['摘要']\n",
    "    .apply(lambda x: str(x))\n",
    "    .apply(lambda x: re.sub(pattern, ' ', x))\n",
    "    # .apply(lambda x: re.sub(stop, ' ', x))\n",
    "    .apply(lambda x: \" \".join(jieba.lcut(x, use_paddle=True)))\n",
    "    .apply(lambda x: cc.convert(x))\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>摘要</th>\n",
       "      <th>abstrat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>人事室主任郭燕燕要查看輪班相關資料，經查詢無資料，畫面如附件</td>\n",
       "      <td>人事 室主任 郭燕燕要 查看 輪班 相關 資料 ， 經查詢 無資料 ， 畫面 如 附件</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>有關北嶺國小112年寒暑休設定</td>\n",
       "      <td>有關 北嶺國 小 112 年 寒暑 休設定</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>秘書室新進人員無法選取該室職稱</td>\n",
       "      <td>秘書室 新 進人員 無法 選取 該室 職稱</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/3及1/4曠職部分麻煩請處理，因該員原任職台東地院1/3辭職，1/12本院報到。</td>\n",
       "      <td>1 / 3 及 1 / 4 曠職 部分 麻煩 請 處理 ， 因該 員 原任 職臺 東地院 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/10請假，值班表設定帶頒給陳妘綺，申請完成但班表未變動，亦無法重新申請</td>\n",
       "      <td>1 / 10 請假 ， 值班 表設定 帶 頒給 陳 妘 綺 ， 申請 完成 但班表未 變動 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>請協助開通秘書室行政助理(專案人員)邱韻娉差勤系統，(AD帳號:yunping-siraya...</td>\n",
       "      <td>請 協助 開通 秘書室 行政助理 ( 專案 人員 ) 邱韻 娉 差勤 系統 ， ( AD 帳...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>請協助開啟本校公務人員加班餘數試算功能</td>\n",
       "      <td>請 協助 開啟 本校 公務人員 加班 餘數 試算 功能</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>人員組織樹，技正有重複，而且會看到以前當科長的同仁差單，不知如何解決</td>\n",
       "      <td>人員 組織 樹 ， 技正 有重 複 ， 而且 會 看到 以前 當科長 的 同仁 差單 ， 不...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>1/13上午08:53刷卡，因未顯示卡別，致系統出現刷卡不一致，重新轉成出勤資料亦無法處理，...</td>\n",
       "      <td>1 / 13 上午 08 : 53 刷卡 ， 因未 顯示 卡別 ， 致系統 出現 刷卡 不 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>請協助填寫\"是否連續在職\"、\"初任公職日\"等黃底之\"資料欄位英文名稱\"及\"資料表名稱\"</td>\n",
       "      <td>請 協助 填寫 \" 是否 連續 在 職 \" 、 \" 初任 公職 日 \" 等 黃 底 之 \" ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>266 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    摘要  \\\n",
       "0                       人事室主任郭燕燕要查看輪班相關資料，經查詢無資料，畫面如附件   \n",
       "1                                      有關北嶺國小112年寒暑休設定   \n",
       "2                                      秘書室新進人員無法選取該室職稱   \n",
       "3           1/3及1/4曠職部分麻煩請處理，因該員原任職台東地院1/3辭職，1/12本院報到。   \n",
       "4                1/10請假，值班表設定帶頒給陳妘綺，申請完成但班表未變動，亦無法重新申請   \n",
       "..                                                 ...   \n",
       "261  請協助開通秘書室行政助理(專案人員)邱韻娉差勤系統，(AD帳號:yunping-siraya...   \n",
       "262                                請協助開啟本校公務人員加班餘數試算功能   \n",
       "263                 人員組織樹，技正有重複，而且會看到以前當科長的同仁差單，不知如何解決   \n",
       "264  1/13上午08:53刷卡，因未顯示卡別，致系統出現刷卡不一致，重新轉成出勤資料亦無法處理，...   \n",
       "265        請協助填寫\"是否連續在職\"、\"初任公職日\"等黃底之\"資料欄位英文名稱\"及\"資料表名稱\"   \n",
       "\n",
       "                                               abstrat  \n",
       "0          人事 室主任 郭燕燕要 查看 輪班 相關 資料 ， 經查詢 無資料 ， 畫面 如 附件  \n",
       "1                                有關 北嶺國 小 112 年 寒暑 休設定  \n",
       "2                                秘書室 新 進人員 無法 選取 該室 職稱  \n",
       "3    1 / 3 及 1 / 4 曠職 部分 麻煩 請 處理 ， 因該 員 原任 職臺 東地院 1...  \n",
       "4    1 / 10 請假 ， 值班 表設定 帶 頒給 陳 妘 綺 ， 申請 完成 但班表未 變動 ...  \n",
       "..                                                 ...  \n",
       "261  請 協助 開通 秘書室 行政助理 ( 專案 人員 ) 邱韻 娉 差勤 系統 ， ( AD 帳...  \n",
       "262                        請 協助 開啟 本校 公務人員 加班 餘數 試算 功能  \n",
       "263  人員 組織 樹 ， 技正 有重 複 ， 而且 會 看到 以前 當科長 的 同仁 差單 ， 不...  \n",
       "264  1 / 13 上午 08 : 53 刷卡 ， 因未 顯示 卡別 ， 致系統 出現 刷卡 不 ...  \n",
       "265  請 協助 填寫 \" 是否 連續 在 職 \" 、 \" 初任 公職 日 \" 等 黃 底 之 \" ...  \n",
       "\n",
       "[266 rows x 2 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"摘要\", \"abstrat\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF IDF vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# built tf-idf\n",
    "tf_idf_vectorizer = TfidfVectorizer()\n",
    "tf_idf = tf_idf_vectorizer.fit_transform(df['abstrat'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>02316</th>\n",
       "      <th>03</th>\n",
       "      <th>05</th>\n",
       "      <th>0600</th>\n",
       "      <th>0750</th>\n",
       "      <th>08</th>\n",
       "      <th>0800</th>\n",
       "      <th>...</th>\n",
       "      <th>體育室</th>\n",
       "      <th>高中</th>\n",
       "      <th>高雄市</th>\n",
       "      <th>麻煩</th>\n",
       "      <th>麻煩查</th>\n",
       "      <th>點到</th>\n",
       "      <th>點完</th>\n",
       "      <th>點核</th>\n",
       "      <th>點選</th>\n",
       "      <th>龐雜</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.243417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.242532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>266 rows × 1653 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      00   01   02  02316   03   05  0600  0750        08  0800  ...  體育室  \\\n",
       "0    0.0  0.0  0.0    0.0  0.0  0.0   0.0   0.0  0.000000   0.0  ...  0.0   \n",
       "1    0.0  0.0  0.0    0.0  0.0  0.0   0.0   0.0  0.000000   0.0  ...  0.0   \n",
       "2    0.0  0.0  0.0    0.0  0.0  0.0   0.0   0.0  0.000000   0.0  ...  0.0   \n",
       "3    0.0  0.0  0.0    0.0  0.0  0.0   0.0   0.0  0.000000   0.0  ...  0.0   \n",
       "4    0.0  0.0  0.0    0.0  0.0  0.0   0.0   0.0  0.000000   0.0  ...  0.0   \n",
       "..   ...  ...  ...    ...  ...  ...   ...   ...       ...   ...  ...  ...   \n",
       "261  0.0  0.0  0.0    0.0  0.0  0.0   0.0   0.0  0.000000   0.0  ...  0.0   \n",
       "262  0.0  0.0  0.0    0.0  0.0  0.0   0.0   0.0  0.000000   0.0  ...  0.0   \n",
       "263  0.0  0.0  0.0    0.0  0.0  0.0   0.0   0.0  0.000000   0.0  ...  0.0   \n",
       "264  0.0  0.0  0.0    0.0  0.0  0.0   0.0   0.0  0.242532   0.0  ...  0.0   \n",
       "265  0.0  0.0  0.0    0.0  0.0  0.0   0.0   0.0  0.000000   0.0  ...  0.0   \n",
       "\n",
       "      高中  高雄市        麻煩  麻煩查   點到   點完   點核   點選   龐雜  \n",
       "0    0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1    0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2    0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3    0.0  0.0  0.243417  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4    0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "..   ...  ...       ...  ...  ...  ...  ...  ...  ...  \n",
       "261  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "262  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "263  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "264  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "265  0.0  0.0  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[266 rows x 1653 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eigen vector list\n",
    "feature_names = tf_idf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# TF-IDF matirx\n",
    "matrix = tf_idf.toarray()\n",
    "feature_names_df = pd.DataFrame(matrix, columns=feature_names)\n",
    "\n",
    "# print(feature_names_df)\n",
    "feature_names_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(\n",
    "    n_components=n_topics,\n",
    "    max_iter=50, # 疊代次數 類比epoch\n",
    "    learning_method='online', # 優化方式，在線變分推理\n",
    "    learning_offset=50, # learning rate\n",
    "    random_state=42 # 亂數種子\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(learning_method=&#x27;online&#x27;, learning_offset=50,\n",
       "                          max_iter=50, n_components=3, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(learning_method=&#x27;online&#x27;, learning_offset=50,\n",
       "                          max_iter=50, n_components=3, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LatentDirichletAllocation(learning_method='online', learning_offset=50,\n",
       "                          max_iter=50, n_components=3, random_state=42)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use tf_idf corpus train lda model\n",
    "lda.fit(tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word distribution in topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate n_top_words topic word\n",
    "top_words_df = top_words_data_frame(lda, tf_idf_vectorizer, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word 1</th>\n",
       "      <th>word 2</th>\n",
       "      <th>word 3</th>\n",
       "      <th>word 4</th>\n",
       "      <th>word 5</th>\n",
       "      <th>word 6</th>\n",
       "      <th>word 7</th>\n",
       "      <th>word 8</th>\n",
       "      <th>word 9</th>\n",
       "      <th>word 10</th>\n",
       "      <th>...</th>\n",
       "      <th>word 1491</th>\n",
       "      <th>word 1492</th>\n",
       "      <th>word 1493</th>\n",
       "      <th>word 1494</th>\n",
       "      <th>word 1495</th>\n",
       "      <th>word 1496</th>\n",
       "      <th>word 1497</th>\n",
       "      <th>word 1498</th>\n",
       "      <th>word 1499</th>\n",
       "      <th>word 1500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>加班</td>\n",
       "      <td>時數</td>\n",
       "      <td>補休</td>\n",
       "      <td>核算</td>\n",
       "      <td>紀錄</td>\n",
       "      <td>出差</td>\n",
       "      <td>試算</td>\n",
       "      <td>功能</td>\n",
       "      <td>系統後臺</td>\n",
       "      <td>給予</td>\n",
       "      <td>...</td>\n",
       "      <td>剩餘</td>\n",
       "      <td>職人員</td>\n",
       "      <td>taitung</td>\n",
       "      <td>日依</td>\n",
       "      <td>吳政益</td>\n",
       "      <td>篩選</td>\n",
       "      <td>二股</td>\n",
       "      <td>彈性</td>\n",
       "      <td>我將</td>\n",
       "      <td>總務長</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>流程</td>\n",
       "      <td>主任</td>\n",
       "      <td>主管</td>\n",
       "      <td>批核</td>\n",
       "      <td>假單</td>\n",
       "      <td>代理</td>\n",
       "      <td>業務</td>\n",
       "      <td>人事</td>\n",
       "      <td>修改</td>\n",
       "      <td>單位</td>\n",
       "      <td>...</td>\n",
       "      <td>容易</td>\n",
       "      <td>問是</td>\n",
       "      <td>先將</td>\n",
       "      <td>依據</td>\n",
       "      <td>人員補</td>\n",
       "      <td>各自</td>\n",
       "      <td>以分</td>\n",
       "      <td>有時</td>\n",
       "      <td>函示</td>\n",
       "      <td>缺勤</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>人員</td>\n",
       "      <td>資料</td>\n",
       "      <td>協助</td>\n",
       "      <td>謝謝</td>\n",
       "      <td>112</td>\n",
       "      <td>無法</td>\n",
       "      <td>差勤</td>\n",
       "      <td>刷卡</td>\n",
       "      <td>上班</td>\n",
       "      <td>系統</td>\n",
       "      <td>...</td>\n",
       "      <td>經廠</td>\n",
       "      <td>補送</td>\n",
       "      <td>人員資料</td>\n",
       "      <td>航務組</td>\n",
       "      <td>之表單</td>\n",
       "      <td>總務</td>\n",
       "      <td>僱運動</td>\n",
       "      <td>音樂學系</td>\n",
       "      <td>助理</td>\n",
       "      <td>有待</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  word 1 word 2 word 3 word 4 word 5 word 6 word 7 word 8 word 9 word 10  ...  \\\n",
       "0     加班     時數     補休     核算     紀錄     出差     試算     功能   系統後臺      給予  ...   \n",
       "1     流程     主任     主管     批核     假單     代理     業務     人事     修改      單位  ...   \n",
       "2     人員     資料     協助     謝謝    112     無法     差勤     刷卡     上班      系統  ...   \n",
       "\n",
       "  word 1491 word 1492 word 1493 word 1494 word 1495 word 1496 word 1497  \\\n",
       "0        剩餘       職人員   taitung        日依       吳政益        篩選        二股   \n",
       "1        容易        問是        先將        依據       人員補        各自        以分   \n",
       "2        經廠        補送      人員資料       航務組       之表單        總務       僱運動   \n",
       "\n",
       "  word 1498 word 1499 word 1500  \n",
       "0        彈性        我將       總務長  \n",
       "1        有時        函示        缺勤  \n",
       "2      音樂學系        助理        有待  \n",
       "\n",
       "[3 rows x 1500 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1653"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total features\n",
    "len(tf_idf_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(266, 1653)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf-idf metrix\n",
    "# convert tf_idf into tuple，for future calculation by probablity in corpus\n",
    "X = tf_idf.toarray()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## topic probability in circumstance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic probability in circumstance\n",
    "predict_df = predict_to_data_frame(lda, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P(topic 1)</th>\n",
       "      <th>P(topic 2)</th>\n",
       "      <th>P(topic 3)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.083671</td>\n",
       "      <td>0.708666</td>\n",
       "      <td>0.207663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.107747</td>\n",
       "      <td>0.107236</td>\n",
       "      <td>0.785017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.104128</td>\n",
       "      <td>0.114912</td>\n",
       "      <td>0.780960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.834865</td>\n",
       "      <td>0.079073</td>\n",
       "      <td>0.086062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.710055</td>\n",
       "      <td>0.085323</td>\n",
       "      <td>0.204622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>0.073792</td>\n",
       "      <td>0.073465</td>\n",
       "      <td>0.852742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>0.818649</td>\n",
       "      <td>0.089921</td>\n",
       "      <td>0.091430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>0.073990</td>\n",
       "      <td>0.074002</td>\n",
       "      <td>0.852008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>0.066134</td>\n",
       "      <td>0.065374</td>\n",
       "      <td>0.868492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>0.082174</td>\n",
       "      <td>0.082006</td>\n",
       "      <td>0.835820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>266 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     P(topic 1)  P(topic 2)  P(topic 3)\n",
       "0      0.083671    0.708666    0.207663\n",
       "1      0.107747    0.107236    0.785017\n",
       "2      0.104128    0.114912    0.780960\n",
       "3      0.834865    0.079073    0.086062\n",
       "4      0.710055    0.085323    0.204622\n",
       "..          ...         ...         ...\n",
       "261    0.073792    0.073465    0.852742\n",
       "262    0.818649    0.089921    0.091430\n",
       "263    0.073990    0.074002    0.852008\n",
       "264    0.066134    0.065374    0.868492\n",
       "265    0.082174    0.082006    0.835820\n",
       "\n",
       "[266 rows x 3 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## topic modeling visualiztion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "本次生成了文件： poetry_topic_modeling.csv poetry-distribution.csv poetry-lda-visualization.html\n"
     ]
    }
   ],
   "source": [
    "# pyLDAvis plot \n",
    "data = pyLDAvis.lda_model.prepare(lda, tf_idf, tf_idf_vectorizer)\n",
    "pyLDAvis.save_html(data, html_path)\n",
    "# clear screen\n",
    "os.system('clear')\n",
    "# by browser open html doc to check result \n",
    "os.system(f'start {html_path}')\n",
    "\n",
    "\n",
    "print(\"--\" * 20)\n",
    "print('本次生成了文件：',\n",
    "      top_words_csv_path,\n",
    "      predict_topic_csv_path,\n",
    "      html_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as n_top_words to csv\n",
    "# top_words_df.to_csv(top_words_csv_path, encoding='utf-8-sig', index=None)\n",
    "\n",
    "# # save predict topic to csv\n",
    "# predict_df.to_csv(predict_topic_csv_path, encoding='utf-8-sig', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of Topic Modeling Metrics\n",
    "\n",
    "1. saliency(term w) = frequency(w) * [sum_t p(t | w) * log(p(t | w)/p(t))] for topics t; see Chuang et. al (2012)\n",
    "2. relevance(term w | topic t) = λ * p(w | t) + (1 - λ) * p(w | t)/p(w); see Sievert & Shirley (2014)\n",
    "\n",
    "\n",
    "### 1. Saliency (顯著性) -> blue bar\n",
    "- `saliency(term w)` measures the importance of term \\( w \\) across a set of topics.\n",
    "- `frequency(w)` is the frequency of term \\( w \\) in the entire corpus.\n",
    "- \\( \\sum_t p(t | w) \\) sums the probabilities of all possible topics \\( t \\) given term \\( w \\).\n",
    "- \\( \\log(p(t | w)/p(t)) \\) is the log of the ratio of the probability of topic \\( t \\) given term \\( w \\) to the marginal probability of topic \\( t \\) across all documents.\n",
    "- This metric calculates the saliency of a term by multiplying its frequency in a specific topic with the difference in its distribution across all topics.\n",
    "\n",
    "### 2. Relevance (相關性) -> red bar\n",
    "- `relevance(term w | topic t)` measures the relevance of term \\( w \\) within a specific topic \\( t \\).\n",
    "- λ (`λ`) is a parameter between 0 and 1 used to balance the probability of term \\( w \\) in topic \\( t \\) \\( p(w | t) \\) with the lift of the term \\( p(w | t)/p(w) \\).\n",
    "- `p(w | t)` is the probability of term \\( w \\) occurring within topic \\( t \\).\n",
    "- `p(w)` is the marginal probability of term \\( w \\) occurring across all documents.\n",
    "- This formula measures relevance by combining the conditional probability of a term in a specific topic with its lift across the corpus.\n",
    "\n",
    "Overall, these formulas are used to determine the significance of terms within specific topics, which is crucial for understanding and interpreting the results of topic models. These metrics help in selecting terms that are both common and distinctive to a topic, enhancing our understanding of the topic's meaning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10     請 問系統 管理 - 機關 差勤 - 加班 時數 限制 ， 為何 沒有 一般 加班 平日 可...\n",
       "13     配合 公務員 服務法 修正 ， 平日 加班 時數 上限 為 4 小時 ， 但系統 管理 / ...\n",
       "30     本校 人事 人員業 完成 112 年 寒假 的 [ 差勤 管理 / 寒暑 休設 定維護 ] ...\n",
       "43     莒光 站 反應 要 進差 勤系統 請 出差 或 加班 時 網頁 都 無法 馬 上 進去 ， ...\n",
       "86     因為 學校 寒暑假 有 不同 差勤 規定 ， 請問 如何 一次 調整 多人 差勤 規定 ？ ...\n",
       "100    中辦 支付 管理 組林麗華 的 代理人 通常 會 設給 中辦 的 菸酒 組陳長 安 ， 以前...\n",
       "108    主計處 薪資 管理系 統之年終 、 考績 AKM 檔 成功 匯入 表單 簽核 系統 ， 但 ...\n",
       "123    因 職務輪調 ， 更換 請 購單 管理 人員 ， 原本 請 購單 流程 是 申請 人 - 申...\n",
       "144    鍾 正光 專委 、 程泰源 專委 於 今年 1 月 16 日屆齡 退休 ， 原已 預設 好 ...\n",
       "152    煩請 協助 刪除 刷卡 時間 單位 ： 行政 管理 組 姓名 ： 廖佳怡 刷卡 時間 ： 1...\n",
       "188    今 ( 16 ) 日要 在 「 系統 管理 」 → 「 人員 管理 」 → 「 人員 基本 ...\n",
       "192    您好 ， 有關 之 前提 問 加班 餘數合 併 設定 ， 業以 設定 完成 ， 因協助 同仁...\n",
       "211         系統 管理者 、 差勤 管理 功能 選項 消失 了 ( 差勤 管理 、 工具 ... )\n",
       "223    林員身 為 南化 管理站 主任 ， 可以 點核 所屬 人員 差勤 ， 但 卻 在 其他 所屬...\n",
       "230    陳 美靜 為 曾文 管理站 主任 ， 遊憩 課 張麗君 為 遊憩 課 代理 課長 及 秘書室...\n",
       "247    林宏緯為 工務課 課長 ， 但 他 的 所屬 差勤 資料 卻 看到 是 曾文 管理站 的 人...\n",
       "Name: abstrat, dtype: object"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 包含管理關鍵字\n",
    "df[df[\"abstrat\"].str.contains('管理', case=False)][\"abstrat\"]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
