{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pytorch Tutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'1.13.1+cpu'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# getting the dataset in \n",
        "import requests\n",
        "import zipfile\n",
        "\n",
        "# download data\n",
        "url = 'https://download.pytorch.org/tutorial/hymenoptera_data.zip'\n",
        "\n",
        "r = requests.get(url, allow_redirects=True)\n",
        "open('hymenoptera_data.zip', 'wb').write(r.content)\n",
        "\n",
        "# unzip data\n",
        "with zipfile.ZipFile('hymenoptera_data.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('.')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 資料讀取\n",
        "### torch.utils.data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n\\n## template\\n\\nclass myDataset(Dataset):\\n    def __init__(self):\\n      # 定義初始化參數\\n      # 讀取資料集路徑\\n\\n    def __getitem__(self, index):\\n      # 讀取每次迭代的資料集中第 idx  資料\\n      # 進行前處理 (torchvision.Transform 等)\\n        return 資料和 label\\n\\n    def __len__(self):\\n      # 計算資料集總共數量\\n        return 資料集總數\\n\\n'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 若要定義自己的數據集，需要繼承 Datasets 抽象類別，以及重新 override __init__()、__getitem__()、__len__()。\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "'''\n",
        "\n",
        "## template\n",
        "\n",
        "class myDataset(Dataset):\n",
        "    def __init__(self):\n",
        "      # 定義初始化參數\n",
        "      # 讀取資料集路徑\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      # 讀取每次迭代的資料集中第 idx  資料\n",
        "      # 進行前處理 (torchvision.Transform 等)\n",
        "        return 資料和 label\n",
        "\n",
        "    def __len__(self):\n",
        "      # 計算資料集總共數量\n",
        "        return 資料集總數\n",
        "\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['c']\n",
            "['p']\n",
            "['a']\n",
            "['m']\n",
            "['b']\n",
            "['o']\n",
            "['g']\n",
            "['r']\n",
            "['q']\n",
            "['v']\n",
            "['t']\n",
            "['f']\n",
            "['w']\n",
            "['h']\n",
            "['z']\n",
            "['d']\n",
            "['k']\n",
            "['s']\n",
            "['j']\n",
            "['i']\n",
            "['n']\n",
            "['e']\n",
            "['u']\n",
            "['l']\n",
            "['x']\n",
            "['y']\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class ExampleDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    self.data = \"abcdefghijklmnopqrstuvwxyz\"\n",
        "  \n",
        "  def __getitem__(self,idx): # if the index is idx, what will be the data?\n",
        "    return self.data[idx]\n",
        "  \n",
        "  def __len__(self): # What is the length of the dataset\n",
        "    return len(self.data)\n",
        "\n",
        "dataset1 = ExampleDataset() # create the dataset\n",
        "dataloader = DataLoader(dataset = dataset1,shuffle = True, batch_size = 1)\n",
        "for datapoint in dataloader:\n",
        "  print(datapoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['P', 'x', 'E', 'F', 'K', 'M', 'E', 'm', 'o', 'N', 'Q', 'H', 't', 'I', 'J', 'C', 'Q', 'M', 'N', 'Z', 'w', 'R', 'O', 'C', 'N', 'G']\n",
            "['v', 'r', 'c', 'J', 'n', 'j', 'Z', 'X', 'G', 'Y', 'A', 'D', 'C', 'b', 'G', 'E', 'y', 'W', 'g', 'i', 'W', 'T', 'U', 'V', 'Z', 'H']\n",
            "['a', 'K', 'R', 'Y', 'U', 'L', 'A', 'R', 'O', 'S', 'T', 'u', 'S', 'V', 'U', 'p', 'z', 'I', 's', 'W', 'X', 'q', 'T', 'B', 'F', 'e']\n",
            "['l', 'h', 'D', 'K', 'k', 'M', 'd', 'S', 'B', 'I', 'O', 'P', 'A', 'B', 'F', 'X', 'Y', 'J', 'D', 'f', 'L', 'L', 'V', 'H', 'Q', 'P']\n"
          ]
        }
      ],
      "source": [
        "class ExampleDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    self.data = \"abcdefghijklmnopqrstuvwxyz\"\n",
        "  \n",
        "  def __getitem__(self,idx): # if the index is idx, what will be the data?\n",
        "    if idx >= len(self.data): # if the index >= 26, return upper case letter\n",
        "      return self.data[idx%26].upper()\n",
        "    else: # if the index < 26, return lower case, return lower case letter\n",
        "      return self.data[idx]\n",
        "  \n",
        "  def __len__(self): # What is the length of the dataset\n",
        "    return 4 * len(self.data) # The length is now twice as large\n",
        "\n",
        "dataset1 = ExampleDataset() # create the dataset\n",
        "dataloader = DataLoader(dataset = dataset1,shuffle = True,batch_size =26)\n",
        "for datapoint in dataloader:\n",
        "  print(datapoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 圖片讀取example -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "class mydataset(Dataset):\n",
        "\n",
        "    def __init__(self, root_dir, lable_dir):\n",
        "        self.root_dir = root_dir\n",
        "        self.label_dir = lable_dir\n",
        "        self.path = os.path.join(self.root_dir, self.label_dir)\n",
        "        self.img_path = os.listdir(self.path)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.img_path[idx]\n",
        "        img_item_path = os.path.join(self.root_dir, self.label_dir, img_name)\n",
        "        img = Image.open(img_item_path)\n",
        "        label = self.label_dir\n",
        "        \n",
        "        return img, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_path)\n",
        "    \n",
        "\n",
        "root_dir = r\"hymenoptera_data\\train\"\n",
        "label_dir_ants = \"ants\"\n",
        "label_dir_bees = \"bees\"\n",
        "\n",
        "# 圖片物件實體化\n",
        "ants_lable_set = mydataset(root_dir, label_dir_ants)\n",
        "bees_lable_set = mydataset(root_dir, label_dir_bees)\n",
        "\n",
        "# 數據拼接\n",
        "training_data = ants_lable_set + bees_lable_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "124"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(ants_lable_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "121"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(bees_lable_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 讀取圖片內容\n",
        "img, label = ants_lable_set[29]\n",
        "img.show()\n",
        "\n",
        "img, label = bees_lable_set[29]\n",
        "img.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'ants': 0, 'bees': 1}\n"
          ]
        }
      ],
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "image_folder = ImageFolder('./hymenoptera_data/train', transform=None, target_transform=None)\n",
        "print(image_folder.class_to_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 圖片讀取example -2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'cats': 0, 'dogs': 1}\n"
          ]
        }
      ],
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "image_folder = ImageFolder('./dog_cat_data/dataset/training_set', transform=None, target_transform=None)\n",
        "print(image_folder.class_to_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data: tensor([[[[ 0.1597, -0.0116,  0.0912,  ...,  0.5707,  0.3994,  0.2624],\n",
            "          [ 0.2111, -0.0972,  0.2282,  ...,  0.5022,  0.4679,  0.4508],\n",
            "          [ 0.2111,  0.2282,  0.2967,  ...,  0.3481,  0.4337,  0.5022],\n",
            "          ...,\n",
            "          [ 0.9817,  0.9988,  1.0159,  ...,  0.9474,  0.9646,  0.9817],\n",
            "          [ 0.9303,  0.9474,  0.9817,  ...,  0.9988,  1.0159,  1.0159],\n",
            "          [ 0.8789,  0.9132,  0.9474,  ...,  0.9988,  1.0159,  1.0159]],\n",
            "\n",
            "         [[ 0.0301, -0.1275,  0.0126,  ...,  0.8704,  0.6779,  0.5203],\n",
            "          [ 0.1001, -0.1975,  0.1702,  ...,  0.7829,  0.7304,  0.6954],\n",
            "          [ 0.1176,  0.1702,  0.2402,  ...,  0.6078,  0.6779,  0.7479],\n",
            "          ...,\n",
            "          [ 0.9405,  0.9405,  0.9755,  ...,  0.8179,  0.8529,  0.8704],\n",
            "          [ 0.9055,  0.9055,  0.9405,  ...,  0.8354,  0.8529,  0.8529],\n",
            "          [ 0.8529,  0.8704,  0.8880,  ...,  0.8354,  0.8529,  0.8529]],\n",
            "\n",
            "         [[ 0.3393,  0.1999,  0.3742,  ...,  1.3851,  1.2108,  1.0539],\n",
            "          [ 0.4091,  0.1476,  0.5311,  ...,  1.3154,  1.2631,  1.2282],\n",
            "          [ 0.4614,  0.5136,  0.6182,  ...,  1.1062,  1.1934,  1.2805],\n",
            "          ...,\n",
            "          [ 1.1411,  1.1585,  1.1759,  ...,  0.9494,  0.9842,  1.0017],\n",
            "          [ 1.1062,  1.1062,  1.1411,  ...,  0.9842,  1.0017,  1.0017],\n",
            "          [ 1.0539,  1.0714,  1.1062,  ...,  0.9842,  1.0017,  1.0017]]]])\n",
            "label: tensor([1])\n"
          ]
        }
      ],
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "                  transforms.Resize((256, 256)),\n",
        "                  transforms.ToTensor(),\n",
        "                  transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "# 使用 torchvision.datasets.ImageFolder 讀取貓狗資料\n",
        "image_folder = ImageFolder('./dog_cat_data/dataset/training_set', transform=train_transform, target_transform=None)\n",
        "# 建立 DataLoader，shuffle 為 True 表示會將資料進行打亂\n",
        "data_loader = DataLoader(dataset = image_folder, batch_size= 1, shuffle= True, num_workers= 4)\n",
        "# 列印數據\n",
        "for batch_idx, (data, target) in enumerate(data_loader):\n",
        "     print(\"data:\", data)\n",
        "     print(\"label:\", target)\n",
        "\n",
        "     if batch_idx == 0:\n",
        "          break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to C:\\Users\\xdxd2\\Sunny_VS_worksapce\\Sunny_python\\lee hung yi\\ML2021-Spring\\Pytorch\\cifar-10-python.tar.gz\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fda25812707b4682b4991c4e90d49299",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting C:\\Users\\xdxd2\\Sunny_VS_worksapce\\Sunny_python\\lee hung yi\\ML2021-Spring\\Pytorch\\cifar-10-python.tar.gz to C:\\Users\\xdxd2\\Sunny_VS_worksapce\\Sunny_python\\lee hung yi\\ML2021-Spring\\Pytorch\n"
          ]
        }
      ],
      "source": [
        "# 內建資料集下載 CIFAR10\n",
        "import torchvision\n",
        "cifar_data = torchvision.datasets.CIFAR10(root=r\"C:\\Users\\xdxd2\\Sunny_VS_worksapce\\Sunny_python\\lee hung yi\\ML2021-Spring\\Pytorch\", train=True, download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "class my_cat_data(Dataset):\n",
        "    def __init__(self, root_dir, label_dir):\n",
        "        self.root_dir = root_dir\n",
        "        self.label_dir = label_dir\n",
        "        self.path = os.path.join(self.root_dir, self.label_dir)\n",
        "        self.img_path = os.listdir(self.path)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_name = self.img_path[index]\n",
        "        img_item_path = os.path.join(self.root_dir, self.label_dir, img_name)\n",
        "        \n",
        "        img = cv2.imread(img_item_path)\n",
        "        # cv2.imshow('Image', img)\n",
        "        # cv2.waitKey(0)  # 等待用户按下任意键\n",
        "        # cv2.destroyAllWindows()  # 关闭图像窗口\n",
        "\n",
        "        label = self.label_dir\n",
        "        label_ = -1\n",
        "        if label == \"cats\":\n",
        "            label_ = 1\n",
        "        elif label == \"dogs\":\n",
        "            label_ = 0\n",
        "        else:\n",
        "            lable_ = 2\n",
        "\n",
        "        return img, label_\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.img_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 嘗試讀取圖片\n",
        "root_dir = r\"./dog_cat_data/dataset/training_set/\"\n",
        "label_dir = \"cats\"\n",
        "\n",
        "animal_dataset = my_cat_data(root_dir, label_dir)\n",
        "\n",
        "# # 读取图像文件\n",
        "image = animal_dataset[0][0]\n",
        "\n",
        "# 检查图像是否成功加载\n",
        "if image is not None:\n",
        "    # 图像加载成功，可以在这里进行处理\n",
        "    # 例如，显示图像\n",
        "    cv2.imshow('Image', image)\n",
        "    cv2.waitKey(0)  # 等待用户按下任意键\n",
        "    cv2.destroyAllWindows()  # 关闭图像窗口\n",
        "else:\n",
        "    # 图像加载失败\n",
        "    print('无法加载图像')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 整合數據集\n",
        "\n",
        "root_dir = r\"./dog_cat_data/dataset/training_set/\"\n",
        "cats_label_dir = \"cats\"\n",
        "dogs_label_dir = \"dogs\"\n",
        "\n",
        "cats_dataset = my_cat_data(root_dir, cats_label_dir)\n",
        "dogs_dataset = my_cat_data(root_dir, dogs_label_dir)\n",
        "\n",
        "animals_dataset = cats_dataset + dogs_dataset\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Pytorch Tutorial",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
